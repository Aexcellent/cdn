Computers & Industrial Engineering 149 (2020) 106854 Contents lists available at ScienceDirect
Computers & Industrial Engineering
journal homepage: www.elsevier.com/locate/caie

A review of applications in federated learning
Li Li a,b, Yuxi Fan a, Mike Tse c, Kuo-Yi Lin a,b,*
a College of Electronics and Information Engineering, Tongji University, Shanghai 201804, China b Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai 201804, China c Cardiff Business School, Cardiff University, Cardiff CF10 3AT, UK

ARTICLE INFO
Keywords: Federated learning Literature review Citation analysis Research front

ABSTRACT
Federated Learning (FL) is a collaboratively decentralized privacy-preserving technology to overcome challenges of data silos and data sensibility. Exactly what research is carrying the research momentum forward is a question of interest to research communities as well as industrial engineering. This study reviews FL and explores the main evolution path for issues exist in FL development process to advance the understanding of FL. This study aims to review prevailing application in industrial engineering to guide for the future landing application. This study also identifies six research fronts to address FL literature and help advance our understanding of FL for future optimization. This study contributes to conclude application in industrial engineering and computer science and summarize a review of applications in FL.

1. Introduction
With the development of storage capacity and processing power, the importance of data science in industrial engineering becomes more apparent. Recent years have seen the explosive development of artificial intelligence, machine learning, smart production and deep learning in industrial engineering (Li, Wang, & Lin, 2020; Lin, 2018). However, there are two major challenges in this area as data science development. Firstly, data governance is the most significant aspect. Some data is privatized based on the legal concern. With the promulgation of General Data Protection Regulation (GDPR) (EU, 2018), users become the ab­ solute owner of their own data. Any institutions or organizations do not have authority to employ user’s own data unless they have agreement. Secondly, data silo is also a confronting problem that puts a limit on the development of modern industry since more training data would improve the training performance. For example, compared with the earliest AlphaGo, which used 160,000 sets of human chess data and could beat entry-level professional players. Alpha Zero (Holcomb, Porter, Ault, Mao, & Wang, 2018) used 28.6 billion sets of human and machine-generated chess data, which could easily beat professional players. Besides, data annotation relies on experienced workers in some fields such as medical industry which may cause rareness of valid data. The scarcity of labeled data is also detrimental to industrial develop­ ment. However, the emergence of FL happened to overcome these challenges in industry.

FL is a burgeoning machine learning scheme, aiming at tackling the problem of data island while preserving data privacy. It refers to mul­ tiple clients (such as mobile devices, institutions, organizations, etc.) coordinated with one or more central servers for decentralized machine learning settings. It was first put forward by Google in 2016 to predict user’s text input within tens of thousands Android devices while keeping data on devices (McMahan, Moore, Ramage, Hampson, & Arcas, 2017). The original process of FL is generally described as Fig. 1 shows. This kind of federated training approach called federated average (FedAvg), which is the baseline of FL in many other researches. Firstly, each device downloads a generic global model for the following local training. Secondly, the download global model will be improved by multiple local updates with local data, which belong to different mobile devices separately and then upload related gradient information to cloud in an encryption mode. Thirdly, the averaged update of local models imple­ mented in the cloud will be dispatched to device as a renewed global model. Finally, the above procedures repeat until the model achieves a certain desired performance or the final deadline arrives. The emergence of this technology will solve the contradiction between data privacy and data sharing for dispersed devices. Due to the property that data are not exposed to third central server, FL is appropriate for application when data are privacy-sensitive. These includes cases in health care or mobile devices that data are not available to be aggregated with legal concern.
Recently, many scholars band together to publish papers to review advances and open problems in FL. The studies provide several further

* Corresponding author at: College of Electronics and Information Engineering, Tongji University, Shanghai 201804, China. E-mail address: 19603@tongji.edu.cn (K.-Y. Lin).
https://doi.org/10.1016/j.cie.2020.106854
Available online 18 September 2020 0360-8352/© 2020 Elsevier Ltd. All rights reserved.

L. Li et al.
aspects to enhance FL contribution (Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji, & Zhao, 2019). Motivated by the promising prospects and increasing growth of FL research in industrial field, this study aims to review prevailing application of FL in industrial engineering to guide for the future landing application. This study concluded characteristic of FL and remained challenges to clarify various solutions that researchers have done to optimize FL. This study reviewed related studies of FL to base on the baseline a universal definition to identify fronts to address FL literature and help advance our understanding of FL for future optimization.
This paper is organized as follows. Beside the introduction, we sketch the overview of FL which include characteristics and mainstream opensource framework as well as categories in Section 2. In Section 3, we point out three challenges in FL along with relative improvement. Furthermore, we conclude indirect information leakage in FL and existing privacy-preserving method employed in FL. Section 4 discusses realistic applications in IOT devices and grounding application in in­ dustry engineering and healthcare. At the end, some frontier achieve­ ments are given, around these discussions we describe some promising direction of FL to give a guiding for future work.
2. Overview of federate learning
2.1. Characteristics of FL
FL is highly related to distributed learning. Traditional distributed system is made up of distributed computation, distributed storage. The first proposed FL of model update for Android clients is to some extent similar to distributed computation. Although FL put a great deal of emphasis on privacy protection, the latest researches of distributed machine learning also pay close attention to privacy-preserving distributed system. Distributed processing is to connect multiple com­ puters in different locations via communication network under the control of center server, so that each computer undertakes different parts of the same task to complete it. Thus, the distributed processing is mainly aimed at accelerating processing stage, while FL focus on build a collaborative model without privacy leakage. To reveal difference be­ tween FL and distributed learning more specifically, we highlight following characteristics in FL.
2.1.1. Universality for cross-organizational scenarios Essentially, FL proposed by Google is an encrypted distributed

Computers & Industrial Engineering 149 (2020) 106854
machine learning technology, that allows participants to build a joint training model but maintain underlying data locally. Then the original concept of FL was extended to refer to all privacy-preserving decen­ tralized collaborative machine learning techniques (Yang, Liu, Chen, & Tong, 2019). Therefore, FL is able to tackle not only horizontally par­ titioned data according to samples but also vertically partitioned data according to features in collaborative-learning setting. FL could be extended to bring cross-organizational enterprise into federal frame­ work. For instance, bank that possess data of clients’ purchasing power could cooperate with electronic business platform which possess data of product features, to recommend products. Thus, intelligently construct joint model for multiple entities, multiple data sources, different feature dimensions. This enable all to realize cross-platform and regional cocreation value on the premise of protecting data privacy.
2.1.2. Massively non-identically independent distribution (Non-IID) In FL, data is widespread in tens of thousands edge node or mobile
devices. Available data in each node may no more than the total number of nodes. While in distributed system, the main purpose is to increase degree of parallelism to alleviate computation or storage pressure in central server. The number of nodes in distributed system couldn’t reach the same order of magnitude as the FL. Nowadays, the world has entered an era of wearable devices which are used extensively for health monitoring (Edwards, 2019). Each device only generate several data and it cannot be compared with the total number of devices. Obviously, in this case, FL is more suitable for model improvement. In contrast with distributed system, which works primarily on balanced and IID data distribution, FL is concentrated on unbalanced and non-IID data because of the heterogeneity among device resources.
2.1.3. Decentralized technology Decentralization, in a strictly technical sense, does not means com­
plete decentralization, but there is no definitive center. Decentralization is only to dilute the awareness of the central node. There is no center to determine each client, and each client goes to influence central model. The influence between nodes will generate a non-linear relationship through the network formed by client. Parameter server, a typical distributed and centralized technology, mainly make use of central server which is dominating to dispatch data distribution and computa­ tion resource to obtain an efficient collaborative model (Ho, Cipar, Cui, Lee, Kim, Gibbons, & Xing, 2013). This kind of centralized data pro­ cessing method result in a double communication overhead. Because if

Fig. 1. Illustration of FL framework proposed by Google. 2

L. Li et al.
some dataset scattered in different database are collected for training, these data should be copied and then transmitted to central server at first. And then central server will allocate data to each distributed client for distributed computation. It adds additional severe tests to system on computing power, storage and bandwidth. For cases in FL, each client is completely autonomous, data is not allocated by center and the training process is not governed by server. Therefore, FL is an integrated tech­ nology to combine machine learning models and data fusion through decentralized collaboration.
2.1.4. Equality of status for each node In this cooperation framework, all parties enjoy equal status and
certain dominion to achieve common prosperity. In terms of equality, whoever possesses the great mass of data has the dominant position in traditional distributed collaborative training. Thus, the development of collaborative learning in industrial field could be adversely affected by the preference on organizations with bulk of data or images with types of label. For joint training in deep learning network, those institutions with big data could manipulate the prediction model thus small and mediumsized organizations do not have impetus in joint training. However, in FL, position of these clients with small data sets would be promoted due to equality in all parties.
To sum up, FL is a decentralized technology that enable scattered clients or organizations to train a collaborative model autonomously, while keeping data localized. This method can support corporate orga­ nizations to share collaborative models without sharing any raw data.

Computers & Industrial Engineering 149 (2020) 106854
instances, and the horizontal axis of the sheet is regarded as client, while the vertical axis represents the characteristics of clients. Then we can divide FL based on data partition mode.
2.3.1. Horizontal FL In the case of horizontal FL, there is a certain amount of overlap
between the feature of data spread across various nodes, while the data are quite different in sample space. At present, the existing FL algorithms primarily aimed at application in smart devices or devices in the internet of things (IOT). FL in these scenarios usually could be classified into horizontal FL. Because data may significantly differ in sample space but have similar feature space simultaneously. As is mentioned above, the federated model solution for Android mobile phone update raised by Google (McMahan et al., 2017) is typically a kind of horizontal FL since the data has the same feature dimension. In addition, to meet the challenge of limited labeled entities, Gao, Ju, Wei, Liu, Chen, and Yang (2019) introduced hierarchical heterogeneous horizontal FL frame. The shortage of lack of label can be solved because heterogeneous domain adaptation would be adapted multiple times by using each participant as the target domain each time. This would do benefit to lack of data annotation in Electroencephalography (EEG) classification. In real application such as medical care, a large amount of work is inseparable from data collection. When it comes to cross-regional cooperation, it is almost impossible for each hospital to build a data pool for sharing. Thus, FL could construct a federal network for cross-regional hospitals with similar medical information to improve joint model as Fig. 2 shows.

2.2. Open source framework
There have been two mainstream open-source frameworks for FL up to now and they are starting to take shape. One is TensorFlow Federated (TFF) framework at the service of machine learning or other computa­ tion demand for decentralized data (Google, 2019). It is the first selfcontained framework designed at production level mainly for mobile devices. Specially, TFF integrates FedAvg for model update and Secure Aggregation for privacy concern (Bonawitz, Ivanov, Kreuter, Marce­ done, McMahan, Patel, & Seth, 2017). This TTF consists of FL API and Federated Core (FC) API. In detail, FL API offers a set of high-order in­ terfaces make users can apply the included machine learning method to process federated training. FC API, the basic layer for federation learning, serving for distributed computation. Furthermore, it has been successfully applied in next word prediction or Emoji prediction in a mobile keyboard (Ramaswamy, Mathews, Rao, & Beaufays, 2019). In real application, it has achieved implementation over ten million of devices while hope to be highly scalable to deal with computation over billion of devices.
The other one is Federated AI Technology Enabler (FATE) created by Webank team (Webank, 2019a). As the first open source industrial-level framework, it primarily serves for cross-organizational architecture. It provides enough privacy for client based on homomorphic encryption and secure multiparty computing. Besides, various machine learning algorithms such as logistic regression and deep learning, as well as transfer learning are able to be built on this federation system. In addition to these out of the box algorithms, most traditional methods can be adapted to this federal frame. At present, the Webank team has promoted the implementation of a series of FATE in credit risk control, object detection and anti-money laundering (Webank, 2019b). These two frameworks are popular for FL in real application and further development on algorithm improvement.
2.3. Categorization of FL
Based on paper presented by Yang et al. (2019), FL largely falls into three groups, respectively, horizontal FL, vertical FL and federated transfer learning. Since data stored in different nodes or institutions mainly exist in a feature matrix form. Commonly, data consists many

2.3.2. Vertical FL Vertical FL is suitable for cases in which data is partitioned in the
vertical direction according to feature dimension. All the parties hold homogeneous data which means they have partial overlap on sample ID whereas differ in feature space. For example, there was a medical institution, and they intend to identify illnesses such as diabetes mellitus in a predictive way. According to research, people who suffer from high blood pressure and obesity may be prone to developing type2 diabetes (Lee, Lacy, Jankowich, Correa, & Wu, 2020). Therefore, it could be analyzed in view of some rough dimensions, such as patients’ age and weight as well as medical history. If there is a young man without obesity or high blood pressure, but intake more calories and lack of physical activity. He is also prone to get diabetes, but it couldn’t be predicted and personalized due to lack of information. With develop­ ment of FL, it can work with some companies which holds smartphone application data sets such as step counter or dietary structure. Further. They can cooperate with each other without demand for raw data transmission as Fig. 3 shows. Generally, scholars deal with this problem through taking out the same entities with various characteristics to get a joint training. By contrast with horizontal FL, it is a more challenging work due to entity resolution (Gasco´n et al., 2017). Not quite as simple as situation in horizontal FL, aggregating all the dataset in a common server to learn from the global model doesn’t work on vertical FL since the correspondence between different owners is still an urgently need to be addressed. There comes a modified token-based entity resolution algorithm to preprocess vertical partitioned data, powered by Nock, Hardy, Henecka, Ivey-Law, Patrini, Smith, and Thorne (2018). Hardy, Henecka, Ivey-Law, Nock, Patrini, Smith, and Thorne (2017) designed an end-to-end scheme on linear classifier and applied additive homo­ morphic encryption to defense honest-but-curious adversary for vertical FL. It is reported that current applications for parties with common sample space including traffic violation assessment and small enterprise credit risk assessment are based on FATE created by Webank team. In addition, Cheng, Fan, Jin, Liu, Chen, and Yang (2019) designed a secure framework called SecureBoost in the setting of vertically partitioned data set. However, the abovementioned methods could only be applied in simple machine learning models such as logistic regression. There­ fore, vertical FL still has much more room for improvement to be applied in more complicated machine learning approaches.

3

L. Li et al.

Computers & Industrial Engineering 149 (2020) 106854

Fig. 2. An application sample of Horizontal FL.

Fig. 3. An application sample of Vertical FL.

2.3.3. Federated transfer learning Unlike the scenarios in horizontal FL and vertical FL, in most cases,
data shares neither sample space nor feature space. Thus, the main problem in this setting is lack of data labels with poor data quality. Transfer learning enables to move the knowledge of one domain (i.e., the source domain) to another domain (i.e., the target domain) to ach­ ieve better learning results, which is appropriate for this situation (Pan, Ni, Sun, Yang, & Chen, 2010). In this way, Liu, Chen, and Yang (2018) conceived federated transfer learning (FTL) to generalize FL to have broader application when it comes to common parties with small intersection. This is the first complete stack for FL based on transfer learning, including training, evaluation and cross validation. Besides this, the neural networks with additive homomorphic encryption tech­ nology in this frame could not only prevent privacy leakage but also provide comparable accuracy with traditional non-privacy-preserving method. However, communication efficiency remains an issue. Accordingly, Sharma, Chaoping, Liu, and Kang (2019) work hard on improvement for FTL. They made use of secret sharing technology

instead of HE to further reduce overhead without decreasing the accu­ rate rate. Furthermore, it could be extended to hinder malicious server. While in the previous work they assume that they the model is semihonest. For a real application, Chen, Ning, and Rangwala (2019), Chen, Sun, and Jin (2019) constructed a FedHealth model that gather data owned by different organizations via FL and offer personalized service for healthcare through transfer learning. As shown in Fig. 4, some disease diagnosis and treatment information in one hospital could be transferred to another hospital to help other disease diagnosis by FTL. The research in FTL is not yet mature, thereby there is still plenty of room for growth to make it more flexible with different data structure. Data islands and privacy protection issues are prominent problems encountered in the current large-scale industrialization of machine learning. However, federated transfer learning is an effective way to protect both data security and user privacy while breaking the barriers of data islands.

4

L. Li et al.

Computers & Industrial Engineering 149 (2020) 106854

Fig. 4. An application sample of federated transfer learn.

3. Evolution of FL
The primitive framework of FL is FedAvg. Though it could deal with some lightweight Non-IID data. It is still faced with challenges of high communication overhead and structural heterogeneity. Recent works focus on algorithm optimization to improve efficiency and accuracy and participants’ privacy to enhance data protection. In this section, this study discusses about the evolution and optimization in the following. We mainly explore development path in algorithm optimization level as well as security level.
3.1. Optimization
Since the term of FL was first proposed in 2016, drawing people’s extensive attention, study about it has progressed. Although a lot of work had been done, there are still some challenges fail to be overcame for practical application. In terms of optimization for grounding appli­ cation, high communication cost, statistical and structural heterogeneity are major issues faced by researchers currently (Li, Sanjabi, Beirami, & Smith, 2020). In this section, we summarize the optimization path of FL according to development process and method categories to overcome these challenges. As Fig. 5 shows, the algorithm optimization all based

on the paper presented by McMahan et al. (2017). The first branch de­ notes the studies to deal with high communication cost. The second one represents the evolution of overcome the challenge of statistical het­ erogeneity, while the third denotes structural heterogeneity. In the same branch, different symbols represent different ways to tackle the issue. The thickness of the line shows reference frequency of these papers in Google Scholar by other papers. The thicker the line, the higher refer­ ence frequency of the paper. The details of this optimization path are as follows.
(1) High communication cost.
By far, the key bottleneck of FL has been the difficulty of decreasing communication overhead when proceeding federal training (Yang et al., 2019). The most important feature of modern data is timeliness since the life cycle of this data is short and data iterative update speed is fast. To tackle with large masses of data and make FL flexible with explosive increasing data, reducing communication overhead should be given top priority. Meanwhile, effective efforts have been made in work including reducing communication rounds and improving model upload speed further reduce update time.

Fig. 5. Optimization path to overcome three challenges in FL. 5

L. Li et al.
3.1.1. Reducing communication rounds Due to unmatched download and upload speed, communication
between server and clients is willing to be as little as possible to reduce upload times. The research of McMahan et al. (2017) is considered as the pioneering work on FL to make communication more efficient by increasing calculated quantity on each client between each communi­ cation round. They also pointed out that increase parallelism which means motivate more clients to join training on each round is an effective way. Inspired by Google, Nishio and Yonetani (2019) built FedCs framework to integrate the available clients to the utmost extent in each training round to make it efficiently in practice. Maximum mean discrepancy was inserted to FL algorithm to enforce local model to ac­ quire more knowledge from other in training devices thus speed up convergence (Yao, Huang, & Sun, 2018). Yurochkin et al. (2019) designed Bayesian Nonparametric FL framework, which is state of the art since it can aggregate local models into a federated model without extra parameters thus avoid unwanted communication rounds. The experiment shows that they can obtain satisfactory accuracy rating with only one communication round.
3.1.2. Decrease model update time Even if the communication rounds are optimized, how to accelerate
model update is a remained problem. Initially, McMahan et al. proposed two strategies to reduce model update time (Koneˇcný, McMahan, Yu, Richta´rik, Suresh, & Bacon, 2017). One is structured update, which means transmit only part of the update model by means of low-rank model or in a random mask way. Likewise, an end-to-end neural network is a kind of structured update mode which maps update infor­ mation into a lower-dimension space thus relieve pressure of commu­ nication (Li & Han, 2019). The other is sketched update, which refer to make use of compressed update model. Zhu and Jin (2019) optimized sparse evolutionary training (SET) thus convey only piece of parameters to server, which resemble the sketched update. Since in each round, each client manipulates fixed epochs, Jiang and Ying (2020) designed an adaptive method for local training. The local training epochs is decided by server according to training time and training loss, thus it will reduce local training time when loss is getting small. The above-mentioned algorithms all based on stochastic gradient descent (SGD), but this method could be inefficient if the function is anisotropic. Therefore, Liu, Chen, Chen, and Zhang (2020) utilized momentum gradient descent to consider previous gradient information in each local training epoch to accelerate convergence speed. These algorithms are not fully suitable for all federal setting. Therefore, a more flexible communication-efficient method needs to be explored for high efficiency demand in medical industry.
(2) Statistical heterogeneity.

Computers & Industrial Engineering 149 (2020) 106854
to cope with any target distribution comprised by a mixture of different clients. As for aggregation stage, convergence behavior is another stressed issue. The existence of heterogeneity may lead to mis­ convergence of global model. Further Wang, X. et al. (2019) discussed convergence bound of FL based on gradient-descent in Non-IID data background, and further bring forward an improved adaptive method to reduce loss function within constraints of resource budget. Moreover, Li, Huang, Yang, Wang, and Zhang (2019) gave four kinds of convergence theorems with different parameters setting or premises for FedAvg in Non-IID situations. These studies fill a part of the theoretical gap in the research of convergence speed of a FL algorithm. Besides, it provides the effect of parameter adjustment on the convergence speed for the guidance.
3.1.4. Add extra data preprocessing procedure For data pre-processing, Huang, Shea et al. (2019) introduced clus­
tering thought with FL and constructed a community-based FL method. By separating independent data into different clusters, then processing federated training on each community, the non-IID problem is thus can be resolved. However, one drawback is that it’s not suitable for massively data training due to high parameter conversion overhead. In hierarchical heterogeneous horizontal framework, it projects each embedding submanifold into a common embedding space to overcome data heterogeneity (Gao et al., 2019).
3.1.5. Modify local training mode Another idea is to optimize modeling way to achieve personalization
for individual devices such as MOCHA, which introduced multi-task learning to make utilization of shared representation (Smith, Chiang, Sanjabi, & Talwalkar, 2017). Zhao, Li, Lai, Suda, Civin, and Chandra (2018) did the similar work, they considered a solution to deal with noniid data by sharing a small set of data among each local model. Huang, Yin et al. (2019) also gained a good deal of enlightenment from the previous data sharing ideology to overcome Non-IID problem. They put cross-entropy loss into transmission process and assign different local update times for each client in each round.
(3) Structural heterogeneity.
In terms of structural heterogeneity, it mainly refers to two aspects. On the one hand, the competence of computing and storage vary from nodes to nodes since different devices use various kinds of chip, thereby cause unbalanced training time. On the other hand, clients differ in network environment. The unreliable and unstable network may lead to devices’ drop out. Up to now, methods to deal with structural hetero­ geneity mainly focus on resource allocation for heterogeneous devices and fault tolerance for devices prone to be offline.

Traditional machine learning approach, implicitly or explicitly, as­ sumes the data distribution is identically independent. This scenario is suitable for collecting all data and then training in a distributed way. However, data are collected from various devices or institutions thereby do not follow Identically Independent Distribution (IID). Skew charac­ teristic and clinical validation may vary among different equipment version (Godinho et al., 2016). And data record form in across multiple horizontals could be totally different. Besides, there’s may be a huge variety of data size in different nodes result in an unbalanced distribu­ tion. To tackle this problem, the general resolution is to focus on global model, or modify local training mode, or adding some extra procedure on data pre-processing stage.
3.1.3. Focus on global model The first proposed FedAvg algorithm resolve this issue by averaging
local upgrade on each device directly. In addition, Mohri, Sivek, and Suresh (2019) noticed previous work ignore the importance of fairness which may lead to bias centralized model. They improved global model

3.1.6. Fault tolerance The federated multi-task learning was constructed in the wake of
Google’s research on decentralized data training (Smith et al., 2017). To address the issue of stragglers (who is drop out or still training with an outdated global parameters), they considered influence with low participation in training process to resist device drop out. Enable FL system to be robust to dropped participants, scholars also designed secure aggregation protocol (Hao, Li, Luo et al., 2019) which is tolerant with arbitrary dropouts as long as surviving users are enough to join federate update. Lib et al. (2019) take stragglers into account and allow these devices to implement different locally update computation times. Wu, He, Lin, and RuiMao (2019) also fully considered device straggling phenomenon in heterogeneous network. They made use of a cache structure to store those unreliable user update thus alleviates their trustless impact on global model.
3.1.7. Resource allocation For the sake of resource constraint, most of foregoing work devote to

6

L. Li et al.
allocate resources properly to heterogeneous devices. For instance, Kang et al. (2019) took overhead in heterogeneous clients into consideration to motivate more high-quality devices to participate training process. And Tran, Bao, and Zomaya (2019) studied training accuracy and convergence time with influence of heterogeneous power constraints. Meanwhile, Chai, Fayyaz, Fayyaz, Anwar, Zhou, Baracaldo, and Cheng (2019) considered the impact of resource (e.g. CPU, memory, and network resources) heterogeneity on training time of FL. To address this issue, Li, T. et al. (2020) designed a fairness metrics to measure loss in devices and a q-Fair optimization goal to impel fair resource allocation in FL. In a nutshell, stragglers and heterogeneity run through FL framework. Therefore, in the future, optimization should continue to contribute to fault-tolerance and properly resource allocation to address this issue.
3.2. Security analysis
In this section, we elaborate the evolution of privacy attack and enhancement in FL. As shown in Fig. 6, the first branch indicates indirect privacy leakage in FL. And the other two branches show improvement trace for privacy enhancement for FL. One is privacy-preserving method on client side, and the other one is on the server side. These two branches intersect at a node which derive another branch to denote hybrid approach to enhance privacy. The thickness of the line also shows reference frequency of these papers. The thicker the line, the higher reference frequency of the paper. The details are as follows.
3.2.1. Privacy risk Though patients’ private data never come out of the local storage
during federated training process which may alleviate privacy concerns. Nevertheless, the system is not sufficiently secure because the trans­ mission of gradients and partial parameters may lead to indirect privacy leakage (Bos, Lauter, & Naehrig, 2014). Since original data under the risk of being cracked by back deduction. Some investigators have considered to retrieve data in FL framework. The general attack types are mainly divided into three categories as bellow:
3.2.1.1. Data poisoning attack. Aiming at embedding some tainted data such as malicious samples or disguised data to destroy data integrity or give rise to the bias of training results. There are two main types of ‘data

Computers & Industrial Engineering 149 (2020) 106854
poisoning’ attack modes including model skew and feedback weaponi­ zation. Traditional machine learning approaches are vulnerable to data poisoning since adversarial could directly manipulate the triggers to misguide the global model. Nevertheless, these traditional data poi­ sonings methods are less effective or may need many malicious partic­ ipants when it comes to FL since malicious attackers have no direct access to raw data (Bagdasaryan, Veit, Hua, Estrin, & Shmatikov, 2018). On the basis research of Bagdasaryan et al., (2018), Yang et al. (2019) studied a novel and effective distributed backdoor attack. They divided an attack trigger into many slices and embedded each slice into different attackers instead of embedding a complete trigger into only one attacker. This new-fashioned mode throws a wrench in the old argument that FL is possible to avoid data poisoning. It also gives a new evaluation form for security analysis in FL.
3.2.1.2. Model poisoning (Also known as adversarial attack). Model poisoning refer to make machine learning model to generate a wrong result by designing a specific input. Furthermore, it can be subdivided into Non-targeted adversarial attack and Targeted adversarial attack. The former one is a common type which lead to an incorrect conse­ quence, and the other one is relatively difficult that aiming at injecting a specific type for input. In FL, secure aggregation is implemented, and aggregator is not familiar with the local update modes thus are not able to detect anomalies or verify correctness of local updates. According to this drawback, the backdoor can be inserted into federated environment by malicious participant through model-replacement methodology thus misunderstand the joint model. This novel attack method can be suc­ cessfully employed in federated training tasks including image classifi­ cation and word prediction (Bagdasaryan et al., 2018). Similarly, Bhagoji, Chakraborty, Mittal, and Calo (2019) attacked global model through few malicious adversaries to wrongly classified targeted model. This kind of attack obviously belong to targeted adversarial attack. In this case, they ensure convergence of integrated model and accuracy of most tasks. In addition, the results show Byzantine-resilient aggregation technology is weak to offense this type of attack in the federated setting. Then Zhang, Chen, Wu, Chen, and Yu (2019) give first attempt to generate model poisoning attack based on Generative Adversarial Nets (GAN). In this work, malicious participant pretended to be a benign agent. Then they assign a GAN architecture to generate training data as well as distributed a wrong label to induce benign client to be damaged.

Fig. 6. The evolution of privacy attack and enhancement in FL. 7

L. Li et al.
The existing methodologies aiming at defending poisoning attack are quite invalid in federated settings. In the future work, to mitigate this type of attack for FL, anomaly detection in server side and concealment of classification results is a promising direction.
3.2.1.3. Inferring attack. The value of this type of attack mainly used to detect privacy records or restore training data through a white box or a black box. It can be broken down into tracing attacks (also known as membership inference attacks) and reconstruction attacks. The first mentioned of two indicates to infer whether a client is contained in the data set. The latter advocates recover some features about an individual participant. With utilization of vulnerability of SGD, Nasr, Shokri, and Houmansadr (2019) designed a white-box membership inference attack method direct at neural network. Then it was successfully applied to federated setting to infer information via a curious server or any of a participant. The previous work focuses on malicious server assumption and unable to recover information on specific client because of invisi­ bility of client update. In cases of this kind, Wang, Z. et al. (2019) built a general attack frame called mGAN-AI which could reconstruct private information for target client. To hinder this kind of attack, more stronger protection method should be explored, and data could be encrypted before upload to cloud.
3.2.2. Privacy-preserving technology in FL The indirect privacy disclosure poses immense challenges on devel­
opment of FL. Potential threats are usually from insider adversaries and outsider adversaries. Insider adversaries including honest-but-curious aggregator, colluding parties and malicious participants steal privacy during training process. The honest-but-curious aggregator means that the server will keep to the privacy agreement but have a try to explore more information about clients. Colluding parties or malicious partici­ pants are unreliable to transmit incorrect updates as well as learn additional information from other benign clients. Outsider adversaries refer to those who can peep intermediate outputs or users that have access to final model. Faced with these vulnerabilities, the existing privacy-preserving methods to enhance privacy guarantees mainly focus on information encryption for client or secure aggregation at server side as well as security protection for FL framework (Ma, Li, Ding, Yang, Shu, Quek, & Poor, 2019). This study discusses novel privacy-preserving technologies based on this classification as bellows.
3.2.2.1. Privacy-preserving at client side. Differential privacy often acts as a means of enhancing privacy preservation for client. When querying data from database, it will reduce chances for records to be identified while maximize query accuracy as much as possible by introducing noise to blur raw data. For instance, since FedAvg is prone to be violated by differential attack, Geyer, Klein, and Nabi (2018) leveraged differ­ ential privacy on FL to conceal whether a client participant in the training process. Likewise, to improve FedAvg, McMahan, Zhang, Ramage, and Talwar (2018) also applied DP to this process by adding Gaussian noise to the global model. In federated online training for ranker using feedback from users, Kharitonov (2019) introduced ε-local differential privacy. Opposite to common algorithms, it is stricter since they protect user-lever privacy instead of imposing privacy-preserving technology after data aggregation.
In addition, homomorphic encryption is also a privacy policy applied in FL frequently to hinder information leakage during parameter ex­ change process among clients. Homomorphic encryption refers to an encryption mechanism that parameters are encoded before adding or multiplying operation and performs equivalent result compare to uncode function. Liu et al. (2018) employed additively homomorphic encryption to modify neural network model and minimize the impact on training accuracy. Ilias and Georgios (2019) also added homomorphic encryption to a more robust FL framework, which make it possible to compute aggregation on encrypted client. Training on these

Computers & Industrial Engineering 149 (2020) 106854
cryptographic models may raise additional communication overhead since more data such as private key should be conveyed.
Locality-sensitive hashing (LSH) is also a prevalent way to keep confidentiality (Gionis, Indyk, & Motwani, 1999). All features would be mapped into an encryption form via p-stable hash function. The main advantage of this encryption mode is that similarity between two sam­ ples will be retained after hash representation. However, two different samples virtually impossible to hold similar hash values. Raw data wouldn’t be exposed because many samples may have same outputs. Besides, LSH would not cause overmuch communication overhead like homomorphic encryption and reduce accuracy like differential privacy. Lee et al. (2018) make use of LSH to detect similar patients in federated settings. Recently, Li et al. (2020) build a practical gradient boosting decision trees rely on LSH. In the pre-processing stage, LSH would help find similar samples dispersed in different clients, and they will use the sum gradients of similar instances instead of only use the gradient of one instance when processing gradient updating.
3.2.2.2. Secure aggregation. Secure multi-party computation (SMC) is employed, which mainly concentrate on how to safely calculate a function for various client without a reliable third party. Bonawitz et al. (2017) proposed the first secure aggregation protocol with utilization of secure multiparty computation. In this agreement, model update infor­ mation of each device is unrevealed to central server. Only after enough devices update their model, can server receive the aggregated model. Owing to the quadratic communication cost, the above-mentioned protocol is not applicable for larger scale situations. By this way, Hao, Li, Luo et al. (2019) envisioned a more efficient privacy-preserving scheme for FL, which integrate differential privacy and lightweight homomorphic encryption technology. This protocol, mainly for sto­ chastic gradient descent approach, is robust to curious-but-honest server and collusion between the cloud and server. Occasionally, global model returned by clouds may not reliable or complete. Because unreliable cloud server may be malicious to return a totally wronged model or may be lazy to convey a compressed but inaccurate model due to computa­ tional pressure. Thereafter Xu, Li, Liu, Yang, and Lin (2020) devised VerifyNet, the first protocol that can verify correctness of returned model from cloud. For privacy guarantee, they implemented variation of secret sharing combined with key agreement protocol to enhance confidentiality of gradients. The up-to-date approach proposed by Chen et al. (2020) also concentrated on secure aggregation scheme. They add an extra public parameter dispatch to each client to force them training in a same way, thus detect malicious client easily when making an ag­ gregation stage.
3.2.2.3. Protection method for FL framework. Although aforementioned algorithms could avoid adversary to invade central server or clients, the encrypted parameters may still cause information leakage by means of novel attack methods as 3.2.1 mentioned. To enhance privacy for the framework, many hybrid approaches have been proposed. However, the introduced noise of differential privacy may lead to decreased accuracy. To reduce noise, the Hybrid-One scheme combine the use of DP with MPC without compromising accuracy rate, which protect communica­ tion messages rely on MPC thus introduce less noise than traditional local DP (Truex et al., 2019). But this method often result in unafford­ able communication cost and long convergence time as homomorphic encryption can be. Then the efficient HybridAlpha emerged at the right moment, which combined functional encryption with SMC protocol to achieve the highly-performance model without privacy sacrifice (Xu, Baracaldo, Zhou, Anwar, & Ludwig, 2019). Additionally, sketched al­ gorithms are inherently suitable for FL since data identities are not stored, and extra mechanisms are needed to trace back original data. Inspired by this, Liu, Li, Smith, and Sekar (2019) established relation­ ship between FL and sketching algorithm to strength confidentiality.

8

L. Li et al.
4. Application
FL takes hold as a prevailing scheme with the construction of collaborative model without legal concern. Even facing with the fore­ mentioned limitations and severe challenges, early participants have seen significant opportunities of FL and have launched a series of related explorations and attempts to apply FL in real life. In this section, we discuss several applications related to industry engineering or computer science.
4.1. Application for mobile devices
FL has been paid much attention to by the researchers since the concept was first put forward by Google to predict users’ input from Gboard on Android devices. Further improvement for prediction on keyboard has been made through Chen, Mathews, Ouyang, and Beau­ fays (2019), Leroy, Coucke, Lavril, Gisselbrecht, and Dureau (2019), Hard, Rao, Mathews, Ramaswamy, Beaufays, Augenstein, and Ramage (2019) and Yang et al. (2018). Besides, emoji prediction is also a research hotspot (Ramaswamy et al., 2019). In addition, bring FL model to smart devices to predict human trajectory (Feng, Rong, Sun, Guo, & Li, 2020) or human behavior (Sozinov, Vlassov, & Girdzijauskas, 2018) is also a potential application.
Nowadays, although there is a rapid growth in storage capacity and computing power of mobile devices. It’s difficult to satisfy the growing quality demand from mobile subscribers due to communication band­ width limitation. Thus, most of comprehensive provider prefer to offer a service environment at the edge of the cellular network close to the customer instead of integrate cloud computing and cloud storage in core network so as to reduce network congestion. This technology is dubbed mobile edge computing (MEC), but it also faces increased risk of infor­ mation leakage. One possible solution is the combination of FL and MEC, Wang, X. et al. (2019) investigate an ‘In-Edge AI’ framework which combine FL based on deep reinforcement learning with MEC system and further optimize resource allocation problem. Further, Qian et al. (2019) devoted to utilizing FL on MEC. They developed a privacy-aware service placement scheme to provide high-quality service by caching desired service on the edge server close to the users.
In this case, mobile devices not only refer to common smart phones but also refer to devices in IOT settings. Smart home is one of the important applicable fields of IoT. To better learn users’ preference, devices in smart home architecture would upload some related data to cloud server which may lead to data breach. Therefore, Aïvodji, Gambs, and Martin (2019) present a sufficient secure federated architecture to build joint models. Similarly, Yu et al. (2020) build a federated multitask learning framework for smart home IOT to automatically learn users’ behavior patterns, which could effectively detect physical haz­ ards. Furthermore, Liu, Wang, Liu, and Xu (2020) proposed a data fusion approach based on FL for robots imitation learning in robot networking. This method could be leveraged on self-driving cars to generate guide models and foresee various emergencies.
4.2. Application in industrial engineering
Driven by the achievement of FL in data privacy protection, it is logical for industrial engineering to follow it with applications of FL. Since data in these areas are not available directly due to some con­ straints of laws and regulations. However, only when FL is leveraged to these areas, can we make use of these disperse dataset to acquire infinite benefits.
To the best of our knowledge, following with the rise of and matu­ ration of FL, it could have widely popularization and application pros­ pects in data-sensitive fields for industrial engineering. Take environment protection as a case in point, Hu, Gao, Liu, and Ma (2018) designed a novel environmental monitoring frame based on federated region learning FRL) for the sake of inconvenient interchangeable

Computers & Industrial Engineering 149 (2020) 106854
monitor data. Thus, monitoring data dispersed from various sensors could be utilized for superior performance of collaborative model. FL is also applied to visual inspection task (Han, Yu, & Gu, 2019). It could not only help us solve the problem of lacking defective samples to detect defects in production tasks but also offered privacy guarantees for manufacturers. In image fields, vision -and-language is also a flashpoint, Liu, Wu, Ge, Fan, and Zou (2020) bring FL to acquire diversiform rep­ resentation from federated tasks for better grounding applications. Apart from image detection and representation, FL is suitable for mali­ cious attacks detection in communication system composed by Un­ manned Aerial Vehicles (UAVs) (Mowla, Tran, Doh, & Chae, 2020). Since the features of UAVs such as unbalanced data distribution and unreliable communication conditions are quite matching with chal­ lenges in FL. With the popularization of electric vehicles, Saputra et al. (2019) designed a federated energy demand prediction method for various charging stations to prevent energy congestion in transmission process. Moreover, Yang, Zhang, Ye, Li, and Xu (2019) leveraged FL to transactions owned by different banks in order to detect credit card fraud efficiently, which is also a significant contribution to financial field. For text mining, Wang, Tong, and Shi (2020) exploit an industrial grade federated framework based on Latent Dirichlet Allocation. It has passed the assessment on real data for spam filtering and sentiment analysis.
To summarize, FL enable data owner to broaden the scope of data applications and improve model performance through iteration among different entities. In the future, FL technology would also support more industries to become more intelligent. The incorporation with FL in AI will build a federal ecosystem without data privacy concern.
4.3. Application in HealthCare
As a disruptive method to preserve data privacy, FL has great pros­ pect in health care. Each medical institute might have a lot of patient data, but that may be far from enough to train their own prediction models (Szegedi, Kiss, & Horva´th, 2019). Combination of FL and disease prediction is one of the good solutions to break down the barriers of analysis throughout different hospitals.
Electronic health records (EMR) contain lots of meaningful clinical concepts, Kim, Sun, Yu, and Jiang (2017) gave an attempt to use tensor factorization models for phenotyping analysis to obtain information concealed in health records without sharing patient-level data. It could be regarded as the first attempt for FL application in medical industry. Pfohl, Dai, and Heller (2019) explored differentially private learning for EMR in federated setting. And they further demonstrated the perfor­ mance is comparable with training in a centralized setting. Huang, Shea et al. (2019) make use of EMRs scattered across hospitals to predict mortality rate for heart disease patients. During training process, there is not any form of data or parameters transmission among hospitals’ da­ tabases. Besides this, data consolidated from multiple remote clients into a central server is encoded in advance and the decoder will be aban­ doned at the end of training. In addition, Brisimi et al. (2018) also use EMRs to evaluate whether a patient with heart disease will be hospi­ talized based on a FL algorithm called cluster Primal Dual Splitting (cPDS). This prediction work can be accomplished either on health monitoring devices or hospitals holding these medical data without in­ formation leakage. With utilization of health records, Lee et al. (2018) proposed a federated patient hashing framework to detect similar pa­ tients scattered in different hospitals without sharing patient-level in­ formation. This patient matching method could help doctors to summarize general character and direct them to treat patient with more experience. In addition, Huang, Yin et al. (2019) leveraged Loss-based adaptive boosting Federated Averaging algorithm on drug usage extracted from MIMIC-III database to predict patient mortality rate. This research concerned computation complexity and communication cost as well as accuracy for each client therefore outperform baselines.
Studies also demonstrated that FL can be applied in the domain of

9

L. Li et al.
Natural language processing (NLP) to analyze valid information from health records. Liu, Dligach, and Miller (2019) focus on need for un­ structured data processing of clinical notes. It was the first attempt of NLP based on FL. They performed a two-stage federated training model contains pre-processing stage to predict a representation model for each patient and phenotyping training stage to study each kind of illness.
Recently, FL is also widely used in the area of biomedical imaging analysis. Federated principal components analysis (fPCA) has been put forward by Silva, Gutman, Romero, Thompson, Altmann, and Lorenzi (2019) to extract features from magnetic resonance images (MRI) come from different medical centers. Furthermore, Gao et al., (2019) proposed a hierarchical heterogeneous horizontal FL (HHHFL) framework for Electroencephalography (EEG) classification to overcome the challenge of limited labeled instances as well as the privacy constraint.
To the best of our knowledge, following with the rise of and matu­ ration of FL, it could have very wide popularization and application prospects in data-sensitive fields in addition to the abovementioned fields. Table 1 shows application of FL has grown by leaps and bounds in 2019. Thus, it is optimistic that FL would have great potential in the future development. Currently, FL mainly contributes to horizontally collaborative training for landing applications, which means feature dimensions of each data are similar to each other. In the future, medical data in hospitals could be cooperated with other institutions such as insurance agent to obtain reasonable pricing. Therefore, vertically FL is a promising direction to be explored. Moreover, one problem is existing federal training mostly base on small set of organizations and is not able to extend to collaborative training for huge number of devices or in­ stitutions. Therefore, analysis of mobile devices data based on FL in an effective way should be progressed to generate more meaningful information.
5. Frontier achievements and future work
FL is in great potential with sustainable development for landing application in industrial engineering and health care. Admittedly, many scholars have done arduous efforts to tackle challenges mentioned in Section 3. To satisfy the situation with rapid development of IOT and increasing privacy concerns, it put forward rigorous demands for federated system design. Several research frontiers remain to be explored with FL. Current main trends are committed to security compliance establishment, attack defense and efficiency promotion as well as heterogeneities processing. In this section, we focus on some remarkable cutting-edge results to solve remained problems for better FL implementation in practical manufacturing application. Additionally, we also briefly introduce some promising direction to lead future improvement in this area.
5.1. Asynchronous training mode
A basic choice on global model training mode is whether to take asynchronous or synchronous method. Recently, the synchronous training has already become the major form for FL due to superior performance of SGD in the central server settings compared to asyn­ chronous way (Chen, Ning et al., 2019; Mohammad & Sorour, 2019) Prior optimization of FL mainly focusses on evolution of FedAvg in a synchronous fashion. However, this method relies on strong assumption of which is not realistic in practice. The heterogeneous resource in terms of different computation ability and various network settings and un­ balanced data distribution would result in different training time and unknown communication cost. Based on previous work on asynchro­ nous gradient descent, Sprague, Jalalirad, Scavuzzo, Capota, Neun, Do, and Kopp (2019) compared asynchronous aggregation scheme with FedAvg and obtained basically satisfactory results. Generous asynchro­ nous training mode in FL refer to asynchronous local update or asyn­ chronous aggregation. At the client side, Chen, Sun et al. (2019) designed an asynchronous approach for client model update. Layers in

Computers & Industrial Engineering 149 (2020) 106854
deep neural network are divided into deep layers and shallow layers with different update frequency. At the server side, asynchronous ag­ gregation could be implemented. For instance, asynchronous online FL framework presented by Chen, Ning et al. (2019), Chen, Sun et al. (2019) updates central model in an asynchronous way by introducing feature learning and dynamic learning step size. Considering trade-off between advantages of synchronous update and asynchronous training, Wu et al. (2019) proposed a semi-asynchronous protocol which allow straggling clients don’t always go together with central server. The main idea is that make stragglers join training properly to speed up training process with utilization of their slowly update model. Gaining a good deal of enlightenment from this semi-asynchronous method, a combination of asynchronous mode and synchronous scheme is a promising direction. In this way, can we reduce unwanted overhead and give little fault-tolerance to stragglers.
5.2. Gradient aggregation
Usually, in gradient aggregation stage, the gradient of global model is the sum of weighted gradient produced by each client. And the weight of each client is decided by the sample ratio. However, there is no evi­ dence demonstrate that this weighted averaging gradient acquired from local clients is equivalent to real global gradient information due to biased estimation in local clients. Xiao, Cheng, Stankovic, and Vuko­ bratovic (2020) detect that the mutual information is increased which implies correlation between clients, while the distance of parameters is getting greater with increased iteration. This study shows gradient averaging is possible not a good manner for gradient aggregation. To eliminate gradient bias in local training stage, Yao, Huang, Zhang, Li, and Sun (2019) keep trace of dispatched global parameters in each local training epoch. Since local gradient update is a function of global pa­ rameters, then gradients can be aggregated in an unbiased way. To better learn aggregation mode in FL, Ji, Chen, Wang, Yu, and Li (2019) introduce a recurrent neural network aggregator to automatically get an optimized way for gradient aggregation. In addition, Wang, X. et al. (2019) designed a layer-wise aggregation mode to serially generate layer parameters in neural network for global model. Considering Noniid distribution on clients, gradient aggregation in a simply averaging way isn’t a good choice. It would be better if researchers can bring in some adaptive weight for each client or some machine learning method to learn how to aggregate these gradients in an effective way.
5.3. Incentive mechanism
For performance improvement, apart from optimization of resource allocation or novel architecture design, to establish an incentive mech­ anism to encourage more parties join into the training is also an effective way. The original FedAvg would select clients randomly. It seems that all clients are equally likely to go into the training. In fact, some lazy clients with high quality or some selfish clients afraid of power con­ sumption may not attend the whole training process with a certain probability. Incentive mechanism could be established to motivate such clients. The cloud server would allocate the reward to each participant according to their contribution. And the client would maximize their utility to obtain more revenue. In this way, a benign cyclic effect would be formulated to obtain a satisfied model. The frameworks such as Stackelberg-based game theory enjoy wide popularity in motivation mechanism design. Sarikaya and Ercetin (2019) explore inventive mechanism in Stackelberg perspective to inspire workers to allocate more CPU for local training. Khan, Tran, Pandey, Saad, Han, Nguyen, and Hong (2019) discussed Stackelberg-based incentive mechanism to set local iteration times adaptively to be effective as much as possible. The crowdsourcing framework adopted two-stage stackelberg model to acquire utility maximization among clients and server (Pandey, Tran, Bennis, Tun, Manzoor, & Hong, 2019). For future work, more frame­ works like matching theory and auction theory can be introduced to

10

L. Li et al.

Computers & Industrial Engineering 149 (2020) 106854

Table 1 Application in various fields.

Researchers

Application domain

Applications in mobile devices

Chen et al., 2019

Smart phone keyboard

Leroy et al., 2019 Hard et al.2019

Smart phone voice assistant Smart phone keyboard

Yang, Andrew, Eichner, Sun, Li, Kong, Ramage, & Beaufays, 2018
Ramaswamy et al. 2019

Smart phone keyboard Smart phone keyboard

Wang, X. et al. (2019)

Mobile edge computing

Qian et al., 2019 Feng et al.2020 Sozinov et al., 2018
Aïvodji et al., 2019 Yu et al., 2020 Liu et al., 2020

Mobile edge computing
Mobile devices motion sensors Smart devices motion sensors
Smart home IOT
Smart home IOT
Robot network

Applications in industrial engineering

Hu et al., 2018

environment protection

Han et al. 2019

Image detection

Liu et al., 2020

Image representation

Mowla et al., 2020 Saputra et al., 2019

Unmanned Aerial Vehicles
Electrical vechicles

Yang et al., 2019

Financial field

Wang, Tong et al., 2020

text mining

Applications in Health Care

Brisimi et al., 2018

Predict future

hospitalizations for

patients

Silva et al.2019

MRI Analysis

Liu et al., 2019 Gao et al.2019

Extraction of clinical notes EEG Classification

Li, Cheng, Liu, Wang, & Chen, 2019
Pfohl et al., 2019 Huang, Yin et al., 2019
Kim et al., 2017

Predict mortality and hospital stay time
Clinical prediction
Mortality prediction over drug utilization data

Studies
learn out- of-vocabulary words
Learn embedded wake word detector next-word prediction in a virtual keyboard
improve virtual keyboard search suggestion quality
predict emoji from text typed on a keyboard
optimizing MEC, caching and communication
Privacy-aware service placement for mobile edge computing Privacy-preserving Human Mobility Prediction Human Activity Recognition
Design a sufficient secure federated smart home setting learn users’ behavior patterns
robots imitation learning
environmental monitoring frame based on federated region learning provide manufactures with the service in automated defect inspection obtain various types of image representations from different tasks malicious attacks detection in communication system of UAVs
federated energy demand prediction
detect credit card fraud
spam filtering and sentiment analysis
Cluster Primal Dual Splitting algorithm
Provide federated analysis framework compatible with the standard ENIGMA pipelines Two-stage federated NLP method
Design a hierarchical heterogeneous horizontal FL framework Introduce community-based FL and evaluate it on non-iid icu EMRs Establish efficacy of FL over centralized and local learning Adaptive boosting method

Pros
expanding the vocabulary of a keyboard without exporting sensitive text using an adaptive averaging strategy in place of standard weighted model averaging train an RNN model from scratch in the server and federated environments and achieve recall improvements being easily trainable given the convexity of the error function by logistic regression model achieve better performance than a server trained model
discussed the potential of inte-grating the Deep Reinforcement Learning and FL framework with the mobile edge system propose a privacy-aware ser- vice placement (PSP) scheme to meet users’ service demands Using group optimization strategy, reduce the performance degradation identifies and rejects erroneous clients
combines FL with secure data aggregation
effectively detect physical hazards
increases imitation learning efficiency of local robots in cloud robotic systems
considers the regional characteristics during the distribution of training samples to improve the inference accuracy solve the problem of lacking defective samples to detect defects
Be validated on three kinds of FL settings
enhance the model with a client group prioritization technique leveraging the Dempster–Shafer theory applied the clustering-based energy demand learning method for to further improve the prediction accuracy achieves an average of test AUC 10% higher than traditional method.
Using Random Response with Priori (RRP), which provides theoretical guarantees on both data privacy and model accuracy.
Yield classifiers using relatively few features
Deal with variability of high dimensional features efficiently
Adding pre-processing step to improve accuracy The first EEG classifier over heterogeneous EEG data
converged to higher predictive accuracy in less communication rounds than the baseline FL model Perform FL in a differentially private manner
Alleviate non-iid by introducing data-sharing technology

Constraint
Strongly relies on a learned probabilistic mode Do not show robustness to background noise Still have high communication cost
impractical to train models with a large number of parameters
client cache contents are different, and metrics cannot be compared across experiments how to distribute the huge computation load on heterogenous scenarios are still unexplored. Not able to be used for several edge clouds only consider the basic mobility model for the simplicity producing models with slightly worse, accuracy compared to centralized models rather complex architecture to implement Not flexible with mapping mechanism for diverse deployment Need to further work on convergence justification of the fusion process
Need to be extended to multi-layer structures instead of two-layer structure need quick model deployment to serve various industries
more beneficial for the smaller dataset than the larger one in horizontal FL Need to improve the reliability of the global updates in this architecture. Need to be more stable and flexible.
Should take more reliable measurements into account to protect the privacy noise from our perturbing mechanism will slightly influence the overall performance
Need more iterations for convergence
Only tested in limited dataset
Not suitable for small questionable cases Only work on 3 different datasets
Model parameters of community will lead to extra communication overhead Underestimate of privacy cost
Training on iid data outperform non-iid data
(continued on next page)

11

L. Li et al. Table 1 (continued )
Researchers
Lee et al., 2018

Computers & Industrial Engineering 149 (2020) 106854

Application domain
Analysis of computational phenotypes Similar patient matching

Studies
Federated tensor factorization for privacy preserving computational phenotyping Federated patient hashing framework

Pros
Summarized information does not disclose the patient data
Avoid security attack from reverse engineering

Constraint
Only Accurate with small or skewly distributed data
Inevitable computational complexity

cope with trade-off between number of participants and update latency.
5.4. Verification for returned model
Most privacy-preserving method in FL rely on a strong assumption that clients are semi-honest which obey training rules but keeping curious about private data acquisition. However, realistic application gets the other kind. Client may wittingly or unwittingly transmit an erroneous model compel global model to deviate from normal trace. For instance, in wearable medical system, adversaries may generate plau­ sible but not accurate data to attack the entire model (Cai & Ven­ katasubramanian, 2018). This kind of Byzantine problem is always encountered in FL. Thus, Byzantine fault-tolerant system should be developed which means even if certain clients don’t follow training protocol or be malicious to attack global model, the collaborative training can still work well.
To detect this anomalous model update, Li, Sahu, Zaheer, Sanjabi, Talwalkar, and Smith (2019) considered an autoencoder enable model parameters to be replaced by low-dimension vector as well as discover irregular weights update. Mun˜oz-Gonza´lez, Co, and Lupu (2019) dis­ cussed adaptive FL to grub abnormal updates via a Hidden Markov Model to evaluate model quality. Traditional Byzantine fault-tolerant system is supported by some defense mechanism rather than malicious client detection. Considering loss of accuracy in federated setting, it is better to design much more Byzantine fault-tolerant system based on fault detection to eliminate or reduce threats.
5.5. FL with block-chain technology
As a novel technology, block-chain is developing fast abroad. In short, Block-chain is essentially a distributed ledger, derived from Bit­ coin (Nakamoto, 2008), which is characterized by decentralization, immutability, traceability, collective maintenance, openness and trans­ parency. Several blockchain-assisted schemes for industrial data sharing have been proposed, including quality surveillance of 3D-printed arti­ cles (Kennedy et al., 2017), consumption monitoring and privacypreserving energy trading for smart grids (Aitzhan & Svetinovic, 2018) and emergency medical service for pre-hospital care (Hasavari & Song, 2019). Existing studies based on block chain mainly focus on innovate medical information sharing system but training collabora­ tively to maximize data utilization has not been implemented. Recent research has proofed that block chain has potential to significantly transform some issues in FL. Blockchain and FL are auxiliary to each other. As an inherently secure distributed system, blockchain naturally suitable for developed with FL. Since blockchain framework is tolerant with malicious node and work normally as long as malicious nodes do not exceed 51% of the total.
Injecting block-chain technology into FL, Majeed and Hong (2019) envisioned a robust Fl-chain that could verify local model update. Although the security of entire architecture can be guaranteed with block chain technology, this security has nothing to do with privacy protection. There is no privacy concern in allusion to individual node. If there is a malicious clinic or hospital join in the collaborative training, it may spare no effort to snoop other participants’ privacy information. Hence Ilias and Georgios (2019) utilized blockchain smart convention to coordinate all clients and additionally used homomorphic encryption to provide extra privacy guarantee. The blockchain-based privacy-

preserving FL framework designed by Awan, Li, Luo, and Liu (2019) also added a variation of the Paillier cryptosystem as an excess measure to forestall privacy leakage. Furthermore, take advantage of block chain, the contribution of each party to optimize global model could be traced, which make it possible for an incentive mechanism. Aforementioned FL frames based on block chain didn’t give specific rewarding mechanism for clients to join training. To improve performance for FL, a dynamic weighting method had been proposed (Kim & Hong, 2019). It consid­ ered learning accuracy and participation frequency as training weight to motivate high-quality client to get involved in the training. Besides, Block-Fl proposed by Kim, Park, Bennis, and Kim (2019) award client holding number of samples to reduce convergence time. To sum up, incorporate block chain with FL is auspicious since it is a decentralized technology thus doesn’t need central server to predict global model anymore. Therefore, it could overcome the limitation of bandwidth in FL. Further, it could not only exchange updates while verify correctness to enhance security but also employ some activate mechanism to improve FL service. But introducing blockchain may cause more latency when exchange learning model. It would be better to design a blockchain-based FL to with low latency.
5.6. Federated training for unsupervised machine learning
According to the analysis of research on FL, existing FL frameworks construct based on supervised learning method. For instance, FL have been effectively leveraged in neural network (Wang, S. et al., 2019; Hao, Li, Xu, Liu, & Yang, 2019; Bonawitz, Eichner, Grieskamp, Huba, Inger­ man, Ivanov, & Roselander, 2019) and SVM (Liu et al., 2019), as well as linear classifier (Hardy et al., 2017).
Actually, in most of cases where labeled data either do not exist, or with little existence, unsupervised learning methods are supposed to be applied. Thus, unsupervised learning is reasonable to be used to infer potential information in these messy data. For example, it has been widely used for image registration (Dalca, Balakrishnan, Guttag, & Sabuncu, 2019; de Vos et al., 2019) and image classification (Ahn, Kumar, Feng, Fulham, & Kim, 2019). Although researchers have made great progress on federated transfer learning to handle with dispersive data with few labels, the landing applications remain a bottleneck for unsupervised learning in federated framework. To tackle the challenge of limited number of labels, collaborative training has been employed in unsupervised area. Such method like Collaborative and Adversarial Network (CAN), a novel unsupervised domain adaptation approach, shows effectiveness and high performance (Zhang, Ouyang, Li, & Xu, 2018). Therefore, as a kind of collaborative training approach, FL has great potential on unsupervised learning area. Recently, van Berlo, Saeed, and Ozcelebi (2020) introduced Federated Unsupervised Repre­ sentation Learning which is a breakthrough in unsupervised FL. Through unsupervised representation learning during pre-training stage, the requirement of labeled data significantly reduced. This study also shows competitive performance compared with supervised learning and transfer learning. Therefore, it motivates future work towards the extension of federated framework on unsupervised learning.
6. Conclusion
This study contributes to conclude application in industrial engi­ neering and computer science and summarize review of FL but not

12

L. Li et al.
limited to applications. To our best knowledge, this work is the first time to summarize the development prospects of FL on industrial field. Amidst masses of literature, we have concluded characteristic of FL and remained challenges. Further, we give the main path of optimization trace to clarify various solutions that researchers have done to optimize FL mainly including privacy concerns and algorithm efficiency. Besides, we also sum up some applications in federated settings and some develop area with great potential. As a burgeoning technology, FL at­ tracts increasing attention these days. This work benefits to researchers to overcome the remained challenges of FL.
CRediT authorship contribution statement
Li Li: Conceptualization, Methodology, Software, Supervision. Yuxi Fan: Data curation, Writing - original draft. Mike Tse: Visualization, Resources. Kuo-Yi Lin: Project administration, Conceptualization, Validation, Writing - review & editing.
Acknowledgements
This research was supported by National Key R&D Program of China, No. 2018YFE0105000, 2018YFB1305304, the Shanghai Municipal Commission of science and technology No. 19511132100, and the Na­ tional Natural Science Foundation of China under Grant No. 51475334.
References
Ahn, E., Kumar, A., Feng, D., Fulham, M., & Kim, J. (2019). Unsupervised deep transfer feature learning for medical image classification. In 2019 IEEE 16th international symposium on biomedical imaging (ISBI 2019) (pp. 1915–1918). https://doi. org/10.1109/ISBI.2019.8759275.
Aitzhan, N. Z., & Svetinovic, D. (2018). Security and privacy in decentralized energy trading through multi-signatures, blockchain and anonymous messaging streams. IEEE Transactions on Dependable and Secure Computing, 15(5), 840–852. https://doi. org/10.1109/TDSC.2016.2616861.
Aïvodji, U. M., Gambs, S., & Martin, A. (2019). IOTFLA: A secured and privacypreserving smart home architecture implementing federated learning. IEEE Security and Privacy Workshops (SPW), 2019, 175–180. https://doi.org/10.1109/ SPW.2019.00041.
Awan, S., Li, F., Luo, B., & Liu, M. (2019). Poster: A reliable and accountable privacypreserving federated learning framework using the blockchain. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security - CCS ’19 (pp. 2561–2563). https://doi.org/10.1145/3319535.3363256.
Bagdasaryan, E., Veit, A., Hua, Y., Estrin, D., & Shmatikov, V. (2018). How to backdoor federated learning. ArXiv:1807.00459 [Cs]. Retrieved from http://arxiv.org/abs/1 807.00459.
Bhagoji, A. N., Chakraborty, S., Mittal, P., & Calo, S. (2019). Analyzing federated learning through an adversarial lens. Retrieved from International Conference on Machine Learning, 634–643 http://proceedings.mlr.press/v97/bhagoji19a.html.
Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., … Roselander, J. (2019). Towards federated learning at scale: System design. ArXiv: 1902.01046 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1902.01046.
Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H. B., Patel, S., … Seth, K. (2017). Practical secure aggregation for privacy preserving machine learning (No. 281). Retrieved from http://eprint.iacr.org/2017/281.
Bos, J. W., Lauter, K., & Naehrig, M. (2014). Private predictive analysis on encrypted medical data. Journal of Biomedical Informatics, 50, 234–243. https://doi.org/ 10.1016/j.jbi.2014.04.003.
Brisimi, T. S., Chen, R., Mela, T., Olshevsky, A., Paschalidis, I. C., & Shi, W. (2018). Federated learning of predictive models from federated Electronic Health Records. International Journal of Medical Informatics, 112, 59–67. https://doi.org/10.1016/j. ijmedinf.2018.01.007.
Cai, H., & Venkatasubramanian, K. K. (2018). Detecting data manipulation attacks on physiological sensor measurements in wearable medical systems. EURASIP Journal on Information Security, 2018(1), 13. https://doi.org/10.1186/s13635-018-0082-y.
Chai, Z., Fayyaz, H., Fayyaz, Z., Anwar, A., Zhou, Y., Baracaldo, N., … Cheng, Y. (2019). Towards taming the resource and data heterogeneity in federated learning. 19–21. Retrieved from https://www.usenix.org/conference/opml19/presentation/chai.
Chen, M., Mathews, R., Ouyang, T., & Beaufays, F. (2019). Federated learning of out-ofvocabulary words. ArXiv:1903.10635 [Cs]. Retrieved from http://arxiv.org/abs/1 903.10635.
Chen, Y., Luo, F., Li, T., Xiang, T., Liu, Z., & Li, J. (2020). A training-integrity privacypreserving federated learning scheme with trusted execution environment. Information Sciences, 522, 69–79. https://doi.org/10.1016/j.ins.2020.02.037.
Chen, Y., Ning, Y., & Rangwala, H. (2019). Asynchronous online federated learning for edge devices. ArXiv:1911.02134 [Cs]. Retrieved from http://arxiv.org/abs/1911 .02134.

Computers & Industrial Engineering 149 (2020) 106854
Chen, Y., Sun, X., & Jin, Y. (2019). Communication-efficient federated deep learning with asynchronous model update and temporally weighted aggregation. ArXiv: 1903.07424 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1903.07424.
Cheng, K., Fan, T., Jin, Y., Liu, Y., Chen, T., & Yang, Q. (2019). SecureBoost: A lossless federated learning framework. ArXiv:1901.08755 [Cs, Stat]. Retrieved from htt p://arxiv.org/abs/1901.08755.
Dalca, A. V., Balakrishnan, G., Guttag, J., & Sabuncu, M. R. (2019). Unsupervised learning of probabilistic diffeomorphic registration for images and surfaces. Medical Image Analysis, 57, 226–236. https://doi.org/10.1016/j.media.2019.07.006.
de Vos, B. D., Berendsen, F. F., Viergever, M. A., Sokooti, H., Staring, M., & Iˇsgum, I. (2019). A deep learning framework for unsupervised affine and deformable image registration. Medical Image Analysis, 52, 128–143. https://doi.org/10.1016/j. media.2018.11.010.
Edwards, J. (2019). Medicine on the Move: Wearable devices supply health-care providers with the data and insights necessary to diagnose medical issues and create optimal treatment plans [Special Reports]. IEEE Signal Processing Magazine, 36(6), 8–11. https://doi.org/10.1109/MSP.2019.2930767.
EU (2018). Regulation of the European Parliament and of the council on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing directive (general data protection regulation). https://eurlex.europa.eu/legal- content/EN/TXT. Accessed 26 December 2018.
Feng, J., Rong, C., Sun, F., Guo, D., & Li, Y. (2020). PMF: A privacy-preserving human mobility prediction framework via federated learning. In Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 4(1), 10:1–10:21. htt ps://doi.org/10.1145/3381006.
Gao, D., Ju, C., Wei, X., Liu, Y., Chen, T., & Yang, Q. (2019). HHHFL: Hierarchical heterogeneous horizontal federated learning for electroencephalography. ArXiv: 1909.05784 [Cs, Eess]. Retrieved from http://arxiv.org/abs/1909.05784.
Gasco´n, A., Schoppmann, P., Balle, B., Raykova, M., Doerner, J., Zahur, S., et al. (2017). Privacy-preserving distributed linear regression on high-dimensional data. Proceedings on Privacy Enhancing Technologies, 2017(4), 345–364. https://doi.org/ 10.1515/popets-2017-0053.
Geyer, R. C., Klein, T., & Nabi, M. (2018). Differentially Private Federated Learning: A Client Level Perspective. ArXiv:1712.07557 [Cs, Stat]. Retrieved from http://arxiv. org/abs/1712.07557.
Gionis, A., Indyk, P., Motwani, R., et al. (1999). Similarity search in high dimensions via hashing. Vldb, 99, 518–529.
Godinho, C., Domingos, J., Cunha, G., Santos, A. T., Fernandes, R. M., Abreu, D., et al. (2016). A systematic review of the characteristics and validity of monitoring technologies to assess Parkinson’s disease. Journal of Neuroengineering and Rehabilitation, 13, 24. https://doi.org/10.1186/s12984-016-0136-7.
Google (2019). Tensorflow federated. https://www.tensorflow.org/federated. Accessed 2019.
Han, X., Yu, H., & Gu, H. (2019). Visual inspection with federated learning. In F. Karray, A. Campilho & A. Yu (Eds.) Image analysis and recognition (pp. 52–64). https://doi. org/10.1007/978-3-030-27272-2_5.
Hao, M., Li, H., Luo, X., Xu, G., Yang, H., & Liu, S. (2019). Efficient and privacy-enhanced federated learning for industrial artificial intelligence. IEEE Transactions on Industrial Informatics, 1–1. https://doi.org/10.1109/TII.2019.2945367.
Hao, M., Li, H., Xu, G., Liu, S., & Yang, H. (2019). Towards efficient and privacypreserving federated deep learning. In ICC 2019–2019 IEEE International Conference on Communications (ICC) (pp. 1–6). https://doi.org/10.1109/ICC.2019.8761267.
Hard, A., Rao, K., Mathews, R., Ramaswamy, S., Beaufays, F., Augenstein, S., … Ramage, D. (2019). Federated learning for mobile keyboard prediction. ArXiv:1811.03604 [Cs]. Retrieved from http://arxiv.org/abs/1811.03604.
Hardy, S., Henecka, W., Ivey-Law, H., Nock, R., Patrini, G., Smith, G., & Thorne, B. (2017). Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. ArXiv:1711.10677 [Cs]. Retrieved from htt p://arxiv.org/abs/1711.10677.
Hasavari, S., & Song, Y. T. (2019). A secure and scalable data source for emergency medical care using blockchain technology. In 2019 IEEE 17th International Conference on Software Engineering Research, Management and Applications (SERA) (pp. 71–75). https://doi.org/10.1109/SERA.2019.8886792.
Ho, Q., Cipar, J., Cui, H., Lee, S., Kim, J. K., Gibbons, P. B., … Xing, E. P. (2013). More effective distributed ML via a stale synchronous parallel parameter server. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani & K. Q. Weinberger (Eds.), Advances in neural information processing systems (Vol. 26, pp. 1223–1231). Retrieved from http://papers.nips.cc/paper/4894-more-effective-distributed-ml-via-a-stale-synchr onous-parallel-parameter-server.pdf.
Holcomb, S. D., Porter, W. K., Ault, S. V., Mao, G., & Wang, J. (2018). Overview on DeepMind and Its AlphaGo Zero AI. In Proceedings of the 2018 International Conference on Big Data and Education - ICBDE ’18 (pp. 67–71). https://doi.org/1 0.1145/3206157.3206174.
Hu, B., Gao, Y., Liu, L., & Ma, H. (2018). Federated region-learning: An edge computing based framework for urban environment sensing. IEEE Global Communications Conference (GLOBECOM), 2018, 1–7. https://doi.org/10.1109/ GLOCOM.2018.8647649.
Huang, L., Shea, A. L., Qian, H., Masurkar, A., Deng, H., & Liu, D. (2019). Patient clustering improves efficiency of federated machine learning to predict mortality and hospital stay time using distributed electronic medical records. Journal of Biomedical Informatics, 99, Article 103291. https://doi.org/10.1016/j. jbi.2019.103291.
Huang, L., Yin, Y., Fu, Z., Zhang, S., Deng, H., & Liu, D. (2019). LoAdaBoost:Loss-Based AdaBoost Federated Machine Learning on medical Data. ArXiv:1811.12629 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1811.12629.

13

L. Li et al.
Ilias, C., & Georgios, S. (2019). Machine learning for all: A more robust federated learning framework. 544–551. Retrieved from http://www.scitepress.org/Digita lLibrary/Link.aspx?doi=10.5220/0007571705440551.
Ji, J., Chen, X., Wang, Q., Yu, L., & Li, P. (2019). Learning to learn gradient aggregation by gradient descent. In Proceedings of the twenty-eighth international joint conference on artificial intelligence (pp. 2614–2620).
Jiang, P., & Ying, L. (2020). An optimal stopping approach for iterative training in federated learning. In 2020 54th annual conference on information sciences and systems (CISS) (pp. 1–6). https://doi.org/10.1109/CISS48834.2020.1570616094.
Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A. N., … Zhao, S. (2019). Advances and open problems in federated learning. ArXiv:1912.04977 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1912.04977.
Kang, J., Xiong, Z., Niyato, D., Yu, H., Liang, Y.-C., & Kim, D. I. (2019). Incentive design for efficient federated learning in mobile networks: A contract theory approach. IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS), 2019, 1–5. https:// doi.org/10.1109/VTS-APWCS.2019.8851649.
Kennedy, Z. C., Stephenson, D. E., Christ, J. F., Pope, T. R., Arey, B. W., Barrett, C. A., et al. (2017). Enhanced anti-counterfeiting measures for additive manufacturing: Coupling lanthanide nanomaterial chemical signatures with blockchain technology. Journal of Materials Chemistry C, 5(37), 9570–9578. https://doi.org/10.1039/ C7TC03348F.
Khan, L. U., Tran, N. H., Pandey, S. R., Saad, W., Han, Z., Nguyen, M. N. H., & Hong, C. S. (2019). Federated learning for edge networks: resource optimization and incentive mechanism. ArXiv:1911.05642 [Cs]. Retrieved from http://arxiv.org/abs/1911 .05642.
Kharitonov, E. (2019). Federated online learning to rank with evolution strategies. WSDM, 2019, 249–257. https://doi.org/10.1145/3289600.3290968.
Kim, H., Park, J., Bennis, M., & Kim, S. -L. (2019). Blockchained on-device federated learning. ArXiv:1808.03949 [Cs, Math]. Retrieved from http://arxiv.org/abs/1 808.03949.
Kim, Y. J., & Hong, C. S. (2019). Blockchain-based node-aware dynamic weighting methods for improving federated learning performance. In 2019 20th Asia-pacific network operations and management symposium (APNOMS) (pp. 1–4).
Kim, Y., Sun, J., Yu, H., & Jiang, X. (2017). Federated tensor factorization for computational phenotyping. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 887–895). https://doi.org/ 10.1145/3097983.3098118.
Koneˇcný, J., McMahan, H. B., Yu, F. X., Richt´arik, P., Suresh, A. T., & Bacon, D. (2017). Federated learning: Strategies for improving communication efficiency. ArXiv: 1610.05492 [Cs]. Retrieved from http://arxiv.org/abs/1610.05492.
Lee, J., Sun, J., Wang, F., Wang, S., Jun, C.-H., & Jiang, X. (2018). Privacy-preserving patient similarity learning in a federated environment: development and analysis. JMIR Medical Informatics, 6(2), Article e20. https://doi.org/10.2196/ medinform.7744.
Lee, S., Lacy, M. E., Jankowich, M., Correa, A., & Wu, W.-C. (2020). Association between obesity phenotypes of insulin resistance and risk of type 2 diabetes in African Americans: The Jackson Heart Study. Journal of Clinical & Translational Endocrinology, 19, Article 100210. https://doi.org/10.1016/j.jcte.2019.100210.
Leroy, D., Coucke, A., Lavril, T., Gisselbrecht, T., & Dureau, J. (2019). Federated learning for keyword spotting. In ICASSP 2019–2019 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 6341–6345). https://doi.org/10.1109/ ICASSP.2019.8683546.
Li, H., & Han, T. (2019). An end-to-end encrypted neural network for gradient updates transmission in federated learning. Data Compression Conference (DCC), 2019, 589. https://doi.org/10.1109/DCC.2019.00101.
Li, L., Wang, Y., & Lin, K. (2020). Preventive maintenance scheduling optimization based on opportunistic production-maintenance synchronization. Journal of Intelligent Manufacturing. https://doi.org/10.1007/s10845-020-01588-9.
Li, S., Cheng, Y., Liu, Y., Wang, W., & Chen, T. (2019). Abnormal Client Behavior Detection in Federated Learning. ArXiv:1910.09933 [Cs, Stat]. Retrieved from htt p://arxiv.org/abs/1910.09933.
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., & Smith, V. (2019). Federated optimization in heterogeneous networks. ArXiv:1812.06127 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1812.06127.
Li, T., Sanjabi, M., Beirami, A., & Smith, V. (2020). Fair resource allocation in federated learning. ICLR 2020-international conference on learning representations.
Li, X., Huang, K., Yang, W., Wang, S., & Zhang, Z. (2019). On the Convergence of FedAvg on Non-IID Data. In Presented at the international conference on learning representations. Retrieved from https://openreview.net/forum?id=HJxNAnVtDS.
Lin, K. (2018). User experience-based product design for smart production to empower industry 4.0 in the glass recycling circular economy. Computers & Industrial Engineering, 125, 729–738.
Liu, D., Dligach, D., & Miller, T. (2019). Two-stage federated phenotyping and patient representation learning. In Proceedings of the 18th BioNLP Workshop and Shared Task (pp. 283–291).
Liu, B., Wang, L., Liu, M., & Xu, C.-Z. (2020). Federated imitation learning: a novel framework for cloud robotic systems with heterogeneous sensor data. IEEE Robotics and Automation Letters, 5(2), 3509–3516. https://doi.org/10.1109/ LRA.2020.2976321.
Liu, F., Wu, X., Ge, S., Fan, W., & Zou, Y. (2020). Federated learning for vision-andlanguage grounding problems. In AAAI 2020-the thirty-fourth AAAI conference on artificial intelligence (pp. 11572–11579).
Liu, W., Chen, L., Chen, Y., & Zhang, W. (2020). Accelerating federated learning via momentum gradient descent. IEEE Transactions on Parallel and Distributed Systems, 31 (8), 1754–1766. https://doi.org/10.1109/TPDS.2020.2975189.

Computers & Industrial Engineering 149 (2020) 106854
Liu, Y., Chen, T., & Yang, Q. (2018). Secure federated transfer learning. ArXiv: 1812.03337 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1812.03337.
Liu, Z., Li, T., Smith, V., & Sekar, V. (2019). Enhancing the privacy of federated learning with sketching. ArXiv:1911.01812 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1 911.01812.
Ma, C., Li, J., Ding, M., Yang, H. H., Shu, F., Quek, T. Q. S., & Poor, H. V. (2019). On Safeguarding privacy and security in the framework of federated learning. ArXiv: 1909.06512 [Cs]. Retrieved from http://arxiv.org/abs/1909.06512.
Majeed, U., & Hong, C. S. (2019). FLchain: Federated Learning via MEC-enabled Blockchain Network. In 2019 20th Asia-pacific network operations and management symposium (APNOMS) (pp. 1–4).
McMahan, B., Moore, E., Ramage, D., Hampson, S., & Arcas, B. A. Y. (2017). Communication-efficient learning of deep networks from decentralized data. Retrieved from Artificial Intelligence and Statistics, 1273–1282 http://proceedings. mlr.press/v54/mcmahan17a.html.
McMahan, H. B., Zhang, L., Ramage, D., & Talwar, K. (2018). Learning differentially private recurrent language models. ICLR 2018.
Mohammad, U., & Sorour, S. (2019). Adaptive task allocation for asynchronous federated mobile edge learning. ArXiv:1905.01656 [Cs]. Retrieved from http://arxiv .org/abs/1905.01656.
Mohri, M., Sivek, G., & Suresh, A. T. (2019). Agnostic federated learning. Retrieved from International Conference on Machine Learning, 4615–4625 http://proceedings.mlr.pr ess/v97/mohri19a.html.
Mowla, N. I., Tran, N. H., Doh, I., & Chae, K. (2020). Federated learning-based cognitive detection of jamming attack in flying Ad-Hoc network. IEEE Access, 8, 4338–4350. https://doi.org/10.1109/ACCESS.2019.2962873.
Mun˜oz-Gonz´alez, L., Co, K. T., & Lupu, E. C. (2019). Byzantine-robust federated machine learning through adaptive model averaging. ArXiv:1909.05125 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1909.05125.
Nakamoto, S. (2008). Bitcoin: A peer-to-peer electronic cash system. https://bitcoin. org/bitcoin.pdf.
Nasr, M., Shokri, R., & Houmansadr, A. (2019). Comprehensive privacy analysis of deep learning: passive and active white-box inference attacks against centralized and federated learning. IEEE Symposium on Security and Privacy (SP), 2019, 739–753. https://doi.org/10.1109/SP.2019.00065.
Nishio, T., & Yonetani, R. (2019). Client Selection for federated learning with heterogeneous resources in mobile edge. In ICC 2019–2019 IEEE international conference on communications (ICC) (pp. 1–7). https://doi.org/10.1109/ ICC.2019.8761315.
Nock, R., Hardy, S., Henecka, W., Ivey-Law, H., Patrini, G., Smith, G., & Thorne, B. (2018). Entity resolution and federated learning get a federated resolution. ArXiv: 1803.04035 [Cs]. Retrieved from http://arxiv.org/abs/1803.04035.
Pan, S., Ni, X., Sun, J.-T., Yang, Q., & Chen, Z. (2010). Cross-domain sentiment classification via spectral feature alignment. 751–760. https://doi.org/10.1145/1 772690.1772767.
Pandey, S. R., Tran, N. H., Bennis, M., Tun, Y. K., Manzoor, A., & Hong, C. S. (2019). A Crowdsourcing framework for on-device federated learning. ArXiv:1911.01046 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1911.01046.
Pfohl, S. R., Dai, A. M., & Heller, K. (2019). Federated and differentially private learning for electronic health records. ArXiv:1911.05861 [Cs, Stat]. Retrieved from htt p://arxiv.org/abs/1911.05861.
Qian, Y., Hu, L., Chen, J., Guan, X., Hassan, M. M., & Alelaiwi, A. (2019). Privacy-aware service placement for mobile edge computing via federated learning. Information Sciences, 505, 562–570. https://doi.org/10.1016/j.ins.2019.07.069.
Ramaswamy, S., Mathews, R., Rao, K., & Beaufays, F. (2019). Federated learning for emoji prediction in a mobile keyboard. ArXiv:1906.04329 [Cs]. Retrieved from htt p://arxiv.org/abs/1906.04329.
Saputra, Y. M., Hoang, D. T., Nguyen, D. N., Dutkiewicz, E., Mueck, M. D., & Srikanteswara, S. (2019). Energy demand prediction with federated learning for electric vehicle networks. IEEE Global Communications Conference (GLOBECOM), 2019, 1–6. https://doi.org/10.1109/GLOBECOM38437.2019.9013587.
Sarikaya, Y., & Ercetin, O. (2019). Motivating workers in federated learning: A stackelberg game perspective. ArXiv:1908.03092 [Cs]. Retrieved from http://arxiv. org/abs/1908.03092.
Sharma, S., Chaoping, X., Liu, Y., & Kang, Y. (2019). Secure and efficient federated transfer learning. ArXiv:1910.13271 [Cs]. Retrieved from http://arxiv.org/abs/191 0.13271.
Silva, S., Gutman, B. A., Romero, E., Thompson, P. M., Altmann, A., & Lorenzi, M. (2019). Federated learning in distributed medical databases: meta-analysis of largescale subcortical brain data. In 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019) (pp. 270–274). https://doi.org/10.1109/ISBI.2019. 8759317.
Smith, V., Chiang, C.-K., Sanjabi, M, & Talwalkar, A. S. (2017). Federated multi-task learning. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan & R. Garnett (Eds.), Advances in neural information processing systems (Vol. 30, pp. 4424–4434). Retrieved from http://papers.nips.cc/paper/ 7029-federated-multi-task-learning.pdf.
Sozinov, K., Vlassov, V., & Girdzijauskas, S. (2018). Human activity recognition using federated learning. In 2018 IEEE Intl Conf on Parallel Distributed Processing with Applications, Ubiquitous Computing Communications, Big Data Cloud Computing, Social Computing Networking, Sustainable Computing Communications (ISPA/ IUCC/BDCloud/SocialCom/SustainCom) (pp. 1103–1111). https://doi.org/10.1109 /BDCloud.2018.00164.
Sprague, M. R., Jalalirad, A., Scavuzzo, M., Capota, C., Neun, M., Do, L., & Kopp, M. (2019). Asynchronous federated learning for geospatial applications. In A. Monreale, C. Alzate, M. Kamp, Y. Krishnamurthy, D. Paurat, M. Sayed-Mouchaweh, … R. P.

14

L. Li et al.
Ribeiro (Eds.), ECML PKDD 2018 Workshops (pp. 21–28). https://doi.org/10.1007/ 978-3-030-14880-5_2. Szegedi, G., Kiss, P., & Horv´ath, T. (2019). Evolutionary federated learning on EEG-data. In ITAT 2019-Information technologies – Applications and Theory (pp. 71–78). Tran, N. H., Bao, W., Zomaya, A., N.H, N. M., & Hong, C. S. (2019). Federated learning over wireless networks: Optimization model design and analysis. In IEEE INFOCOM 2019 - IEEE Conference on Computer Communications (pp. 1387–1395). https ://doi.org/10.1109/INFOCOM.2019.8737464. Truex, S., Baracaldo, N., Anwar, A., Steinke, T., Ludwig, H., Zhang, R., et al. (2019). A hybrid approach to privacy-preserving federated learning. In Proceedings of the 12th ACM workshop on artificial intelligence and security (pp. 1–11). https://doi.org/ 10.1145/3338501.3357370. van Berlo, B., Saeed, A., & Ozcelebi, T. (2020). Towards federated unsupervised representation learning. In Proceedings of the third ACM international workshop on edge systems, analytics and networking (pp. 31–36). https://doi.org/10.1145/ 3378679.3394530. Wang, X., Han, Y., Wang, C., Zhao, Q., Chen, X., & Chen, M. (2019). In-edge AI: Intelligentizing mobile edge computing, caching and communication by federated learning. IEEE Network, 33(5), 156–165. https://doi.org/10.1109/ MNET.2019.1800286. Wang, Z., Song, M., Zhang, Z., Song, Y., Wang, Q., & Qi, H. (2019). Beyond inferring class representatives: user-level privacy leakage from federated learning. IEEE INFOCOM 2019 - IEEE Conference on Computer Communications, 2512–2520. https://doi.org/ 10.1109/INFOCOM.2019.8737416. Wang, S., Tuor, T., Salonidis, T., Leung, K. K., Makaya, C., He, T., & Chan, K. (2019). Adaptive federated learning in resource constrained edge computing systems. IEEE Journal on Selected Areas in Communications, 37(6), 1205–1221. https://doi.org/ 10.1109/JSAC.2019.2904348. Wang, Y., Tong, Y., & Shi, D. (2020). Federated latent dirichlet allocation: A local differential privacy based framework. AAAI 2020- AAAI Conference on Artificial Intelligence, 2020, 6283–6290. Webank (2019a). Federated AI Technology Enabler. (FATE). https://github.com/weban kfintech/fate Accessed 2019. Webank (2019b). FedAI ecosystem. https://cn.fedai.org/cases/.2019, Accessed 2019. Wu, W., He, L., Lin, W., RuiMao, & Jarvis, S. (2019). SAFA: A semi-asynchronous protocol for fast federated learning with low overhead. ArXiv:1910.01355 [Cs]. Retrieved from http://arxiv.org/abs/1910.01355. Xiao, P., Cheng, S., Stankovic, V., & Vukobratovic, D. (2020). Averaging is probably not the optimum way of aggregating parameters in federated learning. Entropy, 22(3), 314. https://doi.org/10.3390/e22030314. Xu, G., Li, H., Liu, S., Yang, K., & Lin, X. (2020). VerifyNet: Secure and verifiable federated learning. IEEE Transactions on Information Forensics and Security, 15, 911–926. https://doi.org/10.1109/TIFS.2019.2929409. Xu, R., Baracaldo, N., Zhou, Y., Anwar, A., & Ludwig, H. (2019). HybridAlpha: An efficient approach for privacy-preserving federated learning. In Proceedings of the

Computers & Industrial Engineering 149 (2020) 106854
12th ACM workshop on artificial intelligence and security (pp. 13–23). https://doi.org/ 10.1145/3338501.3357371. Yang, Q., Liu, Y., Chen, T., & Tong, Y. (2019). Federated machine learning: concept and applications. ACM Transactions on Intelligent Systems and Technology, 10(2), 1–19. https://doi.org/10.1145/3298981. Yang, Q., Liu, Y., Cheng, Y., Kang, Y., Chen, T., & Yu, H. (2019). DBA: Distributed. Synthesis Lectures on Artificial Intelligence and Machine Learning, 13(3), 1–207. https:// doi.org/10.2200/S00960ED2V01Y201910AIM043. Yang, T., Andrew, G., Eichner, H., Sun, H., Li, W., Kong, N., … Beaufays, F. (2018). Applied federated learning: Improving google keyboard query suggestions. ArXiv: 1812.02903 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1812.02903. Yang, W., Zhang, Y., Ye, K., Li, L., & Xu, C.-Z. (2019). FFD: A federated learning based method for credit card fraud detection. In K. Chen, S. Seshadri & L. -J. Zhang (Eds.), Big Data – BigData 2019 (pp. 18–32). https://doi.org/10.1007/978-3-030-235512_2. Yao, X., Huang, C., & Sun, L. (2018). Two-stream federated learning: Reduce the communication costs. IEEE Visual Communications and Image Processing (VCIP), 2018, 1–4. https://doi.org/10.1109/VCIP.2018.8698609. Yao, X., Huang, T., Zhang, R.-X., Li, R., & Sun, L. (2019). Federated learning with unbiased gradient aggregation and controllable meta updating. ArXiv:1910.08234 [Cs, Stat]. Retrieved from http://arxiv.org/abs/1910.08234. Yu, T., Li, T., Sun, Y., Nanda, S., Smith, V., Sekar, V., et al. (2020). Learning contextaware policies from multiple smart homes via federated multi-task learning. IEEE/ ACM Fifth International Conference on Internet-of-Things Design and Implementation (IoTDI), 2020, 104–115. https://doi.org/10.1109/IoTDI49375.2020.00017. Yurochkin, M., Agarwal, M., Ghosh, S., Greenewald, K., Hoang, N., & Khazaeni, Y. (2019). Bayesian nonparametric federated learning of neural networks. Retrieved from International Conference on Machine Learning, 7252–7261 http://proceedings.ml r.press/v97/yurochkin19a.html. Zhang, J., Chen, J., Wu, D., Chen, B., & Yu, S. (2019). Poisoning attack in federated learning using generative adversarial nets. In 2019 18th IEEE International Conference on Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE) (pp. 374–380). https://doi.org/10.1109/TrustCom/BigDataSE.2019.00057. Zhang, W., Ouyang, W., Li, W., & Xu, D. (2018). Collaborative and adversarial network for unsupervised domain adaptation (pp. 3801–3809). Retrieved from http://op enaccess.thecvf.com/content_cvpr_2018/html/Zhang_Collaborative_and_Adversari al_CVPR_2018_paper.html. Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., & Chandra, V. (2018). Federated learning with non-IID data. ArXiv:1806.00582 [Cs, Stat]. Retrieved from http://arxiv. org/abs/1806.00582. Zhu, H., & Jin, Y. (2019). Multi-objective evolutionary federated learning. IEEE Transactions on Neural Networks and Learning Systems, 1–13. https://doi.org/ 10.1109/TNNLS.2019.2919699.

15

