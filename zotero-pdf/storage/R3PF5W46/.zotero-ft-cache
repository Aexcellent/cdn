CrypTFlow2: Practical 2-Party Secure Inference

arXiv:2010.06457v1 [cs.CR] 13 Oct 2020

Deevashwer Rathee
Microsoft Research t-dee@microsoft.com

Mayank Rathee
Microsoft Research t-may@microsoft.com

Nishant Kumar
Microsoft Research nishant.kr10@gmail.com

Nishanth Chandran
Microsoft Research nichandr@microsoft.com

Divya Gupta
Microsoft Research divya.gupta@microsoft.com

Aseem Rastogi
Microsoft Research aseemr@microsoft.com

Rahul Sharma
Microsoft Research rahsha@microsoft.com

ABSTRACT
We present CrypTFlow2, a cryptographic framework for secure inference over realistic Deep Neural Networks (DNNs) using secure 2-party computation. CrypTFlow2 protocols are both correct â€“ i.e., their outputs are bitwise equivalent to the cleartext execution â€“ and efficient â€“ they outperform the state-of-the-art protocols in both latency and scale. At the core of CrypTFlow2, we have new 2PC protocols for secure comparison and division, designed carefully to balance round and communication complexity for secure inference tasks. Using CrypTFlow2, we present the first secure inference over ImageNet-scale DNNs like ResNet50 and DenseNet121. These DNNs are at least an order of magnitude larger than those considered in the prior work of 2-party DNN inference. Even on the benchmarks considered by prior work, CrypTFlow2 requires an order of magnitude less communication and 20Ã—-30Ã— less time than the state-of-the-art.
KEYWORDS
Privacy-preserving inference; deep neural networks; secure twoparty computation

Secure inference is an instance of secure 2-party computation (2PC) and cryptographically secure general protocols for 2PC have been known for decades [32, 64]. However, secure inference for practical ML tasks, e.g., ImageNet scale prediction [24], is challenging for two reasons: a) realistic DNNs use ReLU activations1 that are expensive to compute securely; and b) preserving inference accuracy requires a faithful implementation of secure fixed-point arithmetic. All prior works [6, 31, 43, 48, 49, 51] fail to provide efficient implementation of ReLUs. Although ReLUs can be replaced with approximations that are more tractable for 2PC [22, 31, 49], this approach results in significant accuracy losses that can degrade user experience. The only known approaches to evaluate ReLUs efficiently require sacrificing security by making the untenable assumption that a non-colluding third party takes part in the protocol [7, 45, 50, 57, 62] or by leaking activations [12]. Moreover, some prior works [45, 49â€“51, 62] even sacrifice correctness of their fixedpoint implementations and the result of their secure execution can sometimes diverge from the expected result, i.e. cleartext execution, in random and unpredictable ways. Thus, correct and efficient 2PC protocols for secure inference over realistic DNNs remain elusive.

1.1 Our Contributions

1 INTRODUCTION
The problem of privacy preserving machine learning has become increasingly important. Recently, there have been many works that have made rapid strides towards realizing secure inference [4, 6, 13, 17, 19, 22, 31, 43, 48, 49, 51, 56, 58]. Consider a server that holds the weights ğ‘¤ of a publicly known deep neural network (DNN), ğ¹ , that has been trained on private data. A client holds a private input ğ‘¥; in a standard machine learning (ML) inference task, the goal is for the client to learn the prediction ğ¹ (ğ‘¥, ğ‘¤) of the serverâ€™s model on the input ğ‘¥. In secure inference, the inference is performed with the guarantee that the server learns nothing about ğ‘¥ and the client learns nothing about the serverâ€™s model ğ‘¤ beyond what can be deduced from ğ¹ (ğ‘¥, ğ‘¤) and ğ‘¥.
A solution for secure inference that scales to practical ML tasks would open a plethora of applications based on MLaaS (ML as a Service). Users can obtain value from ML services without worrying about the loss of their private data, while model owners can effectively monetize their services with no fear of breaches of client data (they never observe private client data in the clear). Perhaps the most important emerging applications for secure inference are in healthcare where prior work [4, 45, 56] has explored secure inference services for privacy preserving medical diagnosis of chest diseases, diabetic retinopathy, malaria, and so on.

In this work, we address the above two challenges and build new semi-honest secure 2-party cryptographic protocols for secure computation of DNN inference. Our new efficient protocols enable the first secure implementations of ImageNet scale inference that complete in under a minute! We make three main contributions:
First, we give new protocols for millionairesâ€™ and DReLU2 that enable us to securely and efficiently evaluate the non-linear layers of DNNs such as ReLU, Maxpool and Argmax. Second, we provide new protocols for division. Together with new theorems that we prove on fixed-point arithmetic over shares, we show how to evaluate linear layers, such as convolutions, average pool and fully connected layers, faithfully. Finally, by providing protocols that can work on a variety of input domains, we build a system3 CrypTFlow2 that supports two different types of Secure and Correct Inference (SCI) protocols where linear layers can be evaluated using either homomorphic encryption (SCIHE) or through oblivious transfer (SCIOT).
We now provide more details of our main contributions.
1ReLU(ğ‘¥) is defined as max(ğ‘¥, 0). 2DReLU is the derivative of ReLU, i.e., DReLU(ğ‘¥) is 1 if ğ‘¥ â‰¥ 0 and 0 otherwise. 3Implementation is available at https://github.com/mpc-msri/EzPC.

1

New millionairesâ€™ and DReLU protocols. Our first main technical contribution is a novel protocol for the well-known millionairesâ€™ problem [64], where parties ğ‘ƒ0 and ğ‘ƒ1 hold â„“âˆ’bit integers ğ‘¥ and ğ‘¦, respectively, and want to securely compute ğ‘¥ < ğ‘¦ (or, secret shares of ğ‘¥ < ğ‘¦). The theoretical communication complexity of our protocol is â‰ˆ 3Ã— better than the most communication efficient prior millionairesâ€™ protocol [21, 29, 32, 63, 64]. In terms of round complexity, our protocol executes in log â„“ rounds (e.g. 5 rounds for â„“ = 32 bits); see Table 1 for a detailed comparison and [21] for a detailed overview of the costs of other comparison protocols.
Using our protocol for millionairesâ€™ problem, we build new and efficient protocols for computing DReLU for both â„“âˆ’bit integers (i.e., Zğ¿, ğ¿ = 2â„“ ) and general rings Zğ‘›. Our protocol for DReLU serves as one of the main building blocks for non-linear activations such as ReLU and Maxpool, as well as division over both input domains. Providing support for â„“âˆ’bit integers Zğ¿ as well as arbitrary rings Zğ‘›, allows us to securely evaluate the linear layers (such as matrix multiplication and convolutions) using the approaches of Oblivious Transfer (OT) [8, 51] as well as Homomorphic Encryption (HE) [30, 43, 49], respectively. This provides our protocols great flexibility when executing over different network configurations. Since all prior work [43, 48, 49, 51] for securely computing these activations rely on Yaoâ€™s garbled circuits [64], our protocols are much more efficient in both settings. Asymptotically, our ReLU protocol over Zğ¿ and Zğ‘› communicate â‰ˆ 8Ã— and â‰ˆ 12Ã— less bits than prior works [43, 48, 49, 51, 63, 64] (see Table 2 for a detailed comparison). Experimentally, our protocols are at least an order of magnitude more performant than prior protocols when computing ReLU activations at the scale of ML applications.
Fixed-point arithmetic. The ML models used by all prior works on secure inference are expressed using fixed-point arithmetic; such models can be obtained from [39, 42, 45, 52]. A faithful implementation of fixed-point arithmetic is quintessential to ensure that the secure computation is correct, i.e., it is equivalent to the cleartext computation for all possible inputs. Given a secure inference task ğ¹ (ğ‘¥, ğ‘¤), some prior works [45, 49â€“51, 62] give up on correctness when implementing division operations and instead compute an approximation ğ¹ â€²(ğ‘¥, ğ‘¤). In fixed-point arithmetic, each multiplication requires a division by a power-of-2 and multiplications are used pervasively in linear-layers of DNNs. Moreover, layers like average-pool require division for computing means. Loss in correctness is worrisome as the errors can accumulate and ğ¹ â€²(ğ‘¥, ğ‘¤) can be arbitrarily far from ğ¹ (ğ‘¥, ğ‘¤). Recent work [49] has shown that even in practice the approximations can lead to significant losses in classification accuracy.
As our next contribution, we provide novel protocols to compute division by power-of-2 as well as division by arbitrary integers that are both correct and efficient. The inputs to these protocols can be encoded over both â„“âˆ’bit integers Zğ¿ as well as Zğ‘›, for arbitrary ğ‘›. To the best of our knowledge, the only known approach to compute division correctly is via garbled circuits which we compare with in Table 3. While garbled circuits based protocols require communication which is quadratic in â„“ or log ğ‘›, our protocols are asymptotically better and incur only linear communication. Concretely, for average pool with 7 Ã— 7 filters and 32-bit integers, our protocols have â‰ˆ 54Ã— less communication.

Scaling to practical DNNs. These efficient protocols, help us securely evaluate practical DNNs like SqueezeNet on ImageNet scale classification tasks in under a minute. In sharp contrast, all prior works on secure 2-party inference ([4, 6, 13, 17, 19, 22, 31, 43, 48, 49, 51, 56, 58]) has been limited to small DNNs on tiny datasets like MNIST and CIFAR. While MNIST deals with the task of classifying black and white handwritten digits given as 28 Ã— 28 images into the classes 0 to 9, ImageNet tasks are much more complex: typically 224 Ã— 224 colored images need to be classified into thousand classes (e.g., agaric, gyromitra, ptarmigan, etc.) that even humans can find challenging . Additionally, our work is the first to securely evaluate practical convolutional neural networks (CNNs) like ResNet50 and DenseNet121; these DNNs are at least an order of magnitude larger than the DNNs considered in prior work, provide over 90% Top-5 accuracy on ImageNet, and have also been shown to predict lung diseases from chest X-ray images [45, 66]. Thus, our work provides the first implementations of practical ML inference tasks running securely. Even on the smaller CIFAR scale DNNs, our protocols require an order of magnitude less communication and 20Ã—-30Ã— less time than the state-of-the-art [49] (see Section 7.2).
OT vs HE. Through our evaluation, we also resolve the OT vs HE conundrum: although the initial works on secure inference [48, 51] used OT-based protocols for evaluating convolutions, the state-ofthe-art protocols [43, 49], which currently provide the best published inference latency, use HE-based convolutions. HE-based secure inference has much less communication than OT but HE requires more computation. Hence, at the onset of this work, it was not clear to us whether HE-based convolutions would provide us the best latency for ImageNet-scale benchmarks.
To resolve this empirical question, we implement two classes of protocols, SCIOT and SCIHE, in CrypTFlow2. In SCIOT, inputs are in Zğ¿ (ğ¿ = 2â„“ , for a suitable choice of â„“). Linear layers such as matrix multiplication and convolution are performed using OT-based techniques [8, 51], while the activations such as ReLU, Maxpool and Avgpool are implemented using our new protocols over Zğ¿. In SCIHE, inputs are encoded in an appropriate prime field Zğ‘› (similar to [43, 49]). Here, we compute linear layers using homomorphic encryption and the activations using our protocols over Zğ‘›. In both SCIOT and SCIHE faithful divisions after linear layers are performed using our new protocols over corresponding rings. Next, we evaluate ImageNet-scale inference tasks with both SCIOT and SCIHE . We observe that in a WAN setting, where communication is a bottleneck, HE-based inference is always faster and in a LAN setting OT and HE are incomparable.
1.2 Our Techniques
Millionairesâ€™. Our protocol for securely computing the millionairesâ€™ problem (the bit ğ‘¥ < ğ‘¦) is based on the following observation (first made in [29]). Let ğ‘¥ = ğ‘¥1||ğ‘¥0 and ğ‘¦ = ğ‘¦1||ğ‘¦0 (where || denotes concatenation and ğ‘¥1, ğ‘¦1 are strings of the same length). Then,
4Here we state the communication numbers for GMW [32] for a depth-optimized circuit. The circuit that would give the best communication would still have a complexity of > 2ğœ†â„“ and would additionally pay an inordinate cost in terms of rounds, namely â„“. 5Couteau [21] presented multiple protocols; we pick the one that has the best communication complexity.

2

Layer

Protocol

Comm. (bits) Rounds

Millionairesâ€™ on {0, 1}â„“

GC [63, 64] GMW4/GSV [29, 32]
SC35[21]
This work (ğ‘š = 4)

4ğœ†â„“ â‰ˆ 6ğœ†â„“ > 3ğœ†â„“ < ğœ†â„“ + 14â„“

2
log â„“ + 3 â‰ˆ 4 logâˆ— ğœ†
log â„“

GC [63, 64]

16384

2

Millionairesâ€™ GMW/GSV [29, 32]

23140

8

example

SC3 [21]

13016

15

â„“ = 32

This work (ğ‘š = 7)

2930

5

This work (ğ‘š = 4)

3844

5

Table 1: Comparison of communication with prior work for

millionairesâ€™ problem. For our protocol, ğ‘š is a parameter. For concrete bits of communication we use ğœ† = 128.

OT protocols for leaf comparisons and equality, multiple 1-outof-2ğ‘š OT instances can be combined to reduce communication. Next, recursing up from the leaves to the root, requires securely computing the AND functionality6 that uses Beaver bit triples [8]. We observe that the same secret value is used in 2 AND instances. Hence, we construct correlated pairs of bit triples using 1-out-of-8 OT protocols [44] to reduce this cost to ğœ† + 8 bits (amortized) per triple, where ğœ† is the security parameter and typically 128. Some more work is needed for the above technique to work efficiently for the general case when ğ‘š does not divide â„“ or â„“/ğ‘š is not a power of 2. Finally, by picking ğ‘š appropriately, we obtain a protocol for millionairesâ€™ whose concrete communication (in bits) is nearly 5 times better than prior work.

Layer

Protocol

Comm. (bits) Rounds

ReLU for
Z2â„“ ReLU for general Zğ‘›
ReLU for Z2â„“ , â„“ = 32 ReLU for Zğ‘›, ğœ‚ = 32

GC [63, 64] This work GC [63, 64] This work
GC [63, 64] This work GC [63, 64] This work

8ğœ†â„“ âˆ’ 4ğœ†

< ğœ†â„“ + 18â„“

18ğœ†ğœ‚ âˆ’ 6ğœ†

<

3 2

ğœ†

(ğœ‚

+ 1)

+ 31ğœ‚

32256

3298

72960

5288

2 log â„“ + 2
2 log ğœ‚ + 4
2 7 2 9

Table 2: Comparison of communication with garbled cir-
cuits for ReLU. We define ğœ‚ = âŒˆlog ğ‘›âŒ‰. For concrete bits of communication we use ğœ† = 128.

Layer

Protocol

Comm. (bits)

Rounds

Avgpoolğ‘‘
Z2â„“ Avgpoolğ‘‘
Zğ‘›
Avgpool49 Z2â„“ , â„“ = 32 Avgpool49 Zğ‘›, ğœ‚ = 32

GC [63, 64] This work GC [63, 64] This work
GC [63, 64] This work GC [63, 64] This work

2ğœ†(â„“2 + 5â„“ âˆ’ 3)

< (ğœ† + 21) Â· (â„“ + 3ğ›¿)

2ğœ†(ğœ‚2 + 9ğœ‚ âˆ’ 3)

<

(

3 2

ğœ†

+

34)

Â·

(ğœ‚

+

2ğ›¿ )

302336

5570

335104

7796

2 log(â„“ğ›¿) + 4
2 log(ğœ‚ğ›¿) + 6
2 10 2 14

Table 3: Comparison of communication with garbled cir-
cuits for Avgpoolğ‘‘ . We define ğœ‚ = âŒˆlog ğ‘›âŒ‰ and ğ›¿ = âŒˆlog(6 Â· ğ‘‘)âŒ‰. For concrete bits of communication we use ğœ† = 128. Choice of ğ‘‘ = 49 corresponds to average pool filter of size 7 Ã— 7.

ğ‘¥ < ğ‘¦ is the same as checking if either ğ‘¥1 < ğ‘¦1 or ğ‘¥1 = ğ‘¦1 and ğ‘¥0 < ğ‘¦0. Now, the original problem is reduced to computing two millionairesâ€™ instances over smaller length strings (ğ‘¥1 < ğ‘¦1 and ğ‘¥0 < ğ‘¦0) and one equality test (ğ‘¥1 = ğ‘¦1). By continuing recursively, one could build a tree all the way where the leaves are individual bits, at which point one could use 1-out-of-2 OT-based protocols to perform the comparison/equality. However, the communication complexity of this protocol is still quite large. We make several important modifications to this approach. First, we modify the tree so that the recursion is done log(â„“/ğ‘š) times to obtain leaves with strings of size ğ‘š, for a parameter ğ‘š. We then use 1-out-of-2ğ‘š OT to compute the comparison/equality at the leaves, employing the lookup-table based approach of [25]. Second, we observe that by carefully setting up the receiverâ€™s and senderâ€™s messages in the

DReLU. Let ğ‘ be additively secret shared as ğ‘0, ğ‘1 over the appropriate ring. DReLU(ğ‘) is 1 if ğ‘ â‰¥ 0 and 0 otherwise; note that ğ‘ â‰¥ 0 is defined differently for â„“âˆ’bit integers and general rings. Over Zğ¿, where values are encoded using 2â€™s complement notation, DReLU(ğ‘) = 1 âŠ• MSB(ğ‘), where MSB(ğ‘) is the most significant bit of ğ‘. Moreover, MSB(ğ‘) = MSB(ğ‘0) âŠ• MSB(ğ‘1) âŠ• carry. Here, carry = 1 if ğ‘0â€² + ğ‘1â€² â‰¥ 2â„“âˆ’1, where ğ‘0â€², ğ‘1â€² denotes the integer represented by the lower â„“ âˆ’ 1 bits of ğ‘0, ğ‘1. We compute this carry bit using a call to our millionairesâ€™ protocol. Over Zğ‘›, DReLU(ğ‘) = 1 if ğ‘ âˆˆ [0, âŒˆğ‘›/2âŒ‰). Given the secret shares ğ‘0, ğ‘1, this is equivalent to (ğ‘0 + ğ‘1) âˆˆ [0, âŒˆğ‘›/2âŒ‰) âˆª [ğ‘›, âŒˆ3ğ‘›/2âŒ‰) over integers. While this can be naÃ¯vely computed by making 3 calls to the millionairesâ€™ protocol, we show that by carefully selecting the inputs to the millionairesâ€™ protocol, one can do this with only 2 calls. Finally, we set things up so that the two calls to millionairesâ€™ have correlated inputs that reduces the overall cost to â‰ˆ 1.5 instances of millionairesâ€™ over Zğ‘›.
Division and Truncation. As a technical result, we provide a correct decomposition of division of a secret ring element in Zğ¿ or Zğ‘› by a public integer into division of secret shares by the same public integer and correction terms (Theorem 4.1). These correction terms consist of multiple inequalities on secret values. As a corollary, we also get a much simpler expression for the special case of truncation, i.e., dividing â„“-bit integers by a power-of-2 (Corollary 4.2). We believe that the general theorem as well as the corollary can be of independent interest. Next, we give efficient protocols for both general division (used for Avgpool, Table 3) as well as division by a power-of-2 (used for multiplication in fixed-point arithmetic). The inequalities in the correction term are computed using our new protocol for millionairesâ€™ and the division of shares can be done locally by the respective parties. Our technical theorem is the key to obtaining secure implementation of DNN inference tasks that are bitwise equivalent to cleartext fixed-point execution.
1.3 Other Related Work
Perhaps the first work to consider the secure computation of machine learning inference algorithms was that of [14]. SecureML [51] was the first to consider secure neural network inference and training. Apart from the works mentioned earlier, other works include those that considered malicious adversaries [20, 36, 65] (for simpler
6This functionality takes as input shares of bits ğ‘¥, ğ‘¦ from the two parties and outputs shares of ğ‘¥ AND ğ‘¦ to both parties.

3

ML models like linear models, regression, and polynomials) as well as specialized DNNs with 1 or 2 bit weights [4, 56, 58]. Recently, [26] gave protocols for faithful truncation (but not division) over â„“-bit integers and prime fields in various adversarial settings. For 2-party semi-honest setting, our protocols have up to 20Ã— less communication for the truncations required in our evaluation. [55] proposed an HE-based triple generation protocol over Z2â„“ , which requires less communication than generating triples using OT.
1.4 Organisation
We begin with the details on security and cryptographic primitives used in Section 2 on preliminaries. In Section 3 we provide our protocols for millionairesâ€™ (Section 3.1) and DReLU (Section 3.2, 3.3), over both Zğ¿ and general ring Zğ‘›. In Section 4, we present our protocols for division and truncation. We describe the various components of DNN inference in Section 5 and show how to construct secure protocols for all these components given our protocols from Sections 3 and 4. We present our implementation details in Section 6 and our experiments in Section 7. Finally, we conclude and discuss future work in Section 8.
2 PRELIMINARIES
Notation. For a set W, ğ‘¤ â†$ W denotes sampling an element ğ‘¤, uniformly at random from W. [â„“] denotes the set of integers {0, Â· Â· Â· , â„“ âˆ’ 1}. Let 1{ğ‘} denote the indicator function that is 1 when ğ‘ is true and 0 when ğ‘ is false.
2.1 Threat Model and Security

âŸ¨ğ‘¥âŸ©0ğ¿ + âŸ¨ğ‘¥âŸ©1ğ¿ = ğ‘¥ (where + denotes addition in Zğ¿). Additive secret sharing schemes are perfectly hiding, i.e., given a share âŸ¨ğ‘¥âŸ©0ğ¿ or âŸ¨ğ‘¥âŸ©1ğ¿, the value ğ‘¥ is completely hidden. The reconstruction algorithm
Reconstğ¿ (âŸ¨ğ‘¥âŸ©0ğ¿, âŸ¨ğ‘¥âŸ©1ğ¿) takes as input the two shares and outputs ğ‘¥ = âŸ¨ğ‘¥âŸ©0ğ¿ + âŸ¨ğ‘¥âŸ©1ğ¿. Shares (along with their corresponding Share () and Reconst () algorithms) are defined in a similar manner for Z2 and Zğ‘› with superscripts ğµ and ğ‘›, respectively. We sometimes refer
to shares over Zğ¿ and Zğ‘› as arithmetic shares and shares over Z2 as boolean shares.

2.2.2

Oblivious Transfer. Let

ğ‘˜ 1

-OTâ„“ denote the 1-out-of-ğ‘˜ Obliv-

ious Transfer (OT) functionality [16] (which generalizes 1-out-of-2

OT [27, 54]). The senderâ€™s inputs to the functionality are the ğ‘˜

strings ğ‘š0, Â· Â· Â· , ğ‘šğ‘˜âˆ’1, each of length â„“ and the receiverâ€™s input is a value ğ‘– âˆˆ [ğ‘˜]. The receiver obtains ğ‘šğ‘– from the functionality

and the sender receives no output. We use the protocols from [44],

which are an optimized and generalized version of the OT exten-

sion framework proposed in [9, 41]. This framework allows the

sender and receiver, to â€œreduceâ€ ğœ†ğ‘ number of oblivious transfers

to ğœ† â€œbaseâ€ OTs. We also use the notion of correlated 1-out-of-2

OT [5], denoted by

2 1

-COTâ„“ .

In

our

context,

this

is

a

functionality

where the senderâ€™s input is a ring element ğ‘¥ and the receiverâ€™s

input is a choice bit ğ‘. The sender receives a random ring element

ğ‘Ÿ as output and the receiver obtains either ğ‘Ÿ or ğ‘¥ + ğ‘Ÿ as output

depending on ğ‘. The protocols for

ğ‘˜ 1

-OTâ„“

[44] and

2 1

-COTâ„“

[5]

execute in 2 rounds and have total communication7 of 2ğœ† + ğ‘˜â„“ and

ğœ† + â„“, respectively. Moreover, simpler

2 1

-OTâ„“

has a

communication

of ğœ† + 2â„“ bits [5, 41].

We provide security in the simulation paradigm [18, 32, 47] against a static semi-honest probabilistic polynomial time (PPT) adversary A. That is, a computationally bounded adversary A corrupts either ğ‘ƒ0 or ğ‘ƒ1 at the beginning of the protocol and follows the protocol specification honestly. Security is modeled by defining two interactions: a real interaction where ğ‘ƒ0 and ğ‘ƒ1 execute the protocol in the presence of A and the environment Z and an ideal interaction where the parties send their inputs to a trusted functionality that performs the computation faithfully. Security requires that for every adversary A in the real interaction, there is an adversary S (called the simulator) in the ideal interaction, such that no environment Z can distinguish between real and ideal interactions. Many of our protocols invoke multiple sub-protocols

2.2.3 Multiplexer and B2A conversion. The functionality FMğ‘›UX takes as input arithmetic shares of ğ‘ over ğ‘› and boolean shares of

choice bit ğ‘ from ğ‘ƒ0, ğ‘ƒ1, and returns shares of ğ‘ if ğ‘ = 1, else returns

shares of 0 over the same ring. A protocol for FMğ‘›UX can easily be im-

plemented by 2 simultaneous calls to

2 1

-OTğœ‚

and

communication

complexity is 2(ğœ† + 2ğœ‚), where ğœ‚ = âŒˆlog ğ‘›âŒ‰.

The functionality FBğ‘›2A (for boolean to arithmetic conversion) takes boolean (i.e., over Z2) shares as input and gives out arithmetic

(i.e., over Zğ‘›) shares of the same value as output. It can be realized

via one call to

2 1

-COTğœ‚

and

hence,

its

communication

is ğœ†

+ ğœ‚.

For

completeness, we provide the protocols realizing FMğ‘›UX as well as

FBğ‘›2A formally in Appendix A.3 and Appendix A.4, respectively.

and we describe these using the hybrid model. This is similar to a real interaction, except that sub-protocols are replaced by the invocations of instances of corresponding functionalities. A protocol invoking a functionality F is said to be in â€œF -hybrid model.â€

2.2.4 Homomorphic Encryption. A homomorphic encryption of ğ‘¥ allows computing encryption of ğ‘“ (ğ‘¥) without the knowledge of the decryption key. In this work, we require an additively homomorphic encryption scheme that supports addition and scalar multiplication,

2.2 Cryptographic Primitives

i.e. multiplication of a ciphertext with a plaintext. We use the additively homomorphic scheme of BFV [15, 28] (the scheme used in the

2.2.1 Secret Sharing Schemes. Throughout this work, we use 2-out- recent works of Gazelle [43] and Delphi [49]) and use the optimized

of-2 additive secret sharing schemes over different rings [11, 60]. algorithms of Gazelle for homomorphic matrix-vector products and

The 3 specific rings that we consider are the field Z2, the ring Zğ¿, where ğ¿ = 2â„“ (â„“ = 32, typically), and the ring Zğ‘›, for a positive

homomorphic convolutions. The BFV scheme uses the batching optimization [46, 61] that enables operation on plaintext vectors

integer ğ‘› (this last ring includes the special case of prime fields used

over the field Zğ‘›, where ğ‘› is a prime plaintext modulus of the form

in the works of [43, 49]). We let Shareğ¿ (ğ‘¥) denote the algorithm

that takes as input an element ğ‘¥ in Zğ¿ and outputs shares over
Zğ¿, denoted by âŸ¨ğ‘¥âŸ©0ğ¿ and âŸ¨ğ‘¥âŸ©1ğ¿. Shares are generated by sampling random ring elements âŸ¨ğ‘¥âŸ©0ğ¿ and âŸ¨ğ‘¥âŸ©1ğ¿, with the only constraint that

7The protocol of

ğ‘˜ 1

-OTâ„“ [44] incurs a communication cost of ğœ† + ğ‘˜â„“. However, to

achieve the same level of security, their security parameter needs to be twice that of

2 1

-COTâ„“ .

In

concrete

terms,

therefore,

we

write

the

cost

as

2ğœ†

+ ğ‘˜â„“.

4

2ğ¾ğ‘ + 1, ğ¾ is some positive integer and ğ‘ is scheme parameter that is a power-of-2.
3 MILLIONAIRESâ€™ AND DReLU PROTOCOLS

Algorithm 1 Millionairesâ€™, Î â„“M,ğ‘šILL:
Input: ğ‘ƒ0, ğ‘ƒ1 hold ğ‘¥ âˆˆ {0, 1}â„“ and ğ‘¦ âˆˆ {0, 1}â„“ , respectively. Output: ğ‘ƒ0, ğ‘ƒ1 learn âŸ¨1{ğ‘¥ < ğ‘¦}âŸ©0ğµ and âŸ¨1{ğ‘¥ < ğ‘¦}âŸ©1ğµ, respectively.

In this section, we provide our protocols for millionairesâ€™ problem and DReLU(ğ‘) when the inputs are â„“ bit signed integers as well as
elements in general rings of the form Zğ‘› (including prime fields). Our protocol for millionairesâ€™ problem invokes instances of FAND that take as input boolean shares of values ğ‘¥, ğ‘¦ âˆˆ {0, 1} and returns boolean shares of ğ‘¥ âˆ§ ğ‘¦. We discuss efficient protocols for FAND in Appendix A.1 and A.2.

3.1 Protocol for Millionairesâ€™
In the Yao millionairesâ€™ problem, party ğ‘ƒ0 holds ğ‘¥ and party ğ‘ƒ1 holds ğ‘¦ and they wish to learn boolean shares of 1{ğ‘¥ < ğ‘¦}. Here, ğ‘¥ and ğ‘¦ are â„“-bit unsigned integers. We denote this functionality by FMâ„“ ILL. Our protocol for FMâ„“ ILL builds on the following observation that was also used in [29].
1{ğ‘¥ < ğ‘¦} = 1{ğ‘¥1 < ğ‘¦1} âŠ• (1{ğ‘¥1 = ğ‘¦1} âˆ§ 1{ğ‘¥0 < ğ‘¦0}) , (1)
where, ğ‘¥ = ğ‘¥1||ğ‘¥0 and ğ‘¦ = ğ‘¦1||ğ‘¦0.

Intuition. Let ğ‘š be a parameter and ğ‘€ = 2ğ‘š. First, for ease of

exposition, we consider the special case when ğ‘š divides â„“ and

ğ‘ = â„“/ğ‘š is a power of 2. We describe our protocol for millionairesâ€™

problem in this setting formally in Algorithm 1. We use Equa-

tion 1 above, recursively log ğ‘ times to obtain ğ‘ leaves of size ğ‘š bits.

That is, let ğ‘¥ = ğ‘¥ğ‘âˆ’1|| . . . ||ğ‘¥0 and ğ‘¦ = ğ‘¦ğ‘âˆ’1|| . . . ||ğ‘¦0 (where every ğ‘¥ğ‘–, ğ‘¦ğ‘– âˆˆ {0, 1}ğ‘š). Now, we compute the shares of the inequalities

and equalities of strings at the leaf level using

ğ‘€ 1

-OT1 (steps 9 and

10, resp.). Next, we compute the shares of the inequalities (steps 14

& 15) and equalities (step 16) at each internal node upwards from

the leaf using Equation 1. Value of inequality at the root gives the

final output.

Correctness and security. Correctness is shown by induction on

the depth of the tree starting at the leaves. First, by correctness

of

ğ‘€ 1

-OT1

in step

9,

âŸ¨lt0,ğ‘— âŸ©1ğµ

=

âŸ¨lt0,ğ‘— âŸ©0ğµ

âŠ• 1{ğ‘¥ ğ‘—

< ğ‘¦ğ‘— }. Similarly,

âŸ¨eq0,ğ‘— âŸ©1ğµ = âŸ¨eq0,ğ‘— âŸ©0ğµ âŠ• 1{ğ‘¥ ğ‘— = ğ‘¦ğ‘— }. This proves the base case.

Let ğ‘ğ‘– = ğ‘/2ğ‘– . Also, for level ğ‘– of the tree, parse ğ‘¥ = ğ‘¥ (ğ‘–) =

(ğ‘–
ğ‘¥
ğ‘ğ‘–

) âˆ’1

|

|

.

.

.

ğ‘¥

(ğ‘–) 0

and ğ‘¦

= ğ‘¦ (ğ‘–)

=

(ğ‘–
ğ‘¦
ğ‘ğ‘–

) âˆ’1

|

|

.

.

.

(ğ‘–
ğ‘¦0

)

.

Assume

that

for

ğ‘– it holds that ltğ‘–,ğ‘—

=

âŸ¨ltğ‘–,ğ‘— âŸ©0ğµ âŠ• âŸ¨ltğ‘–,ğ‘— âŸ©1ğµ

=

1{ğ‘¥ (ğ‘–)
ğ‘—

<

ğ‘¦ (ğ‘–) } and
ğ‘—

âŸ¨eqğ‘–,ğ‘— âŸ©0ğµ

âŠ• âŸ¨eqğ‘–,ğ‘— âŸ©1ğµ

=

1{ğ‘¥ (ğ‘–)
ğ‘—

=

ğ‘¦ (ğ‘–) } for all
ğ‘—

ğ‘—

âˆˆ

{0, . . . , ğ‘ğ‘– âˆ’ 1}.

Then, we prove the same for ğ‘– + 1 as follows: By correctness of

FAND, for ğ‘— âˆˆ {0, . . . , ğ‘ğ‘–+1 âˆ’ 1}, âŸ¨ltğ‘–+1,ğ‘— âŸ©0ğµ âŠ• âŸ¨ltğ‘–+1,ğ‘— âŸ©1ğµ = ltğ‘–,2ğ‘—+1 âŠ•

( ltğ‘– ,2 ğ‘—

âˆ§ eqğ‘–,2ğ‘—+1)

=

1{ğ‘¥2(ğ‘–ğ‘—)+1

<

(ğ‘–)
ğ‘¦2 ğ‘— +1

}

âŠ•

(1{ğ‘¥2(ğ‘–ğ‘—)

<

(ğ‘–)
ğ‘¦2ğ‘—

}

âˆ§

1{ğ‘¥2(ğ‘–ğ‘—)+1

=

(ğ‘–)
ğ‘¦2 ğ‘— +1

})

=

1{ğ‘¥ (ğ‘–+1)
ğ‘—

< ğ‘¦ (ğ‘–+1) } (using Equation 1). The induction
ğ‘—

step for eqğ‘–+1,ğ‘— holds in a similar manner, thus proving correctness.

Given uniformity of âŸ¨lt0,ğ‘— âŸ©0ğµ, âŸ¨eq0,ğ‘— âŸ©0ğµ for all ğ‘— âˆˆ {0, . . . , ğ‘ âˆ’ 1}, se-

curity follows easily in the

(

ğ‘€ 1

-OT1, FAND)-hybrid.

General case. When ğ‘š does not divide â„“ and ğ‘ = âŒˆâ„“/ğ‘šâŒ‰ is not a power of 2, we make the following modifications to the protocol.

1: ğ‘ƒ0 parses its input as ğ‘¥ = ğ‘¥ğ‘âˆ’1|| . . . ||ğ‘¥0 and ğ‘ƒ1 parses its input

as ğ‘¦ = ğ‘¦ğ‘âˆ’1|| . . . ||ğ‘¦0, where ğ‘¥ğ‘–, ğ‘¦ğ‘– âˆˆ {0, 1}ğ‘š, ğ‘ = â„“/ğ‘š.

2: Let ğ‘€ = 2ğ‘š.

3: for ğ‘— = {0, . . . , ğ‘ âˆ’ 1} do

4: ğ‘ƒ0 samples âŸ¨lt0,ğ‘— âŸ©0ğµ, âŸ¨eq0,ğ‘— âŸ©0ğµ â†$ {0, 1}. 5: for ğ‘˜ = {0, . . . , ğ‘€ âˆ’ 1} do

6:

ğ‘ƒ0 sets ğ‘  ğ‘—,ğ‘˜ = âŸ¨lt0,ğ‘— âŸ©0ğµ âŠ• 1{ğ‘¥ ğ‘— < ğ‘˜ }.

7:

ğ‘ƒ0 sets ğ‘¡ ğ‘—,ğ‘˜ = âŸ¨eq0,ğ‘— âŸ©0ğµ âŠ• 1{ğ‘¥ ğ‘— = ğ‘˜ }.

8: end for

9:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

ğ‘€ 1

-OT1

where

ğ‘ƒ0

is

the

sender with inputs {ğ‘  ğ‘—,ğ‘˜ }ğ‘˜ and ğ‘ƒ1 is the receiver with input ğ‘¦ğ‘— .

ğ‘ƒ1 sets its output as âŸ¨lt0,ğ‘— âŸ©1ğµ.

10:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

ğ‘€ 1

-OT1

where

ğ‘ƒ0

is

the

sender with inputs {ğ‘¡ ğ‘—,ğ‘˜ }ğ‘˜ and ğ‘ƒ1 is the receiver with input ğ‘¦ğ‘— .

ğ‘ƒ1 sets its output as âŸ¨eq0,ğ‘— âŸ©1ğµ.

11: end for

12: for ğ‘– = {1, . . . , log ğ‘} do

13: for ğ‘— = {0, . . . , (ğ‘/2ğ‘– ) âˆ’ 1} do

14:

For

ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

invokes

FAND

with

inputs

âŸ¨ltğ‘– âˆ’1,2 ğ‘—

âŸ©ğµ
ğ‘

and

âŸ¨eqğ‘– âˆ’1,2 ğ‘— +1 âŸ©ğ‘ğµ

to

learn

output

âŸ¨tempâŸ©ğµ .
ğ‘

15:

ğ‘ƒğ‘

sets

âŸ¨ltğ‘–,ğ‘— âŸ©ğµ
ğ‘

=

âŸ¨ltğ‘–

âˆ’1,2 ğ‘—

+1

âŸ©ğµ
ğ‘

âŠ•

âŸ¨tempâŸ©ğµ .
ğ‘

16:

For ğ‘

âˆˆ

{0, 1},

ğ‘ƒğ‘

invokes

FAND

with

inputs

âŸ¨eqğ‘– âˆ’1,2 ğ‘—

âŸ©ğµ
ğ‘

and

âŸ¨eqğ‘– âˆ’1,2 ğ‘— +1 âŸ©ğ‘ğµ

to

learn

output

âŸ¨eqğ‘–,

ğ‘—

âŸ©ğµ
ğ‘

.

17: end for

18: end for 19: For ğ‘ âˆˆ {0, 1}, ğ‘ƒğ‘ outputs âŸ¨ltlog ğ‘,0âŸ©ğ‘ğµ .

Since ğ‘š does not divide â„“, ğ‘¥ğ‘âˆ’1 âˆˆ {0, 1}ğ‘Ÿ , where ğ‘Ÿ = â„“ mod ğ‘š.8

When doing the compute for ğ‘¥ğ‘âˆ’1 and ğ‘¦ğ‘âˆ’1, we perform a small

optimization and use

ğ‘… 1

-OT1

in steps

9

and 10, where ğ‘…

=

2ğ‘Ÿ .

Second, since ğ‘ is not a power of 2, we do not have a perfect binary

tree of recursion and we need to slightly change our recursion/tree

traversal. In the general case, we construct maximal possible perfect

binary trees and connect the roots of the same using the relation in Equation 1. Let ğ›¼ be such that 2ğ›¼ < ğ‘ â‰¤ 2ğ›¼+1. Now, our tree has

a perfect binary sub-tree with 2ğ›¼ leaves and we have remaining ğ‘â€² = ğ‘ âˆ’ 2ğ›¼ leaves. We recurse on ğ‘â€². In the last step, we obtain our

tree with ğ‘ leaves by combining the roots of perfect binary tree

with

2ğ›¼

leaves

and

tree

with

â€²
ğ‘

leaves

using

Equation

1.

Note

that

value at the root is computed using âŒˆlog ğ‘âŒ‰ sequential steps starting

from the leaves.

3.1.1 Optimizations. We reduce the concrete communication complexity of our protocol using the following optimizations that are applicable to both the special and the general case.

Combining two

ğ‘€ 1

-OT1

calls

into

one

ğ‘€ 1

-OT2:

Since

the

input of ğ‘ƒ1 (OT receiver) to

ğ‘€ 1

-OT1 in steps 9 and 10 is same,

i.e. ğ‘¦ğ‘— , we can collapse these steps into a single call to

ğ‘€ 1

-OT2

8Note that ğ‘Ÿ = ğ‘š when ğ‘š divides â„“.

5

where ğ‘ƒ0 and ğ‘ƒ1 input {(ğ‘  ğ‘—,ğ‘˜ ||ğ‘¡ ğ‘—,ğ‘˜ )}ğ‘˜ and ğ‘¦ğ‘— , respectively. ğ‘ƒ1

sets its output as (âŸ¨lt0,ğ‘— âŸ©1ğµ ||âŸ¨eq0,ğ‘— âŸ©1ğµ). This reduces the cost from 2(2ğœ† + ğ‘€) to (2ğœ† + 2ğ‘€).

Realizing FAND efficiently: It is well-known that FAND can be realized using Beaver bit triples [8]. For our protocol, we

observe that the 2 calls to FAND in steps 14 and 16 have a

common input, âŸ¨eqğ‘–âˆ’1,2ğ‘—+1âŸ©ğ‘ğµ. Hence, we optimize communi-

cation of these steps by generating correlated bit triples (âŸ¨ğ‘‘âŸ©ğµ,

ğ‘

âŸ¨ğ‘’âŸ©ğµ, âŸ¨ğ‘“ âŸ©ğµ) and (âŸ¨ğ‘‘ â€²âŸ©ğµ, âŸ¨ğ‘’âŸ©ğµ, âŸ¨ğ‘“ â€²âŸ©ğµ), for ğ‘ âˆˆ {0, 1}, such that

ğ‘ğ‘

ğ‘ğ‘

ğ‘

ğ‘‘ âˆ§ ğ‘’ = ğ‘“ and ğ‘‘ â€² âˆ§ ğ‘’ = ğ‘“ â€². Next, we use

8 1

-OT2

to

generate

one such correlated bit triple (Appendix A.2) with communi-

cation 2ğœ† + 16 bits, giving the amortized cost of ğœ† + 8 bits per

triple. Given correlated bit triples, we need 6 additional bits

to compute both FAND calls. Removing unnecessary equality computations: As observed

in [29], the equalities computed on lowest significant bits are

never used. Concretely, we can skip computing the values

eqğ‘–,0 for ğ‘– âˆˆ {0, . . . , log ğ‘}. Once we do this optimization, we

only need a single call to FAND instead of 2 correlated calls

for the leftmost branch of the tree. We use the

16 1

-OT2

â†’

2Ã—

4 1

-OT1

reduction

to

generate

2

regular

bit

triples

from

[25] (Appendix A.1) with communication of 2ğœ† + 32 bits. This

gives us amortized communication of ğœ† + 16 bits per triple

and we need 4 additional bits to realize FAND. Overall, we get a reduction in total communication by ğ‘€ (for the leaf) plus

(ğœ† + 2) Â· âŒˆlog ğ‘âŒ‰ (for leftmost branch) bits.

3.1.2 Communication Complexity. In our protocol, we communi-

cate in protocols for OT (steps 9&10) and FAND (steps 14&16). With

above optimizations, we need 1 call to

ğ‘€ 1

-OT1,

(ğ‘

âˆ’ 2)

calls

to

ğ‘€ 1

-OT2

and 1 call to

ğ‘… 1

-OT2

which cost

(2ğœ† + ğ‘€),

(ğ‘ âˆ’ 2) Â· (2ğœ† +

2ğ‘€) and (2ğœ† + 2ğ‘…) bits, respectively. In addition, we have âŒˆlog ğ‘âŒ‰

invocations of FAND and (ğ‘ âˆ’ 1 âˆ’ âŒˆlog ğ‘âŒ‰) invocations of correlated FAND. These require communication of (ğœ† + 20) Â· âŒˆlog ğ‘âŒ‰ and (2ğœ† + 22) Â· (ğ‘ âˆ’ 1 âˆ’ âŒˆlog ğ‘âŒ‰) bits. This gives us total communication of

ğœ†(4ğ‘ âˆ’ âŒˆlog ğ‘âŒ‰ âˆ’ 2) + ğ‘€ (2ğ‘ âˆ’ 3) + 2ğ‘… + 22(ğ‘ âˆ’ 1) âˆ’ 2âŒˆlog ğ‘âŒ‰ bits. Using

this expression for â„“ = 32 we get least communication for ğ‘š = 7

(Table 1). We note that there is a trade-off between communication

and computational cost of OTs used and we discuss our choice of

ğ‘š for our experiments in Section 6.

3.2 Protocol for DReLU for â„“-bit integers
In Algorithm 2, we describe our protocol for FDinRte,â„“LU that takes as input arithmetic shares of ğ‘ and returns boolean shares of DReLU(ğ‘). Note that DReLU(ğ‘) = (1âŠ•MSB(ğ‘)), where MSB(ğ‘) is the most significant bit of ğ‘. Let arithmetic shares of ğ‘ âˆˆ Zğ¿ be âŸ¨ğ‘âŸ©0ğ¿ = msb0||ğ‘¥0 and âŸ¨ğ‘âŸ©1ğ¿ = msb1||ğ‘¥1 such that msb0, msb1 âˆˆ {0, 1}. We compute the boolean shares of MSB(ğ‘) as follows: Let carry = 1{(ğ‘¥0 + ğ‘¥1) > 2â„“âˆ’1 âˆ’ 1}. Then, MSB(ğ‘) = msb0 âŠ• msb1 âŠ• carry. We compute boolean shares of carry by invoking an instance of FMâ„“âˆ’IL1L.
Correctness and security. By correctness of FMâ„“âˆ’IL1L, Reconstğµ (âŸ¨carryâŸ©0ğµ, âŸ¨carryâŸ©1ğµ) = 1{(2â„“âˆ’1 âˆ’ 1 âˆ’ğ‘¥0) < ğ‘¥1} = 1{(ğ‘¥0 +ğ‘¥1) > 2â„“âˆ’1 âˆ’ 1}. Also, Reconstğµ (âŸ¨DReLUâŸ©0ğµ, âŸ¨DReLUâŸ©1ğµ) = msb0 âŠ• msb1 âŠ• carry âŠ• 1 =
6

Algorithm 2 â„“-bit integer DReLU, Î iDnRt,eâ„“LU:

Input: ğ‘ƒ0, ğ‘ƒ1 hold âŸ¨ğ‘âŸ©0ğ¿ and âŸ¨ğ‘âŸ©1ğ¿, respectively. Output: ğ‘ƒ0, ğ‘ƒ1 get âŸ¨DReLU(ğ‘)âŸ©0ğµ and âŸ¨DReLU(ğ‘)âŸ©1ğµ.

1: ğ‘ƒ0 parses its input as âŸ¨ğ‘âŸ©0ğ¿ = msb0||ğ‘¥0 and ğ‘ƒ1 parses its input as âŸ¨ğ‘âŸ©1ğ¿ = msb1||ğ‘¥1, s.t. ğ‘ âˆˆ {0, 1}, msbğ‘ âˆˆ {0, 1}, ğ‘¥ğ‘ âˆˆ {0, 1}â„“âˆ’1.
2: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMâ„“âˆ’IL1L, where ğ‘ƒ0â€™s input is 2â„“âˆ’1 âˆ’

1

âˆ’

ğ‘¥0

and

ğ‘ƒ1â€™s

input

is

ğ‘¥1.

For ğ‘

âˆˆ

{0, 1},

ğ‘ƒğ‘

learns

âŸ¨carryâŸ©ğµ .
ğ‘

3:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

sets âŸ¨DReLUâŸ©ğµ
ğ‘

= msbğ‘

âŠ• âŸ¨carryâŸ©ğµ
ğ‘

âŠ• ğ‘.

Algorithm 3 Simple Integer ring DReLU, Î rDinRge,Lğ‘›Usimple :

Input: ğ‘ƒ0, ğ‘ƒ1 hold âŸ¨ğ‘âŸ©0ğ‘› and âŸ¨ğ‘âŸ©1ğ‘›, respectively, where ğ‘ âˆˆ Zğ‘›. Output: ğ‘ƒ0, ğ‘ƒ1 get âŸ¨DReLU(ğ‘)âŸ©0ğµ and âŸ¨DReLU(ğ‘)âŸ©1ğµ.

1: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğœ‚ILL with ğœ‚ = âŒˆlog ğ‘›âŒ‰, where

ğ‘ƒ0â€™s input is ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› and ğ‘ƒ1â€™s input is âŸ¨ğ‘âŸ©1ğ‘›. For ğ‘ âˆˆ {0, 1},

ğ‘ƒğ‘

learns

âŸ¨wrapâŸ©ğµ
ğ‘

as

output.

2: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğœ‚+IL1L, where ğ‘ƒ0â€™s input is

ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› and ğ‘ƒ1â€™s input is (ğ‘› âˆ’ 1)/2 + âŸ¨ğ‘âŸ©1ğ‘› . For ğ‘ âˆˆ

{0,

1},

ğ‘ƒğ‘

learns

âŸ¨ltâŸ©ğµ
ğ‘

as

output.

3: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğœ‚+IL1L, where ğ‘ƒ0â€™s input is

ğ‘› + (ğ‘› âˆ’ 1)/2 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› and ğ‘ƒ1â€™s input is âŸ¨ğ‘âŸ©1ğ‘›. For ğ‘ âˆˆ {0, 1},

ğ‘ƒğ‘

learns

âŸ¨rtâŸ©ğµ
ğ‘

as

output.

4: For ğ‘ âˆˆ {0, 1}, ğ‘ƒğ‘ invokes FM2 UX with input

âŸ¨ltâŸ©ğµ âŠ• âŸ¨rtâŸ©ğµ

ğ‘

ğ‘

and

choice âŸ¨wrapâŸ©ğµ to learn âŸ¨ğ‘§âŸ©ğµ.

ğ‘

ğ‘

5:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

outputs âŸ¨ğ‘§âŸ©ğµ
ğ‘

âŠ• âŸ¨ltâŸ©ğµ
ğ‘

âŠ• ğ‘.

MSB(ğ‘) âŠ• 1. Security follows trivially in the FMâ„“âˆ’IL1L hybrid.
Communication complexity In Algorithm 2, we communicate the same as in Î â„“Mâˆ’I1LL, that is < (ğœ† + 14) (â„“ âˆ’ 1) by using ğ‘š = 4.

3.3 Protocol for DReLU for general Zğ‘›
We describe a protocol for FDriRnegL,ğ‘›U that takes arithmetic shares of ğ‘ over Zğ‘› as input and returns boolean shares of DReLU(ğ‘). For integer rings Zğ‘›, DReLU(ğ‘) = 1 if ğ‘ < âŒˆğ‘›/2âŒ‰ and 0 otherwise. Note that this includes the case of prime fields considered in the works of [43, 49]. Below, we formally discuss the case of rings of odd number of elements and omit the analogous case of even rings. We first describe a (simplified) protocol for DReLU over Zğ‘› in Algorithm 3 with protocol logic as follows: Let arithmetic shares of ğ‘ âˆˆ Zğ‘› be âŸ¨ğ‘âŸ©0ğ‘› and âŸ¨ğ‘âŸ©1ğ‘›. Define wrap = 1{âŸ¨ğ‘âŸ©0ğ‘› + âŸ¨ğ‘âŸ©1ğ‘› > ğ‘› âˆ’ 1}, lt = 1{âŸ¨ğ‘âŸ©0ğ‘› + âŸ¨ğ‘âŸ©1ğ‘› > (ğ‘› âˆ’ 1)/2} and rt = 1{âŸ¨ğ‘âŸ©0ğ‘› + âŸ¨ğ‘âŸ©1ğ‘› > ğ‘› + (ğ‘› âˆ’ 1)/2}. Then, DReLU(ğ‘) is (1 âŠ• lt) if wrap = 0, else it is (1 âŠ• rt). In Algorithm 3, steps 1,2,3, compute these three comparisons using FMILL. Final output can be computed using an invocation of FM2 UX. Optimizations. We describe an optimized protocol for FDriRnegL,ğ‘›U in Algorithm 4 that reduces the number of calls to FMILL to 2. First,

Algorithm 4 Optimized Integer ring DReLU, Î rDinRge,Lğ‘›U:

Input: ğ‘ƒ0, ğ‘ƒ1 hold âŸ¨ğ‘âŸ©0ğ‘› and âŸ¨ğ‘âŸ©1ğ‘›, respectively, where ğ‘ âˆˆ Zğ‘›. Let ğœ‚ = âŒˆlog ğ‘›âŒ‰.
Output: ğ‘ƒ0, ğ‘ƒ1 get âŸ¨DReLU(ğ‘)âŸ©0ğµ and âŸ¨DReLU(ğ‘)âŸ©1ğµ.

1: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğœ‚+IL1L, where ğ‘ƒ0â€™s input is

3(ğ‘› âˆ’ 1)/2 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› and ğ‘ƒ1â€™s input is (ğ‘› âˆ’ 1)/2 + âŸ¨ğ‘âŸ©1ğ‘›. For

ğ‘

âˆˆ

{0, 1},

ğ‘ƒğ‘

learns

âŸ¨wrapâŸ©ğµ
ğ‘

as

output.

2: ğ‘ƒ0 sets ğ‘¥ = 2ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› if âŸ¨ğ‘âŸ©0ğ‘› > (ğ‘› âˆ’ 1)/2, else ğ‘¥ =

ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› . 3: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğœ‚+IL1L, where ğ‘ƒ0â€™s input is ğ‘¥ and

ğ‘ƒ1â€™s input is

(ğ‘› âˆ’ 1)/2 + âŸ¨ğ‘âŸ©1ğ‘›

. For ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

learns

âŸ¨xtâŸ©ğµ
ğ‘

as output.

4: ğ‘ƒ0 samples âŸ¨ğ‘§âŸ©0ğµ â†$ {0, 1}. 5: for ğ‘— = {00, 01, 10, 11} do

6: ğ‘ƒ0 parses ğ‘— as ğ‘—0|| ğ‘—1 and sets ğ‘¡ ğ‘— = 1 âŠ• âŸ¨xtâŸ©0ğµ âŠ• ğ‘—0.

7: if âŸ¨ğ‘âŸ©0ğ‘› > (ğ‘› âˆ’ 1)/2 then

8:

ğ‘ƒ0

sets

ğ‘ â€²
ğ‘—

=

ğ‘¡ğ‘—

âˆ§

( âŸ¨wrapâŸ©0ğµ

âŠ•

ğ‘—1).

9: else

10:

ğ‘ƒ0

sets

ğ‘ â€²
ğ‘—

=

ğ‘¡ğ‘—

âŠ•

((1

âŠ•

ğ‘¡ğ‘—)

âˆ§

( âŸ¨wrapâŸ©0ğµ

âŠ•

ğ‘—1))

11: end if

12:

ğ‘ƒ0

sets ğ‘  ğ‘—

=

ğ‘ â€²
ğ‘—

âŠ•

âŸ¨ğ‘§âŸ©0ğµ

13: end for

14: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

4 1

-OT1

where

ğ‘ƒ0

is

the

sender with inputs {ğ‘  ğ‘— }ğ‘— and ğ‘ƒ1 is the receiver with input

âŸ¨xtâŸ©1ğµ ||âŸ¨wrapâŸ©1ğµ. ğ‘ƒ1 sets its output as âŸ¨ğ‘§âŸ©1ğµ.

15:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

outputs âŸ¨ğ‘§âŸ©ğµ.
ğ‘

we observe that if the input of ğ‘ƒ1 is identical in all three invo-

cations, then the invocations of OT in Algorithm 1 (steps 9&10)

can be done together for the three comparisons. This reduces the

communication for each leaf OT invocation in steps 9&10 by an

additive factor of 4ğœ†. To enable this, ğ‘ƒ0, ğ‘ƒ1 add (ğ‘› âˆ’ 1)/2 to their inputs to FMğœ‚+IL1L in steps 1,3 (ğœ‚ = âŒˆlog ğ‘›âŒ‰). Hence, ğ‘ƒ1â€™s input to FMğœ‚+IL1L is (ğ‘› âˆ’ 1)/2 + âŸ¨ğ‘âŸ©1ğ‘› in all invocations and ğ‘ƒ0â€™s inputs are

3(ğ‘› âˆ’ 1)/2 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› , ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› , 2ğ‘› âˆ’ 1 âˆ’ âŸ¨ğ‘âŸ©0ğ‘› in steps 1,2,3,

respectively.

Next, we observe that one of the comparisons in step 2 or step 3

is redundant. For instance, if âŸ¨ğ‘âŸ©0ğ‘› > (ğ‘› âˆ’ 1)/2, then the result of the comparison lt = âŸ¨ğ‘âŸ©0ğ‘› + âŸ¨ğ‘âŸ©1ğ‘› > (ğ‘› âˆ’ 1)/2 done in step 2 is always 1. Similarly, if âŸ¨ğ‘âŸ©0ğ‘› â‰¤ (ğ‘› âˆ’ 1)/2, then the result of the comparison rt = 1{âŸ¨ğ‘âŸ©0ğ‘› + âŸ¨ğ‘âŸ©1ğ‘› > ğ‘› + (ğ‘› âˆ’ 1)/2} done in step 3 is always 0. Moreover, ğ‘ƒ0 knows based on her input âŸ¨ğ‘âŸ©0ğ‘› which of the two comparisons is redundant. Hence, in the optimized protocol,

ğ‘ƒ0 and ğ‘ƒ1 always run the comparison to compute shares of wrap and one of the other two comparisons. Note that the choice of

which comparison is omitted by ğ‘ƒ0 need not be communicated to

ğ‘ƒ1, since ğ‘ƒ1â€™s input is same in all invocations of FMILL. Moreover,

this omission does not reveal any additional information to ğ‘ƒ1 by

security of FMILL. Finally, ğ‘ƒ0 and ğ‘ƒ1 can run a

4 1

-OT1

to

learn

the

shares of DReLU(ğ‘). Here, ğ‘ƒ1 is the receiver and her choice bits

are the shares learnt in the two comparisons. ğ‘ƒ0 is the sender who sets the 4 OT messages based on her input share, and two shares learnt from the comparison protocol. We elaborate on this in the correctness proof below.

Correctness and Security. First, by correctness of FMğœ‚+IL1L (step 1),

wrap = Reconstğµ (âŸ¨wrapâŸ©0ğµ, âŸ¨wrapâŸ©1ğµ) = 1{âŸ¨ğ‘âŸ©0ğ¿ + âŸ¨ğ‘âŸ©1ğ¿ > ğ‘› âˆ’ 1}. Let ğ‘—âˆ— = âŸ¨xtâŸ©1ğµ ||âŸ¨wrapâŸ©1ğµ. Then, ğ‘¡ ğ‘—âˆ— = 1 âŠ• xt. We will show

that

ğ‘ 

â€² ğ‘—âˆ—

=

DReLU(ğ‘),

and

hence,

by

correctness

of

4 1

-OT1,

ğ‘§

=

Reconstğµ (âŸ¨ğ‘§âŸ©0ğµ, âŸ¨ğ‘§âŸ©1ğµ) = DReLU(ğ‘). We have the following two cases.

When âŸ¨ğ‘âŸ©0ğ¿ > (ğ‘› âˆ’ 1)/2, lt = 1, and DReLU(ğ‘) = wrap âˆ§ (1 âŠ• rt).

Here, by correctness of FMğœ‚+IL1L (step 3), xt = Reconstğµ (âŸ¨xtâŸ©0ğµ, âŸ¨xtâŸ©1ğµ) =

rt.

Hence,

â€²
ğ‘ ğ‘—âˆ—

=

ğ‘¡ğ‘—âˆ—

âˆ§

( âŸ¨wrapâŸ©0ğµ

âŠ•

ğ‘—1âˆ—)

=

(1

âŠ•

rt)

âˆ§

wrap.

When âŸ¨ğ‘âŸ©0ğ¿ â‰¤ (ğ‘› âˆ’ 1)/2, rt = 0, DReLU(ğ‘) is 1 âŠ• lt if wrap = 0,

else 1. It can be written as (1 âŠ• lt) âŠ• (lt âˆ§ wrap). In this case, by cor-

rectness of FMğœ‚+IL1L (step 3), xt = Reconstğµ (âŸ¨xtâŸ©0ğµ, âŸ¨xtâŸ©1ğµ) = lt. Hence,

â€²
ğ‘ ğ‘—âˆ—

=

ğ‘¡ğ‘—âˆ—

âŠ• ((1 âŠ•ğ‘¡ ğ‘—âˆ— ) âˆ§ (âŸ¨wrapâŸ©0ğµ

âŠ•

ğ‘—1âˆ—))

=

(1 âŠ• lt) âŠ• (ltâˆ§wrap). Since

âŸ¨ğ‘§âŸ©0ğµ is uniform, security follows in the (FMğœ‚+IL1L,

4 1

-OT1)-hybrid.

Communication complexity. With the above optimization, the over-

all communication complexity of our protocol for DReLU in Zğ‘›

is equivalent to 2 calls to Î ğœ‚M+I1LL where ğ‘ƒ1 has same input plus

2ğœ† + 4 (for protocol for

4 1

-OT1).

Two

calls

to

Î ğœ‚M+I1LL

in

this

case

(using ğ‘š

=

4) cost

<

3 2

ğœ†

(ğœ‚

+ 1)

+ 28(ğœ‚

+ 1)

bits. Hence, total com-

munication is <

3 2

ğœ†

(ğœ‚

+ 1) + 28(ğœ‚

+ 1)

+ 2ğœ† + 4. We note that the

communication complexity of simplified protocol in Algorithm 3 is

approximately 3 independent calls to Î ğœ‚MILL, which cost 3(ğœ†ğœ‚ + 14ğœ‚) bits, plus 2ğœ† + 4 bits for FM2 UX. Thus, our optimization gives almost 2Ã— improvement.

4 DIVISION AND TRUNCATION
We present our results on secure implementations of division in the ring by a positive integer and truncation (division by powerof-2) that are bitwise equivalent to the corresponding cleartext computation. We begin with closed form expressions for each of these followed by secure protocols that use them.

4.1 Expressing general division and truncation
using arithmetic over secret shares
Let idiv : Z Ã— Z â†’ Z denote signed integer division, where the quotient is rounded towards âˆ’âˆ and the sign of the remainder is the same as that of divisor. We denote division of a ring element by a positive integer using rdiv : Zğ‘› Ã— Z â†’ Zğ‘› defined as
rdiv(ğ‘, ğ‘‘) â‰œ idiv(ğ‘ğ‘¢ âˆ’ 1{ğ‘ğ‘¢ â‰¥ âŒˆğ‘›/2âŒ‰} Â· ğ‘›, ğ‘‘) mod ğ‘›, (2)
where the integer ğ‘ğ‘¢ âˆˆ {0, 1, . . . , ğ‘› âˆ’ 1} is the unsigned representation of ğ‘ âˆˆ Zğ‘› lifted to integers and 0 < ğ‘‘ < ğ‘›. For brevity, we use ğ‘¥ =ğ‘› ğ‘¦ to denote ğ‘¥ mod ğ‘› = ğ‘¦ mod ğ‘›.
Theorem 4.1. (Division of ring element by positive integer). Let the shares of ğ‘ âˆˆ Zğ‘› be âŸ¨ğ‘âŸ©0ğ‘›, âŸ¨ğ‘âŸ©1ğ‘› âˆˆ Zğ‘›, for some ğ‘› = ğ‘›1 Â· ğ‘‘ + ğ‘›0 âˆˆ Z, where ğ‘›0, ğ‘›1, ğ‘‘ âˆˆ Z and 0 â‰¤ ğ‘›0 < ğ‘‘ < ğ‘›.

7

Let the unsigned representation of ğ‘, âŸ¨ğ‘âŸ©0ğ‘›, âŸ¨ğ‘âŸ©1ğ‘› in Zğ‘› lifted to integers be ğ‘ğ‘¢, ğ‘0, ğ‘1 âˆˆ {0, 1, . . . , ğ‘› âˆ’ 1}, respectively, such that ğ‘0 = ğ‘10 Â· ğ‘‘ + ğ‘00 and ğ‘1 = ğ‘11 Â· ğ‘‘ + ğ‘01, where ğ‘10, ğ‘00, ğ‘11, ğ‘01 âˆˆ Z and 0 â‰¤ ğ‘00, ğ‘01 < ğ‘‘. Let ğ‘›â€² = âŒˆğ‘›/2âŒ‰ âˆˆ Z. Define corr, ğ´, ğµ, ğ¶ âˆˆ Z as follows:

ï£± ï£´

âˆ’1

(ğ‘ğ‘¢ â‰¥ ğ‘›â€²) âˆ§ (ğ‘0 < ğ‘›â€²) âˆ§ (ğ‘1 < ğ‘›â€²)

ï£´ï£² corr = 1

(ğ‘ğ‘¢ < ğ‘›â€²) âˆ§ (ğ‘0 â‰¥ ğ‘›â€²) âˆ§ (ğ‘1 â‰¥ ğ‘›â€²) ,

ï£´ ï£´

0

otherwise

ï£³

ğ´

=

ğ‘00

+

ğ‘01

âˆ’

(1{ğ‘0

â‰¥

ğ‘›â€²}

+

1{ğ‘1

â‰¥

â€²
ğ‘›

}

âˆ’

corr)

Â· ğ‘›0.

ğµ = idiv(ğ‘00 âˆ’ 1{ğ‘0 â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘) + idiv(ğ‘01 âˆ’ 1{ğ‘1 â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘)

ğ¶ = 1{ğ´ < ğ‘‘ } + 1{ğ´ < 0} + 1{ğ´ < âˆ’ğ‘‘ }

Then, we have: rdiv(âŸ¨ğ‘âŸ©0ğ‘›, ğ‘‘) + rdiv(âŸ¨ğ‘âŸ©1ğ‘›, ğ‘‘) + (corr Â· ğ‘›1 + 1 âˆ’ ğ¶ âˆ’ ğµ) =ğ‘› rdiv(ğ‘, ğ‘‘).
The proof of the above theorem is presented in Appendix C.

4.1.1 Special Case of truncation for â„“ bit integers. The expression above can be simplified for the special case of division by 2ğ‘  of â„“-bit integers, i.e., arithmetic right shift with ğ‘  (â‰« ğ‘ ), as follows:

Corollary 4.2. (Truncation for â„“-bit integers). Let the shares of ğ‘ âˆˆ Zğ¿ be âŸ¨ğ‘âŸ©0ğ¿, âŸ¨ğ‘âŸ©1ğ¿ âˆˆ Zğ¿. Let the unsigned representation of ğ‘, âŸ¨ğ‘âŸ©0ğ¿, âŸ¨ğ‘âŸ©1ğ¿ in Zğ¿ lifted to integers be ğ‘ğ‘¢, ğ‘0, ğ‘1 âˆˆ {0, 1, . . . , 2â„“ âˆ’ 1}, respectively, such that ğ‘0 = ğ‘10 Â· 2ğ‘  + ğ‘00 and ğ‘1 = ğ‘11 Â· 2ğ‘  + ğ‘01, where ğ‘10, ğ‘00, ğ‘11, ğ‘01 âˆˆ Z and 0 â‰¤ ğ‘00, ğ‘01 < 2ğ‘  . Let corr âˆˆ Z be defined as in Theorem 4.1. Then, we have:
(ğ‘0 â‰« ğ‘ ) + (ğ‘1 â‰« ğ‘ ) + corr Â· 2â„“âˆ’ğ‘  + 1{ğ‘00 + ğ‘01 â‰¥ 2ğ‘  } =ğ¿ (ğ‘ â‰« ğ‘ ).

Proof. The corollary follows directly from Theorem 4.1 as fol-

lows: First, (ğ‘ â‰« ğ‘ ) = rdiv(ğ‘, 2ğ‘  ). Next, ğ‘› = 2â„“ , ğ‘›1 = 2â„“âˆ’ğ‘  , and

ğ‘›0 = 0. Using these, we get ğ´ = ğ‘00 + ğ‘01, ğµ = 0 and ğ¶ = 1{ğ´ < 2ğ‘  } =

1{ğ‘00 + ğ‘01 < 2ğ‘  }.

â–¡

4.2 Protocols for division

In this section, we describe our protocols for division in different settings. We first describe a protocol for the simplest case of truncation for â„“-bit integers followed by a protocol for general division in Zğ‘› by a positive integer (Section 4.2.2). Finally, we discuss another simpler case of truncation, which allows us to do better than general division for rings with a special structure (Section 4.2.3).

4.2.1 Protocol for truncation of â„“-bit integer. Let FTirnut,nâ„“c,ğ‘  be the functionality that takes arithmetic shares of ğ‘ as input and

returns arithmetic shares of ğ‘ â‰« ğ‘  as output. In this work, we

give a protocol (Algorithm 5) that realizes the functionality FTirnut,nâ„“c,ğ‘  correctly building on Corollary 4.2.

Intuition. Parties ğ‘ƒ0 & ğ‘ƒ1 first invoke an instance of FDinRte,â„“LU (where one party locally flips its share of DReLU(ğ‘)) to get boolean shares

âŸ¨ğ‘šâŸ©ğµ of MSB(ğ‘). Using these shares, they use a
ğ‘

4 1

-OTâ„“

for

calcu-

lating âŸ¨corrâŸ©ğ¿, i.e., arithmetic shares of corr term in Corollary 4.2.
ğ‘
Next, they use an instance of FMğ‘  ILL to compute boolean shares of ğ‘ = 1{ğ‘00 + ğ‘01 â‰¥ 2ğ‘  }. Finally, they compute arithmetic shares of ğ‘ using a call to FBğ¿2A (Algorithm 7).

Algorithm 5 Truncation, Î iTnrtu,â„“n,ğ‘ c:

Input:

For ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

holds

âŸ¨ğ‘âŸ©ğ¿ ,
ğ‘

where

ğ‘

âˆˆ

Zğ¿ .

Output:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

learns âŸ¨ğ‘§âŸ©ğ¿
ğ‘

s.t. ğ‘§

=ğ‘

â‰« ğ‘ .

1:

For ğ‘

âˆˆ

{0,

1},

let

ğ‘ğ‘

,

ğ‘0
ğ‘

,

ğ‘1
ğ‘

âˆˆ Z be as defined in Corollary 4.2.

2:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

invokes

FDinRte,â„“LU

with

input

âŸ¨ğ‘âŸ©ğ¿
ğ‘

to learn

output

âŸ¨ğ›¼ âŸ©ğµ .
ğ‘

Party

ğ‘ƒğ‘

sets

âŸ¨ğ‘šâŸ©ğµ
ğ‘

=

âŸ¨ğ›¼ âŸ©ğµ
ğ‘

âŠ•

ğ‘.

3:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

sets ğ‘¥ğ‘

= MSB(âŸ¨ğ‘âŸ©ğ¿).
ğ‘

4: ğ‘ƒ0 samples âŸ¨corrâŸ©0ğ¿ â†$ Z2â„“ .

5: for ğ‘— = {00, 01, 10, 11} do

6: ğ‘ƒ0 computes ğ‘¡ ğ‘— = (âŸ¨ğ‘šâŸ©0ğµ âŠ• ğ‘—0 âŠ• ğ‘¥0) âˆ§ (âŸ¨ğ‘šâŸ©0ğµ âŠ• ğ‘—0 âŠ• ğ‘—1) s.t. ğ‘— = (ğ‘—0||ğ‘—1).

7: if ğ‘¡ ğ‘— âˆ§ 1{ğ‘¥0 = 0} then

8:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ¿ âˆ’âŸ¨corrâŸ©0ğ¿ âˆ’ 1.

9: else if ğ‘¡ ğ‘— âˆ§ 1{ğ‘¥0 = 1} then

10:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ¿ âˆ’âŸ¨corrâŸ©0ğ¿ + 1.

11: else

12:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ¿ âˆ’âŸ¨corrâŸ©0ğ¿.

13: end if

14: end for

15:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

4 1

-OTâ„“ ,

where

ğ‘ƒ0

is

the

sender

with inputs {ğ‘  ğ‘— }ğ‘— and ğ‘ƒ1 is the receiver with input âŸ¨ğ‘šâŸ©1ğµ ||ğ‘¥1

and learns âŸ¨corrâŸ©1ğ¿.

16: ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of FMğ‘  ILL with ğ‘ƒ0â€™s input as 2ğ‘  âˆ’1âˆ’ğ‘00

and

ğ‘ƒ1â€™s

input

as

ğ‘01.

For ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

learns

âŸ¨ğ‘ âŸ©ğµ .
ğ‘

17: For ğ‘ âˆˆ {0, 1}, ğ‘ƒğ‘ invokes an instance of FBğ¿2A (ğ¿ = 2â„“ ) with

input âŸ¨ğ‘âŸ©ğµ and learns âŸ¨ğ‘‘âŸ©ğ¿.

ğ‘

ğ‘

18:

ğ‘ƒğ‘

outputs âŸ¨ğ‘§âŸ©ğ¿
ğ‘

= (âŸ¨ğ‘âŸ©ğ¿
ğ‘

â‰« ğ‘ ) + âŸ¨corrâŸ©ğ¿ Â· 2â„“âˆ’ğ‘  + âŸ¨ğ‘‘âŸ©ğ¿, ğ‘

ğ‘

ğ‘

âˆˆ {0, 1}.

Correctness and Security. For any ğ‘§ âˆˆ Zğ¿, MSB(ğ‘§) = 1{ğ‘§ğ‘¢ â‰¥ 2â„“âˆ’1},

where ğ‘§ğ‘¢ is unsigned representation of ğ‘§ lifted to integers. First, note

that Reconstğµ (âŸ¨ğ‘šâŸ©0ğµ, âŸ¨ğ‘šâŸ©1ğµ) = 1âŠ•Reconstğµ (âŸ¨ğ›¼âŸ©0ğµ, âŸ¨ğ›¼âŸ©1ğµ) = MSB(ğ‘) by correctness of FDinRte,â„“LU. Next, we show that Reconstğ¿ (âŸ¨corrâŸ©0ğ¿,

âŸ¨corrâŸ©1ğ¿ )

=

corr,

as

defined

in

Corollary

4.2. Let ğ‘¥ğ‘

=

MSB ( âŸ¨ğ‘âŸ©ğ¿ )
ğ‘

for

ğ‘

âˆˆ

{0, 1},

and

let

âˆ—
ğ‘—

=

(âŸ¨ğ‘šâŸ©1ğµ ||ğ‘¥1).

Then,

ğ‘¡ğ‘—âˆ—

=

( âŸ¨ğ‘šâŸ©0ğµ

âŠ•

âŸ¨ğ‘šâŸ©1ğµ

âŠ•

ğ‘¥0) âˆ§ (âŸ¨ğ‘šâŸ©0ğµ âŠ• âŸ¨ğ‘šâŸ©1ğµ âŠ• ğ‘¥1) = (MSB(ğ‘) âŠ• ğ‘¥0) âˆ§ (MSB(ğ‘) âŠ• ğ‘¥1). Now, ğ‘¡ ğ‘—âˆ— = 1 implies that we are in one of the first two cases of expression

for corr â€“ which case we are in can be checked using ğ‘¥0 (steps 7

& 9). Now it is easy to see that ğ‘  ğ‘—âˆ— = âˆ’âŸ¨corrâŸ©0ğ¿ + corr = âŸ¨corrâŸ©1ğ¿.

Next, by correctness of FMğ‘  ILL, ğ‘ = Reconstğµ (âŸ¨ğ‘âŸ©0ğµ, âŸ¨ğ‘âŸ©1ğµ) = âŸ¨ğ‘âŸ©0ğµ âŠ• âŸ¨ğ‘âŸ©1ğµ = 1{ğ‘00 + ğ‘01 â‰¥ 2ğ‘  }. Given boolean shares of ğ‘, step 17, cre-

ates arithmetic shares of the same using an instance of FBğ¿2A. Since

âŸ¨corrâŸ©0ğ¿ is uniformly random, security of our protocol is easy to see

in (FDinRte,â„“LU,

4 1

-OTâ„“ ,

FMğ‘  ILL,

FBğ¿2A)-hybrid.

Communication complexity. Î iTnrtu,â„“n,cğ‘  involves a single call each to

FDinRte,â„“LU,

4 1

-OTâ„“ , FBğ¿2A and FMğ‘  ILL. Hence, communication required

is < ğœ†â„“ + 2ğœ† + 19â„“+ communication for FMğ‘  ILL that depends on

parameter ğ‘ . For â„“ = 32 and ğ‘  = 12, our concrete communication is

4310 bits (using ğ‘š = 7 for Î 1M2ILL as well as Î 3M1ILL inside Î iDnRt,e3L2U)

as opposed to 24064 bits for garbled circuits.

8

4.2.2 Protocol for division in ring. Let FDriInVg,ğ‘›,ğ‘‘ be the functionality for division that takes arithmetic shares of ğ‘ as input and returns arithmetic shares of rdiv(ğ‘, ğ‘‘) as output. Our protocol builds

protocol, end with arithmetic shares (over the same ring) of the output of the layer. This allows us to stitch protocols for arbitrary layers sequentially to obtain a secure computation protocol for any

on our closed form expression from Theorem 4.1. We note that â„“-bit

neural network comprising of these layers. Semi-honest security of

integers is a special case of Zğ‘› and we use the same protocol for division of an element in Zğ¿ by a positive integer.
Intuition. This protocol is similar to the previous protocol for truncation and uses the same logic to compute shares of corr term. Most non-trivial term to compute is ğ¶ that involves three signed comparisons over Z. We emulate these comparisons using calls to FDinRte,ğ›¿LU where ğ›¿ is large enough to ensure that there are no overflows or underflows. It is not too hard to see that âˆ’2ğ‘‘ + 2 â‰¤ ğ´ â‰¤ 2ğ‘‘ âˆ’ 2 and hence, âˆ’3ğ‘‘ + 2 â‰¤ ğ´ âˆ’ ğ‘‘, ğ´, ğ´ + ğ‘‘ â‰¤ 3ğ‘‘ âˆ’ 2. Hence, we set ğ›¿ = âŒˆlog 6ğ‘‘âŒ‰. Now, with this value of ğ›¿, the term ğ¶ can we re-written as (DReLU(ğ´ âˆ’ ğ‘‘) âŠ• 1) + (DReLU(ğ´) âŠ• 1) + (DReLU(ğ´ + ğ‘‘) âŠ• 1), which can be computed using three calls to FDinRte,ğ›¿LU (Step 19) and FBğ‘›2A (Step 20) each. Finally, note that to compute ğ¶ we need arithmetic shares of ğ´ over the ring ZÎ”, Î” = 2ğ›¿ . And this requires shares of corr over the same ring. Hence, we compute shares of corr over both Zğ‘› and ZÎ” (Step 15). Due to space constraints, we describe the protocol formally in Appendix D along with its communication complexity. Also, Table 3 provides theoretical and concrete communication numbers for division in both Zğ¿ and Zğ‘›, as well as a comparison with garbled circuits.

the protocol will follow trivially from sequential composibility of individual sub-protocols [18, 32, 47]. For protocols in SCIOT, this arithmetic secret sharing is over Zğ¿; in SCIHE, the sharing is over Zğ‘›, prime ğ‘›. The inputs to secure inference are floating-point numbers, encoded as fixed-point integers in the ring (Zğ¿ or Zğ‘›); for details see Appendix E.
5.1 Linear Layers
5.1.1 Fully connected layers and convolutions. A fully connected layer in a neural network is simply a product of two matrices - the matrix of weights and the matrix of activations of that layer - of appropriate dimension. At a very high level, a convolutional layer applies a filter (usually of dimension ğ‘“ Ã— ğ‘“ for small integer ğ‘“ ) to the input matrix by sliding across it and computing the sum of elementwise products of the filter with the input. Various parameters are associated with convolutions - e.g. stride (a stride of 1 denotes that the filter slides across the larger input matrix beginning at every row and every column) and zero-padding (which indicates whether the matrix is padded with 0s to increase its dimension before applying the filter). When performing matrix multiplication or convolutions over fixed-point values, the values of the final matrix must be scaled

down appropriately so that it has the same scale as the inputs to

4.2.3 Truncation in rings with special structure. It is easy to
see that truncation by ğ‘  in general rings can be done by performing a division by ğ‘‘ = 2ğ‘  . However, we can omit a call to FDinRte,ğ›¿LU and FBğ‘›2A when the underlying ring and ğ‘‘ satisfy a relation. Specifically, if we have 2 Â· ğ‘›0 â‰¤ ğ‘‘ = 2ğ‘  , then ğ´ is always greater than equal to âˆ’ğ‘‘, where ğ‘›0, ğ´ âˆˆ Z are as defined in Theorem 4.1. Thus, the
third comparison (ğ´ < âˆ’ğ‘‘) in the expression of ğ¶ from Theorem 4.1

the computation. Hence, to do faithful fixed-point arithmetic, we first compute the matrix multiplication or convolution over the ring (Zğ¿ or Zğ‘›) followed by truncation, i.e., division-by-2ğ‘  of all the values. In SCIOT, multiplication and convolutions over the ring Zğ¿ are done using oblivious transfer techniques and in SCIHE these are done over Zğ‘› using homomorphic encryption techniques that we describe next followed by our truncation method.

can be omitted. Moreover, this reduces the value of ğ›¿ needed and ğ›¿ = âŒˆlog 4ğ‘‘âŒ‰ suffices since âˆ’2ğ‘‘ â‰¤ ğ´ âˆ’ ğ‘‘, ğ´ â‰¤ 2ğ‘‘ âˆ’ 2.
Our homomorphic encryption scheme requires ğ‘› to be a prime of the form 2ğ¾ğ‘ + 1 (Section 2.2.4), where ğ¾ is a positive integer and ğ‘ â‰¥ 8192 is a power-of-2. Thus, we have ğ‘›0 = ğ‘› mod 2ğ‘  = 1 for 1 â‰¤ ğ‘  â‰¤ 14. For all our benchmarks, ğ‘  â‰¤ 12 and we use this optimization for truncation in SCIHE.
5 SECURE INFERENCE
We give an overview of all the layers that must be computed securely to realize the task of secure neural network inference. Layers can be broken into two categories - linear and non-linear. An inference algorithm simply consists of a sequence of layers of appropriate dimension connected to each other. Examples of

OT based computation. The OT-based techniques for multiplica-

tion are well-known [8, 23, 51] and we describe them briefly for com-

pleteness. First consider the simple case of secure multiplication of ğ‘

and ğ‘ in Zğ¿ where ğ‘ƒ0 knows ğ‘ and ğ‘ƒ0 and ğ‘ƒ1 hold arithmetic shares

of ğ‘. This can be done by invoking

2 1

-COTğ‘–

for ğ‘–

âˆˆ

{1, . . . , â„“ }

re-

quiring communication equivalent to â„“ instances of

2 1

-COT â„“+1 . 2

Using

this, multiplying two

matrices ğ´

âˆˆ

ğ‘€,ğ‘
Zğ¿

and ğµ

âˆˆ

ğ‘ ,ğ¾
Zğ¿

such that ğ‘ƒ0 knows ğ´ and ğµ is arithmetically secret shared re-

quires ğ‘€ğ‘ ğ¾â„“ instances of

2 1

-COT â„“+1 . 2

This

can

be

optimized

with

structured multiplications inside a matrix multiplication by com-

bining all the COT sender messages when multiplying with the

same element, reducing the complexity to that of ğ‘ ğ¾â„“ instances of

2 1

-COT ğ‘€ (â„“+1)

.

Finally,

we

reduce

the

task

of

secure

convolutions

2

to secure matrix multiplication similar to [45, 50, 62].

linear layers include matrix multiplication, convolutions, Avgpool

and batch normalization, while non-linear layers include ReLU, Maxpool, and Argmax.

HE based computation. SCIHE uses techniques from Gazelle [43] and Delphi [49] to compute matrix multiplications and convolu-

We are in the setting of secure inference where the model owner,
say ğ‘ƒ0, holds the weights. When securely realizing each of these layers, we maintain the following invariant: Parties ğ‘ƒ0 and ğ‘ƒ1 begin with arithmetic shares of the input to the layer and after the

tions over a field Zğ‘› (prime ğ‘›), of appropriate size. At a high level, first, ğ‘ƒ1 sends an encryption of its arithmetic share to ğ‘ƒ0. Then, ğ‘ƒ0 homomorphically computes on this ciphertext using weights of the model (known to ğ‘ƒ0) to compute an encryption of the arithmetic

9

share of the result and sends this back to ğ‘ƒ1. Hence, the communication only depends on the input and output size of the linear layer and is independent of the number of multiplications being performed. Homomorphic operations can have significantly high computational cost - to mitigate this, we build upon the output rotations method from [43] for performing convolutions, and reduce its number of homomorphic rotations. At a very high level, after performing convolutions homomorphically, ciphertexts are grouped, rotated in order to be correctly aligned, and then packed using addition. In our work, we divide the groups further into subgroups that are misaligned by the same offset. Hence the ciphertexts within a subgroup can first be added and the resulting ciphertext can then be aligned using a single rotation as opposed to subgroup-size many rotations in [43]. We refer the reader to Appendix F for details.

Faithful truncation. To correctly emulate fixed-point arithmetic, the value encoded in the shares obtained from the above methods needs to be divided-by-2ğ‘  , where ğ‘  is the scale used. For this we invoke FTirnut,nâ„“c,ğ‘  in SCIOT and FDriInVg,ğ‘›,2ğ‘  in SCIHE for each value of the resulting matrix. With this, result of secure implementation of fixed-point multiplication and convolutions is bitwise equal to the corresponding cleartext execution. In contrast, many prior works on 2PC [49, 51] and 3PC [45, 50, 62] used a local truncation method for approximate truncation based on a result from [51]. Here, the result can be arbitrarily wrong with a (small) probability ğ‘ and with probability 1 âˆ’ ğ‘ the result can be wrong in the last bit. Since ğ‘ grows with the number of truncations, these probabilistic errors are problematic for large DNNs. Moreover, even if ğ‘ is small, 1bit errors can accumulate and the results of cleartext execution and secure execution can diverge; this is undesirable as it breaks correctness of 2PC.

5.1.2 Avgpoolğ‘‘ . The function Avgpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ) over a pool of ğ‘‘ elements ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ is defined to be the arithmetic mean of these ğ‘‘ values. The protocol to compute this function works as

follows: ğ‘ƒ0 and ğ‘ƒ1 begin with arithmetic shares (e.g. over Zğ¿ in SCIOT) of ğ‘ğ‘– , for all ğ‘– âˆˆ [ğ‘‘]. They perform local addition to obtain

shares of ğ‘¤ =

ğ‘‘
ğ‘–=1 ğ‘ğ‘–

(i.e.,

ğ‘ƒğ‘

computes

âŸ¨ğ‘¤ âŸ©ğ¿
ğ‘

=

ğ‘‘ ğ‘– =1

âŸ¨ğ‘ğ‘–

âŸ©ğ¿ ).
ğ‘

Then,

parties

invoke

FDriInVg,ğ¿,ğ‘‘

on

inputs

âŸ¨ğ‘¤ âŸ©ğ¿
ğ‘

to

obtain

the

desired

output.

Correctness and security follow in the FDriInVg,ğ¿,ğ‘‘ âˆ’hybrid model.

Here too, unlike [49], our secure execution of average pool is bitwise

equal to the cleartext version.

5.2 Nonlinear Layers
5.2.1 ReLU. Note that ReLU(ğ‘) = ğ‘ if ğ‘ â‰¥ 0, and 0 otherwise. Equivalently, ReLU(ğ‘) = DReLU(ğ‘) Â· ğ‘. For Zğ¿, first we compute the boolean shares of DReLU(ğ‘) using a call to FDinRte,â„“LU and then we compute shares of ReLU(ğ‘) using a call to multiplexer FMğ¿UX (Section 2.2.3). We describe the protocol for ReLU(ğ‘) over Zğ¿ formally in Algorithm 8, Appendix B (the case of Zğ‘› follows in a similar manner). For communication complexity, refer to Table 2 for comparison with garbled circuits and Appendix B for details.
5.2.2 Maxpoolğ‘‘ and Argmaxğ‘‘ . The function Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ) over ğ‘‘ elements ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ is defined in the following way. Define gt(ğ‘¥, ğ‘¦) = ğ‘§, where ğ‘¤ = ğ‘¥ âˆ’ğ‘¦ and ğ‘§ = ğ‘¥, if ğ‘¤ > 0 and ğ‘§ = ğ‘¦, if ğ‘¤ â‰¤ 0.

Define ğ‘§1 = ğ‘1 and ğ‘§ğ‘– = gt(ğ‘ğ‘–, ğ‘§ğ‘–âˆ’1), recursively for all 2 â‰¤ ğ‘– â‰¤ ğ‘‘. Now, Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ) = ğ‘§ğ‘‘ .
We now describe a protocol such that parties begin with arith-

metic shares (over Zğ¿) of ğ‘ğ‘– , for all ğ‘– âˆˆ [ğ‘‘] and end the protocol with

arithmetic shares (over Zğ¿) of Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ). For simplicity, we describe how ğ‘ƒ0 and ğ‘ƒ1 can compute shares of ğ‘§ = gt(ğ‘¥, ğ‘¦)

(beginning with the shares of ğ‘¥ and ğ‘¦). It is easy to see then how

they can compute Maxpoolğ‘‘ . First, parties locally compute shares

of

ğ‘¤

=

ğ‘¥

âˆ’ğ‘¦

(i.e.,

ğ‘ƒğ‘

computes

âŸ¨ğ‘¤ âŸ©ğ¿
ğ‘

=

âŸ¨ğ‘¥ âŸ©ğ¿
ğ‘

âˆ’

âŸ¨ğ‘¦ âŸ©ğ¿ ,
ğ‘

for

ğ‘

âˆˆ

{0,

1}).

Next,

they

invoke

FDinRte,â„“LU

with

input

âŸ¨ğ‘¤ âŸ©ğ¿
ğ‘

to

learn

output

âŸ¨ğ‘£ âŸ©ğµ .
ğ‘

Now,

they

invoke

FMğ¿UX

with

input

âŸ¨ğ‘¤ âŸ©ğ¿
ğ‘

and

âŸ¨ğ‘£ âŸ©ğµ
ğ‘

to

learn

output

âŸ¨ğ‘¡âŸ©ğ¿. Finally, parties output âŸ¨ğ‘§âŸ©ğ¿ = âŸ¨ğ‘¦âŸ©ğ¿ + âŸ¨ğ‘¡âŸ©ğ¿. The correctness

ğ‘

ğ‘

ğ‘

ğ‘

and security of the protocol follows in a straightforward manner.

Computing Maxpoolğ‘‘ is done using ğ‘‘ âˆ’ 1 invocations of the above sub-protocol in ğ‘‘ âˆ’ 1 sequential steps.

Argmaxğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ) is defined similar to Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ), except that its output is an index ğ‘–âˆ— s.t. ğ‘ğ‘–âˆ— = Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ). Argmaxğ‘‘ can be computed securely similar to Maxpoolğ‘‘ (ğ‘1, Â· Â· Â· , ğ‘ğ‘‘ ).

6 IMPLEMENTATION
We implement our cryptographic protocols in a library and integrate them into the CrypTFlow framework [1, 45] as a new cryptographic backend. CrypTFlow compiles high-level TensorFlow [3] inference code to secure computation protocols using its frontend Athos, that are then executed by its cryptographic backends. We modify the truncation behavior of Athos in support of faithful fixedpoint arithmetic. We start by describing the implementation of our cryptographic library, followed by the modifications that we made to Athos.

6.1 Cryptographic backend

To implement our protocols, we build upon the

2 1

-OTâ„“

imple-

mentation from EMP [63] and extend it to

ğ‘˜ 1

-OTâ„“

using

the

proto-

col from [44]. Our linear-layer implementation in SCIHE is based on

SEAL/Delphi [2, 59] and in SCIOT is based on EMP. All our protocol

implementations are multi-threaded.

Oblivious Transfer.

ğ‘˜ 1

-OTâ„“

requires

a

correlation

robust

func-

tion to mask the senderâ€™s messages in the OT extension protocol,

and we use AESR25K6 (re-keyed AES with 256-bit key)9 to instantiate

it as in [23, 25]. We incorporated the optimizations from [33, 34]

for AES key expansion and pipelining these AESR25K6 calls. This leads to roughly 6Ã— improvement in the performance of AESR25K6 calls,

considerably improving the overall execution time of

ğ‘˜ 1

-OTâ„“ (e.g.

2.7Ã— over LAN for

16 1

-OT8).

Millionairesâ€™ protocol. Recall that ğ‘š is a parameter in our proto-

col Î â„“M,ğ‘šILL. While we discussed the dependence of communication complexity on ğ‘š in Section 3.1.2, here we discuss its influence on

the computational cost. Our protocol makes â„“/ğ‘š calls to

ğ‘€ 1

-OT2

(after merging steps 9&10), where ğ‘€ = 2ğ‘š. Using OT extension

techniques, generating an instance of

ğ‘€ 1

-OT2

requires 6 AESF25K6

9There are two types of AES in MPC applications - fixed-key (FK) and re-keyed (RK) [10, 35]. While the former runs key schedule only once and is more efficient, the latter generates a new key schedule for every invocation and is required in this application.

10

and (ğ‘€ +1) AESR25K6 evaluations. Thus, the computational cost grows super-polynomially with ğ‘š. We note that for â„“ = 32, even though communication is minimized for ğ‘š = 7, empirically we observe that ğ‘š = 4 gives us the best performance under both LAN and WAN settings (communication in this case is about 30% more than when ğ‘š = 7 but computation is â‰ˆ 3Ã— lower).
Implementing linear layers in SCIHE. To implement the linear layers in SCIHE, we build upon the Delphi implementation [2, 49], that is in turn based on the SEAL library [59]. We use the code for fully connected layers as it is from [2]. For convolution layers, we parallelize the code, employ modulus-switching [59] to reduce the ciphertext modulus (and hence ciphertext size), and implement the strided convolutions proposed in Gazelle [43]. These optimizations resulted in significant performance improvement of convolution layers. E.g. for the first convolution layer10 of ResNet50, the runtime decreased from 306s to 18s in the LAN setting and communication decreased from 204 MiB to 76 MiB.
6.2 CrypTFlow integration
We integrate SCIOT and SCIHE as new cryptographic backends into the CrypTFlow framework [1, 45]. Thus, as in CrypTFlow [45], we can work with unmodified TensorFlow code as input to produce our secure computation protocols. CrypTFlowâ€™s TensorFlow frontend Athos outputs fixed-point DNNs that use 64-bit integers and sets an optimal scale using a validation set. CrypTFlow required a bitwidth of 64 to ensure that the probability of local truncation errors in its protocols is small (Section 5.1.1). Since our protocols are correct and have no such errors, we extend Athos to set both the bitwidth and the scale optimally by autotuning on the validation set. The bitwidth and scale leak information about the weights and this leakage is similar to the prior works on secure inference [43, 45, 48â€“ 51, 62].
Implementing faithful truncations using Î iTnrtu,â„“n,cğ‘  requires the parties to communicate. We implement the following peephole optimizations in Athos to reduce the cost of these truncation calls. Consider a DNN having a convolution layer followed by a ReLU layer. While truncation can be done immediately after the convolution, moving the truncation call to after the ReLU layer can reduce the cost of our protocol Î iTnrtu,â„“n,cğ‘  . Since the values after ReLU are guaranteed to be all positive, the call to FDinRte,â„“LU within it (step 2 in Algorithm 5) now becomes redundant and can be omitted. Our optimization further accounts for operations that may occur between the convolutions and ReLU, say a matrix addition. Moving the truncation call from immediately after convolution to after ReLU means the activations flowing into the addition operation are now scaled by 2ğ‘ , instead of the usual ğ‘ . For the addition operation to then work correctly, we scale the other argument of addition by ğ‘  as well. These optimizations are fully automatic and need no manual intervention.
7 EXPERIMENTS
We empirically validate the following claims:
10Layer parameters: image size 230 Ã— 230, filter size 7 Ã— 7, input channels 3, output channels 64, and stride size 2 Ã— 2

Improvement over GC # Layers in Our Benchmarks

26 24 22 20 18 16 14 12 10
8 6 4 2 0
0

60

55

n#eedLamyoeres

50

Z2` -LAN

45

Zn-LAN

40

Z2` -WAN

35

Zn-WAN

30

25

20

15

10

5

0 2 4 6 8 10 12 14 16 18 20
# ReLUs (in powers of 2)

Figure 1: The left y-axis shows ( GC Time ). The right y-axis
Our Time
shows the total number of ReLU layers corresponding to each layer size in our benchmark set. The legend entries de-
note the input domain and the network setting.

â€¢ In Section 7.1, we show that our protocols for computing ReLU activations are more efficient than state-of-the-art garbled circuits-based implementations (Table 4). Additionally, our division protocols outperforms garbled circuits when computing average pool layers.
â€¢ On the DNNs considered by prior work on secure inference, our protocols can evaluate the non-linear layers much more efficiently and decrease the total time (Table 5) as well as the online time (Table 6).
â€¢ We show the first empirical evaluation of 2-party secure inference on ImageNet-scale benchmarks (Section 7.3). These results show the trade-offs between OT and HE-based secure DNN inference (Table 7).
We start with a description of our experimental setup and benchmarks, followed by the results.

Experimental Setup. We ran our benchmarks in two network settings, namely, a LAN setting with both machines situated in West Europe, and a transatlantic WAN setting with one of the machines in East US. The bandwidth between the machines is 377 MBps and 40 MBps in the LAN and the WAN setting respectively and the echo latency is 0.3ms and 80ms respectively. Each machine has commodity class hardware: 3.7 GHz Intel Xeon processor with 4 cores and 16 GBs of RAM.

Our Benchmarks. We evaluate on the ImageNet-scale benchmarks considered by [45]: SqueezeNet [40], ResNet50 [37], and DenseNet121 [38]. To match the reported accuracies, we need 37bit fixed-point numbers for ResNet50, whereas 32 bits suffice for DenseNet121 and SqueezeNet (Appendix I). Recall that our division protocols lead to correct secure executions and there is no accuracy loss in going from cleartext inference to secure inference. Appendix G provides a brief summary of these benchmarks.

11

Benchmark
SqueezeNet ResNet50 DenseNet121

Garbled Circuits LAN WAN Comm

26.4 265.6 136.5 1285.2 199.6 1849.3

7.63 39.19 56.57

(a) over Z2â„“

Our Protocols LAN WAN Comm
3.5 33.3 1.15 16.4 69.4 5.23 24.8 118.7 8.21

Benchmark

Garbled Circuits

Our Protocols

LAN WAN Comm LAN WAN Comm

SqueezeNet 51.7 525.8 16.06 ResNet50 267.5 2589.7 84.02 DenseNet121 383.5 3686.2 118.98

5.6 50.4 28.0 124.0 41.9 256.0

1.77 8.55 12.64

(b) over Zğ‘›

Table 4: Performance comparison with Garbled Circuits for ReLU layers. Runtimes are in seconds and comm. in GiB.

Benchmark

Metric

Linear

Delphi

Non-linear Ours Improvement

MiniONN

Time Comm.

10.7 0.02

ResNet32

Time Comm.

15.9 0.07

30.2 1.0 3.15 0.28 52.9 2.4 5.51 0.59

30.2Ã— 12.3Ã— 22.0Ã— 9.3Ã—

Table 5: Performance comparison with Delphi [49] for non-

linear layers. Runtimes are in seconds and comm. in GiB.

Benchmark

Linear

Delphi

Non-linear Ours Improvement

MiniONN < 0.1 3.97 0.32 ResNet32 < 0.1 6.99 0.63

12.40Ã— 11.09Ã—

Table 6: Performance comparison with Delphi [49] for on-

line runtime in seconds.

7.1 Comparison with Garbled Circuits
We compare with EMP-toolkit [63], the state-of-the-art library for Garbled Circuits (GC). Figure 1 shows the improvement of our ReLU protocols over GC in both LAN and WAN settings. On the xaxis, which is in log-scale, the number of ReLUs range from 20 to 220. The histogram shows, using the right y-axis, the cumulative number of layers in our benchmarks (SqueezeNet, ResNet50, DenseNet121) which require the number of ReLU activations given on the x-axis. We observe that these DNNs have layers that compute between 213 and 220 ReLUs. For such layers, we observe (on the left y-axis) that our protocols are 2Ã—â€“25Ã— faster than GC â€“ the larger the layers the higher the speedups, and gains are larger in the WAN settings. Specifically, for WAN and > 217 ReLUs, the speedups are much higher than the LAN setting. Here, the cost of rounds is amortized over large layers and the communication cost is a large fraction of the total runtime. Note that our implementations perform loadbalancing to leverage full-duplex TCP.
Next, we compare the time taken by GC and our protocols in computing the ReLU activations of our benchmarks in Table 4. Our protocol over Zğ¿ is up to 8Ã— and 18Ã— faster than GC in the LAN and WAN settings respectively, while it is â‰ˆ 7Ã— more communication efficient. As expected, our protocol over Zğ‘› has even better gains over GC. Specifically, it is up to 9Ã— and 21Ã— faster in the LAN and WAN settings respectively, and has â‰ˆ 9Ã— less communication.
We also performed a similar comparison of our protocols with GC for the Avgpool layers of our benchmarks, and saw up to 51Ã— reduction in runtime and 41Ã— reduction in communication. We report the concrete performance numbers and discuss the results in more detail in Appendix H.
7.2 Comparison with Delphi
In this section, we compare with Delphi [49], which is the current state-of-the-art for 2-party secure DNN inference that outperforms [12, 13, 17, 19, 22, 31, 43, 48, 57] in total time as well as the time taken in online phase. It uses garbled circuits for non-linear layers, and we show that with our protocols, the time taken to evaluate the non-linear layers can be decreased significantly.
For a fair evaluation, we demonstrate these improvements on the benchmarks of Delphi [49], i.e., the MiniONN (CIFAR-10) [48] and

ResNet32 (CIFAR-100) DNNs with ReLU activations (as opposed to the ImageNet-scale benchmarks for which Delphi has not been optimized). Similar to Delphi, we perform these computations with a bitwidth of 41 in the LAN setting.
In Table 5, we report the performance of Delphi for evaluating the linear and non-linear components of MiniONN and ResNet32 separately, along with the performance of our protocols for the same non-linear computation11. The table shows that the time to evaluate non-linear layers is the bulk of the total time and our protocols are 20Ã—â€“30Ã— faster in evaluating the non-linear layers. Also note that we reduce the communication by 12Ã— on MiniONN, and require 9Ã— less communication on ResNet32.
Next, we compare the online time of our protocols with the online time of Delphi in Table 6. In the online phase, linear layers take negligible time and all the time is spent in evaluating the nonlinear layers. Here, our protocols are an order of magnitude more efficient than Delphi.
7.3 Evaluation on practical DNNs
With all our protocols and implementation optimizations in place, we demonstrate the scalability of CrypTFlow2 by efficiently running ImageNet-scale secure inference. Table 7 shows that both our backends, SCIOT and SCIHE, are efficient enough to evaluate SqueezeNet in under a minute and scale to ResNet50 and DenseNet121.
In the LAN setting, for both SqueezeNet and DenseNet121, SCIOT performs better than SCIHE by at least 20% owing to the higher compute in the latter. However, the quadratic growth of communication with bitlength in the linear-layers of SCIOT can easily drown this difference if we go to higher bitlengths. Because ResNet50, requires 37-bits (compared to 32 in SqueezeNet and DenseNet121) to preserve accuracy, SCIHE outperforms SCIOT in both LAN and WAN settings. In general for WAN settings where communication becomes the major performance bottleneck, SCIHE performs better than SCIOT: 2Ã— for SqueezeNet and DenseNet121 and 4Ã— for ResNet50. Overall, with CrypTFlow2, we could evaluate all the 3 benchmarks within 10 minutes on LAN and 20 minutes on WAN. Since CrypTFlow2 supports both SCIOT and SCIHE, one can choose a specific backend depending on the network statistics [17, 53] to
11Our non-linear time includes the cost of correct truncation.

12

Benchmark Protocol LAN WAN Comm

SqueezeNet ResNet50 DenseNet121

SCIOT SCIHE SCIOT SCIHE SCIOT SCIHE

44.3 59.2 619.4 545.8 371.4 463.2

293.6 156.6 3611.6 936.0 2257.7 1124.7

26.07 5.27 370.84 32.43 217.19 35.56

Table 7: Performance of CrypTFlow2 on ImageNet-scale

benchmarks. Runtimes are in seconds and comm. in GiB.

get the best secure inference latency. To the best of our knowledge, no prior system provides this support for OT and HE-based secure DNN inference.
8 CONCLUSION AND FUTURE WORK
We have presented secure, efficient, and correct implementations of practical 2-party DNN inference that outperform prior work [49] by an order of magnitude in both latency and scale. We evaluate the first secure implementations of ImageNet scale inference, a task that previously required 3PC protocols [7, 45] (which provide weaker security guarantees) or leaking intermediate computations [12]. In the future, we would like to consider ImageNet scale secure training. Even though we can run inference on commodity machines, for training we would need protocols that can leverage specialized compute and networking hardware. Like all prior work on 2PC for secure DNN inference, CrypTFlow2 only considers semi-honest adversaries. In the future, we would like to consider malicious adversaries. Another future direction is to help the server in hiding ğ¹ from the client when computing a classifier ğ¹ (ğ‘¥, ğ‘¤). Like [43], SCIHE can hide some aspects of ğ¹ : the filter sizes, the strides, and whether a layer is convolutional or fully connected. Thus, SCIHE hides more information than OT-based tools [48] but reveals more information than FHE-based tools [13, 31]. We are exploring approaches to hide more information about ğ¹ while incurring minimal overhead.
REFERENCES
[1] 2020. CrypTFlow: An End-to-end System for Secure TensorFlow Inference. https://github.com/mpc- msri/EzPC.
[2] 2020. Delphi: A Cryptographic Inference Service for Neural Networks. https: //github.com/mc2- project/delphi.
[3] MartÃ­n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal JÃ³zefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan ManÃ©, Rajat Monga, Sherry Moore, Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. ViÃ©gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. CoRR abs/1603.04467 (2016). https://arxiv.org/abs/1603.04467
[4] Nitin Agrawal, Ali Shahin Shamsabadi, Matt J. Kusner, and AdriÃ  GascÃ³n. 2019. QUOTIENT: Two-Party Secure Neural Network Training and Prediction. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019. 1231â€“1247.
[5] Gilad Asharov, Yehuda Lindell, Thomas Schneider, and Michael Zohner. 2013. More efficient oblivious transfer and extensions for faster secure computation. In 2013 ACM SIGSAC Conference on Computer and Communications Security, CCSâ€™13, Berlin, Germany, November 4-8, 2013, Ahmad-Reza Sadeghi, Virgil D. Gligor, and Moti Yung (Eds.). ACM, 535â€“548. https://doi.org/10.1145/2508859.2516738
[6] Marshall Ball, Brent Carmer, Tal Malkin, Mike Rosulek, and Nichole Schimanski. 2019. Garbled Neural Networks are Practical. IACR Cryptology ePrint Archive 2019 (2019), 338. https://eprint.iacr.org/2019/338

[7] Assi Barak, Daniel Escudero, Anders Dalskov, and Marcel Keller. 2019. Secure Evaluation of Quantized Neural Networks. Cryptology ePrint Archive, Report 2019/131. https://eprint.iacr.org/2019/131.
[8] Donald Beaver. 1991. Efficient Multiparty Protocols Using Circuit Randomization. In Advances in Cryptology - CRYPTO â€™91, 11th Annual International Cryptology Conference, Santa Barbara, California, USA, August 11-15, 1991, Proceedings. 420â€“ 432.
[9] Donald Beaver. 1996. Correlated Pseudorandomness and the Complexity of Private Computations. In Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, Philadelphia, Pennsylvania, USA, May 22-24, 1996, Gary L. Miller (Ed.). ACM, 479â€“488. https://doi.org/10.1145/237814.237996
[10] Mihir Bellare, Viet Tung Hoang, Sriram Keelveedhi, and Phillip Rogaway. 2013. Efficient Garbling from a Fixed-Key Blockcipher. In 2013 IEEE Symposium on Security and Privacy, SP 2013, Berkeley, CA, USA, May 19-22, 2013. IEEE Computer Society, 478â€“492. https://doi.org/10.1109/SP.2013.39
[11] G. R. Blakley. 1979. Safeguarding cryptographic keys. In Managing Requirements Knowledge, International Workshop on. IEEE Computer Society, Los Alamitos, CA, USA, 313. https://doi.org/10.1109/AFIPS.1979.98
[12] Fabian Boemer, Anamaria Costache, Rosario Cammarota, and Casimir Wierzynski. 2019. nGraph-HE2: A High-Throughput Framework for Neural Network Inference on Encrypted Data. In Proceedings of the 7th ACM Workshop on En-
crypted Computing & Applied Homomorphic Cryptography, WAHC@CCS 2019,
London, UK, November 11-15, 2019, Michael Brenner, TancrÃ¨de Lepoint, and Kurt Rohloff (Eds.). ACM, 45â€“56. https://doi.org/10.1145/3338469.3358944 [13] Fabian Boemer, Yixing Lao, Rosario Cammarota, and Casimir Wierzynski. 2019. nGraph-HE: A Graph Compiler for Deep Learning on Homomorphically Encrypted Data. In Proceedings of the 16th ACM International Conference on Computing Frontiers, CF 2019, Alghero, Italy, April 30 - May 2, 2019. 3â€“13. [14] Raphael Bost, Raluca Ada Popa, Stephen Tu, and Shafi Goldwasser. 2015. Machine Learning Classification over Encrypted Data. In 22nd Annual Network and
Distributed System Security Symposium, NDSS 2015, San Diego, California, USA,
February 8-11, 2015. The Internet Society. https://www.ndss-symposium.org/ ndss2015/machine- learning- classification- over- encrypted- data [15] Zvika Brakerski. 2012. Fully Homomorphic Encryption without Modulus Switching from Classical GapSVP. In Advances in Cryptology - CRYPTO 2012 - 32nd An-
nual Cryptology Conference, Santa Barbara, CA, USA, August 19-23, 2012. Proceed-
ings (Lecture Notes in Computer Science, Vol. 7417), Reihaneh Safavi-Naini and Ran Canetti (Eds.). Springer, 868â€“886. https://doi.org/10.1007/978-3-642-32009-5_50 [16] Gilles Brassard, Claude CrÃ©peau, and Jean-Marc Robert. 1986. All-or-Nothing Disclosure of Secrets. In Advances in Cryptology - CRYPTO â€™86, Santa Barbara, California, USA, 1986, Proceedings (Lecture Notes in Computer Science, Vol. 263), Andrew M. Odlyzko (Ed.). Springer, 234â€“238. https://doi.org/10.1007/3-54047721- 7_17 [17] Niklas BÃ¼scher, Daniel Demmler, Stefan Katzenbeisser, David Kretzmer, and Thomas Schneider. 2018. HyCC: Compilation of Hybrid Protocols for Practical Secure Computation. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security, CCS 2018, Toronto, ON, Canada, October
15-19, 2018, David Lie, Mohammad Mannan, Michael Backes, and XiaoFeng Wang (Eds.). ACM, 847â€“861. https://doi.org/10.1145/3243734.3243786 [18] Ran Canetti. 2000. Security and Composition of Multiparty Cryptographic Protocols. J. Cryptology 13, 1 (2000), 143â€“202. [19] Nishanth Chandran, Divya Gupta, Aseem Rastogi, Rahul Sharma, and Shardul Tripathi. 2019. EzPC: Programmable and Efficient Secure Two-Party Computation for Machine Learning. In IEEE European Symposium on Security and Privacy, EuroS&P 2019, Stockholm, Sweden, June 17-19, 2019. 496â€“511. [20] Valerie Chen, Valerio Pastro, and Mariana Raykova. 2019. Secure Computation for Machine Learning With SPDZ. CoRR abs/1901.00329 (2019). arXiv:1901.00329 http://arxiv.org/abs/1901.00329 [21] Geoffroy Couteau. 2018. New Protocols for Secure Equality Test and Comparison. In Applied Cryptography and Network Security - 16th International Conference,
ACNS 2018, Leuven, Belgium, July 2-4, 2018, Proceedings (Lecture Notes in Computer
Science, Vol. 10892), Bart Preneel and Frederik Vercauteren (Eds.). Springer, 303â€“ 320. https://doi.org/10.1007/978-3-319-93387-0_16 [22] Roshan Dathathri, Olli Saarikivi, Hao Chen, Kristin Lauter, Saeed Maleki, Madan Musuvathi, and Todd Mytkowicz. 2019. CHET: An Optimizing Compiler for Fully-Homomorphic Neural-Network Inferencing. In Proceedings of the 40th ACM
SIGPLAN Conference on Programming Language Design and Implementation, PLDI
2019, Phoenix, AZ, USA, June 22-26, 2019. 142â€“156. [23] Daniel Demmler, Thomas Schneider, and Michael Zohner. 2015. ABY - A Frame-
work for Efficient Mixed-Protocol Secure Two-Party Computation. In 22nd An-
nual Network and Distributed System Security Symposium, NDSS 2015, San Diego,
California, USA, February 8-11, 2015. [24] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. 2009. Ima-
geNet: A large-scale hierarchical image database. In 2009 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition (CVPR 2009), 20-25 June
2009, Miami, Florida, USA. 248â€“255.

13

[25] Ghada Dessouky, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider, Shaza Zeitouni, and Michael Zohner. 2017. Pushing the Communication Barrier in Secure Computation using Lookup Tables. In 24th An-
nual Network and Distributed System Security Symposium, NDSS 2017, San
Diego, California, USA, February 26 - March 1, 2017. The Internet Society. https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/ pushing- communication- barrier- secure- computation- using- lookup- tables/ [26] Daniel Escudero, Satrajit Ghosh, Marcel Keller, Rahul Rachuri, and Peter Scholl. 2020. Improved Primitives for MPC over Mixed Arithmetic-Binary Circuits. In
Advances in Cryptology - CRYPTO 2020 - 40th Annual International Cryptology
Conference. [27] Shimon Even, Oded Goldreich, and Abraham Lempel. 1985. A Randomized
Protocol for Signing Contracts. Commun. ACM 28, 6 (1985), 637â€“647. https: //doi.org/10.1145/3812.3818 [28] Junfeng Fan and Frederik Vercauteren. 2012. Somewhat Practical Fully Homomorphic Encryption. Cryptology ePrint Archive, Report 2012/144. http: //eprint.iacr.org/2012/144. [29] Juan A. Garay, Berry Schoenmakers, and JosÃ© Villegas. 2007. Practical and Secure Solutions for Integer Comparison. In Public Key Cryptography - PKC 2007,
10th International Conference on Practice and Theory in Public-Key Cryptography,
Beijing, China, April 16-20, 2007, Proceedings (Lecture Notes in Computer Science,
Vol. 4450), Tatsuaki Okamoto and Xiaoyun Wang (Eds.). Springer, 330â€“342. https: //doi.org/10.1007/978- 3- 540- 71677- 8_22 [30] Craig Gentry. 2009. Fully homomorphic encryption using ideal lattices. In Pro-
ceedings of the 41st Annual ACM Symposium on Theory of Computing, STOC 2009,
Bethesda, MD, USA, May 31 - June 2, 2009, Michael Mitzenmacher (Ed.). ACM, 169â€“178. https://doi.org/10.1145/1536414.1536440 [31] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin E. Lauter, Michael Naehrig, and John Wernsing. 2016. CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy. In Proceedings of the
33nd International Conference on Machine Learning, ICML 2016, New York City,
NY, USA, June 19-24, 2016. 201â€“210. [32] Oded Goldreich, Silvio Micali, and Avi Wigderson. 1987. How to Play any
Mental Game or A Completeness Theorem for Protocols with Honest Majority. In Proceedings of the 19th Annual ACM Symposium on Theory of Computing, 1987, New York, New York, USA. 218â€“229. [33] Shay Gueron. 2016. AES-GCM-SIV implementations (128 and 256 bit). https: //github.com/Shay- Gueron/AES- GCM- SIV. [34] Shay Gueron, Yehuda Lindell, Ariel Nof, and Benny Pinkas. 2018. Fast Garbling of Circuits Under Standard Assumptions. J. Cryptol. 31, 3 (2018). https://doi.org/ 10.1007/s00145- 017- 9271- y [35] C. Guo, J. Katz, X. Wang, and Y. Yu. 2020. Efficient and Secure Multiparty Computation from Fixed-Key Block Ciphers. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, Los Alamitos, CA, USA, 247â€“263. https: //doi.org/10.1109/SP.2020.00016 [36] Carmit Hazay, Yuval Ishai, Antonio Marcedone, and Muthuramakrishnan Venkitasubramaniam. 2019. LevioSA: Lightweight Secure Arithmetic Computation. In Proceedings of the 2019 ACM Conference on Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019. 327â€“344. [37] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016. 770â€“778. [38] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Densely Connected Convolutional Networks. In 2017 IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July
21-26, 2017. 2261â€“2269. [39] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. 2016. Binarized Neural Networks. In Advances in Neural Information
Processing Systems 29: Annual Conference on Neural Information Processing Systems
2016, December 5-10, 2016, Barcelona, Spain, Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett (Eds.). 4107â€“4115. [40] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song Han, William J. Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size. CoRR abs/1602.07360 (2016). arXiv:1602.07360 http://arxiv.org/abs/1602.07360 [41] Yuval Ishai, Joe Kilian, Kobbi Nissim, and Erez Petrank. 2003. Extending Oblivious Transfers Efficiently. In Advances in Cryptology - CRYPTO 2003, 23rd Annual
International Cryptology Conference, Santa Barbara, California, USA, August 17-21,
2003, Proceedings (Lecture Notes in Computer Science, Vol. 2729), Dan Boneh (Ed.). Springer, 145â€“161. https://doi.org/10.1007/978-3-540-45146-4_9 [42] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew G. Howard, Hartwig Adam, and Dmitry Kalenichenko. 2018. Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018. 2704â€“2713. [43] Chiraag Juvekar, Vinod Vaikuntanathan, and Anantha Chandrakasan. 2018. GAZELLE: A Low Latency Framework for Secure Neural Network Inference. In
27th USENIX Security Symposium, USENIX Security 2018, Baltimore, MD, USA,

August 15-17, 2018. 1651â€“1669. [44] Vladimir Kolesnikov and Ranjit Kumaresan. 2013. Improved OT Extension for
Transferring Short Secrets. In Advances in Cryptology - CRYPTO 2013 - 33rd Annual
Cryptology Conference, Santa Barbara, CA, USA, August 18-22, 2013. Proceedings,
Part II (Lecture Notes in Computer Science, Vol. 8043), Ran Canetti and Juan A. Garay (Eds.). Springer, 54â€“70. https://doi.org/10.1007/978-3-642-40084-1_4 [45] Nishant Kumar, Mayank Rathee, Nishanth Chandran, Divya Gupta, Aseem Rastogi, and Rahul Sharma. 2020. CrypTFlow: Secure TensorFlow Inference. In 2020
IEEE Symposium on Security and Privacy, S&P 2020, San Francisco, CA, USA, May
18-20, 2020. 1521â€“1538. [46] Kim Laine. 2017. Simple Encrypted Arithmetic Library 2.3.1. https://www.
microsoft.com/en- us/research/uploads/prod/2017/11/sealmanual- 2- 3- 1.pdf . [47] Yehuda Lindell. 2016. How To Simulate It - A Tutorial on the Simulation Proof
Technique. Cryptology ePrint Archive, Report 2016/046. https://eprint.iacr.org/ 2016/046. [48] Jian Liu, Mika Juuti, Yao Lu, and N. Asokan. 2017. Oblivious Neural Network Predictions via MiniONN Transformations. In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security, CCS 2017, Dallas, TX, USA,
October 30 - November 03, 2017. 619â€“631. [49] Pratyush Mishra, Ryan Lehmkuhl, Akshayaram Srinivasan, Wenting Zheng, and
Raluca Ada Popa. 2020. Delphi: A Cryptographic Inference Service for Neural Networks. In 29th USENIX Security Symposium, USENIX Security 20. Boston, MA. [50] Payman Mohassel and Peter Rindal. 2018. ABY3: A Mixed Protocol Framework for Machine Learning. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security, CCS 2018, Toronto, ON, Canada, October
15-19, 2018. 35â€“52. [51] Payman Mohassel and Yupeng Zhang. 2017. SecureML: A System for Scalable
Privacy-Preserving Machine Learning. In 2017 IEEE Symposium on Security and Privacy, S&P 2017, San Jose, CA, USA, May 22-26, 2017. 19â€“38. [52] Markus Nagel, Mart van Baalen, Tijmen Blankevoort, and Max Welling. 2019. Data-Free Quantization Through Weight Equalization and Bias Correction. In
2019 IEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul,
Korea (South), October 27 - November 2, 2019. IEEE, 1325â€“1334. [53] Erman Pattuk, Murat Kantarcioglu, Huseyin Ulusoy, and Bradley A. Malin. 2016.
CheapSMC: A Framework to Minimize Secure Multiparty Computation Cost in the Cloud. In Data and Applications Security and Privacy XXX - 30th Annual
IFIP WG 11.3 Conference, DBSec 2016, Trento, Italy, July 18-20, 2016. Proceedings
(Lecture Notes in Computer Science, Vol. 9766), Silvio Ranise and Vipin Swarup (Eds.). Springer, 285â€“294. [54] Michael O. Rabin. 1981. How to exchange secrets with oblivious transfer. Technical Report TR-81, Aiken Computation Lab, Harvard University. https: //eprint.iacr.org/2005/187.pdf . [55] Deevashwer Rathee, Thomas Schneider, and K. K. Shukla. 2019. Improved Multiplication Triple Generation over Rings via RLWE-Based AHE. In Cryp-
tology and Network Security - 18th International Conference, CANS 2019, Fuzhou,
China, October 25-27, 2019, Proceedings (Lecture Notes in Computer Science,
Vol. 11829), Yi Mu, Robert H. Deng, and Xinyi Huang (Eds.). Springer, 347â€“359. https://doi.org/10.1007/978- 3- 030- 31578- 8_19 [56] M. Sadegh Riazi, Mohammad Samragh, Hao Chen, Kim Laine, Kristin E. Lauter, and Farinaz Koushanfar. 2019. XONN: XNOR-based Oblivious Deep Neural Network Inference. In 28th USENIX Security Symposium, USENIX Security 2019, Santa Clara, CA, USA, August 14-16, 2019. 1501â€“1518. [57] M. Sadegh Riazi, Christian Weinert, Oleksandr Tkachenko, Ebrahim M. Songhori, Thomas Schneider, and Farinaz Koushanfar. 2018. Chameleon: A Hybrid Secure Computation Framework for Machine Learning Applications. In Proceedings of
the 2018 on Asia Conference on Computer and Communications Security, AsiaCCS
2018, Incheon, Republic of Korea, June 04-08, 2018. 707â€“721. https://doi.org/10. 1145/3196494.3196522 [58] Bita Darvish Rouhani, M. Sadegh Riazi, and Farinaz Koushanfar. 2018. Deepsecure: scalable provably-secure deep learning. In Proceedings of the 55th Annual Design Automation Conference, DAC 2018, San Francisco, CA, USA, June 24-29, 2018. ACM, 2:1â€“2:6. [59] SEAL 2019. Microsoft SEAL (release 3.3). https://github.com/Microsoft/SEAL. Microsoft Research, Redmond, WA. [60] Adi Shamir. 1979. How to Share a Secret. Commun. ACM 22, 11 (1979), 612â€“613. https://doi.org/10.1145/359168.359176 [61] N.P. Smart and F. Vercauteren. 2011. Fully Homomorphic SIMD Operations. Cryptology ePrint Archive, Report 2011/133. http://eprint.iacr.org/2011/133. [62] Sameer Wagh, Divya Gupta, and Nishanth Chandran. 2019. SecureNN: 3-Party Secure Computation for Neural Network Training. PoPETs 2019, 3 (2019), 26â€“49. [63] Xiao Wang, Alex J. Malozemoff, and Jonathan Katz. 2016. EMP-toolkit: Efficient MultiParty computation toolkit. https://github.com/emp-toolkit. [64] Andrew Chi-Chih Yao. 1986. How to Generate and Exchange Secrets (Extended Abstract). In 27th Annual Symposium on Foundations of Computer Science, Toronto, Canada, 27-29 October 1986. IEEE Computer Society, 162â€“167. https://doi.org/10. 1109/SFCS.1986.25

14

[65] Wenting Zheng, Raluca Ada Popa, Joseph E. Gonzalez, and Ion Stoica. 2019. Helen: Maliciously Secure Coopetitive Learning for Linear Models. In 2019 IEEE
Symposium on Security and Privacy, S&P 2019, San Francisco, CA, USA, May 19-23,
2019. 724â€“738. [66] Xiaoyong Zhu, George Iordanescu, Ilia Karmanov, and Mazen Zawaideh.
2018. https://blogs.technet.microsoft.com/machinelearning/2018/03/07/usingmicrosoft- ai- to- build- a- lung- disease- prediction- model- using- chest- x- rayimages/

A SUPPORTING PROTOCOLS
Here, we describe supporting protocols that our main protocols rely on.

A.1 Protocol for regular FAND

Regular FAND can be realized using bit-triples [8], which are

of the form (âŸ¨ğ‘‘âŸ©ğµ, âŸ¨ğ‘’âŸ©ğµ, âŸ¨ğ‘“ âŸ©ğµ), where ğ‘ âˆˆ {0, 1} and ğ‘‘ âˆ§ ğ‘’ = ğ‘“ .

ğ‘ğ‘ ğ‘

Using an instance of

16 1

-OT2,

the

parties

can

generate

two

bit-

triples [25]. We describe this protocol for generating the first triple,

and from there, it will be easy to see how to also get the second

triple using the same OT instance. The parties start by sampling

random

shares

âŸ¨ğ‘‘âŸ©ğµ, âŸ¨ğ‘’âŸ©ğµ
ğ‘ğ‘

â†$

{0, 1}

for

ğ‘

âˆˆ

{0, 1}.

ğ‘ƒ1

sets

the

first

two bits of its input to

16 1

-OT2

as

âŸ¨ğ‘‘âŸ©1ğµ ||âŸ¨ğ‘’âŸ©1ğµ,

while

the

other

two

bits are used for the second triple. ğ‘ƒ0 samples a random bit ğ‘Ÿ and

sets its input messages to

16 1

-OT2

as

follows:

for

the

ğ‘–-th

message,

where ğ‘– âˆˆ {0, 1}4, ğ‘ƒ0 uses the first two bits ğ‘–1||ğ‘–2 of ğ‘– to compute

ğ‘Ÿ âŠ• ((ğ‘–1 âŠ• âŸ¨ğ‘‘âŸ©0ğµ)âˆ§(ğ‘–2 âŠ• âŸ¨ğ‘’âŸ©0ğµ)), and sets it as the first bit of the message,

while reserving the second bit for the other triple. Finally, ğ‘ƒ0 sets

âŸ¨ğ‘“ âŸ©0ğµ = ğ‘Ÿ , and ğ‘ƒ1 sets the first bit of the output of

16 1

-OT2

as

âŸ¨ğ‘“

âŸ©1ğµ .

It is easy to see correctness by noting that âŸ¨ğ‘“ âŸ©1ğµ = âŸ¨ğ‘“ âŸ©0ğµ âŠ• (ğ‘‘ âˆ§ ğ‘’),

and since âŸ¨ğ‘“ âŸ©0ğµ is uniformly random, security follows directly in

the

16 1

-OT2-hybrid.

The communication of this protocol is the same as that of

16 1

-OT2,

which is 2ğœ† + 16 Â· 2 bits. Since we generate two bit-triples using this

protocol, the amortized cost per triple is ğœ† + 16 bits, which is 144

for ğœ† = 128.

A.2 Protocol for correlated FAND

Correlated triples are two sets of bit triples (âŸ¨ğ‘‘âŸ©ğµ, âŸ¨ğ‘’âŸ©ğµ, âŸ¨ğ‘“ âŸ©ğµ)

ğ‘ğ‘ ğ‘

and (âŸ¨ğ‘‘ â€²âŸ©ğµ, âŸ¨ğ‘’ â€²âŸ©ğµ, âŸ¨ğ‘“ â€²âŸ©ğµ), for ğ‘ âˆˆ {0, 1}, such that ğ‘’ = ğ‘’ â€², ğ‘‘ âˆ§ ğ‘’ = ğ‘“ ,

and

ğ‘‘â€²

ğ‘
âˆ§ğ‘’

â€²

=

ğ‘
ğ‘“

â€².

ğ‘
The

protocol

from

Appendix

A.1

required

a

16 1

-OT2

invocation

to

generate

bits of ğ‘ƒ1â€™s input were its shares

two of ğ‘‘,

regular triples, where ğ‘’, ğ‘‘ â€², and ğ‘’ â€². However,

the 4 when

generating correlated triples, we can instead use an instance of

8 1

-OT2

because ğ‘’

=

ğ‘’ â€²,

and

thus,

3

bits

suffice

to

represent

ğ‘ƒ1â€™s

input. Correctness and security follow in a similar way as in the

case of regular FAND (see Appendix A.1).

The communication of this protocol is equal to that of

8 1

-OT2,

which costs 2ğœ† +8Â·2 bits. Thus, we get an amortized communication

of ğœ† + 8 bits per correlated triple.

Algorithm 6 Multiplexer, Î ğ‘›MUX:

Input:

For ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

holds

âŸ¨ğ‘âŸ©ğ‘›
ğ‘

and

âŸ¨ğ‘ âŸ©ğµ .
ğ‘

Output:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

learns âŸ¨ğ‘§âŸ©ğ‘›
ğ‘

s.t. ğ‘§

= ğ‘ if ğ‘

= 1, else ğ‘§

= 0.

1: For ğ‘ âˆˆ {0, 1}, ğ‘ƒğ‘ picks ğ‘Ÿğ‘ â†$ Zğ‘›.

2: ğ‘ƒ0 sets ğ‘ 0, ğ‘ 1 as follows: If âŸ¨ğ‘âŸ©0ğµ = 0, (ğ‘ 0, ğ‘ 1) = (âˆ’ğ‘Ÿ0, âˆ’ğ‘Ÿ0 + âŸ¨ğ‘âŸ©0ğ‘›).

Else, (ğ‘ 0, ğ‘ 1) = (âˆ’ğ‘Ÿ0 + âŸ¨ğ‘âŸ©0ğ‘›, âˆ’ğ‘Ÿ0).

3:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

2 1

-OTğœ‚

where

ğ‘ƒ0

is

the

sender

with inputs (ğ‘ 0, ğ‘ 1) and ğ‘ƒ1 is the receiver with input âŸ¨ğ‘âŸ©1ğµ. Let

ğ‘ƒ1â€™s output be ğ‘¥1.

4: ğ‘ƒ1 sets ğ‘¡0, ğ‘¡1 as follows: If âŸ¨ğ‘âŸ©1ğµ = 0, (ğ‘¡0, ğ‘¡1) = (âˆ’ğ‘Ÿ1, âˆ’ğ‘Ÿ1 + âŸ¨ğ‘âŸ©1ğ‘›).

Else, (ğ‘¡0, ğ‘¡1) = (âˆ’ğ‘Ÿ1 + âŸ¨ğ‘âŸ©1ğ‘›, âˆ’ğ‘Ÿ1).

5:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

2 1

-OTğœ‚

where

ğ‘ƒ1

is

the

sender

with inputs (ğ‘¡0, ğ‘¡1) and ğ‘ƒ0 is the receiver with input âŸ¨ğ‘âŸ©0ğµ. Let ğ‘ƒ0â€™s output be ğ‘¥0.

6:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

outputs âŸ¨ğ‘§âŸ©ğ‘›
ğ‘

= ğ‘Ÿğ‘

+ ğ‘¥ğ‘ .

Algorithm 7 Boolean to Arithmetic, Î ğ‘›B2A:

Input: ğ‘ƒ0, ğ‘ƒ1 hold âŸ¨ğ‘âŸ©0ğµ and âŸ¨ğ‘âŸ©1ğµ, respectively, where ğ‘ âˆˆ {0, 1}. Output: ğ‘ƒ0, ğ‘ƒ1 learn âŸ¨ğ‘‘âŸ©0ğ‘› and âŸ¨ğ‘‘âŸ©1ğ‘›, respectively, s.t. ğ‘‘ = ğ‘.

1:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

2 1

-COTğœ‚

where

ğ‘ƒ0

is

the

sender

with correlation function ğ‘“ (ğ‘¥) = ğ‘¥ + âŸ¨ğ‘âŸ©0ğµ and ğ‘ƒ1 is the receiver

with input âŸ¨ğ‘âŸ©1ğµ. Party ğ‘ƒ0 learns ğ‘¥ and sets ğ‘¦0 = ğ‘› âˆ’ ğ‘¥ and ğ‘ƒ1

learns ğ‘¦1.

2:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

computes âŸ¨ğ‘‘âŸ©ğ‘›
ğ‘

=

âŸ¨ğ‘ âŸ©ğµ
ğ‘

âˆ’

2

Â·

ğ‘¦ğ‘ .

Algorithm 8 â„“-bit integer ReLU, Î iRnetL,â„“U:

Input: ğ‘ƒ0, ğ‘ƒ1 hold âŸ¨ğ‘âŸ©0ğ¿ and âŸ¨ğ‘âŸ©1ğ¿, respectively. Output: ğ‘ƒ0, ğ‘ƒ1 get âŸ¨ReLU(ğ‘)âŸ©0ğ¿ and âŸ¨ReLU(ğ‘)âŸ©1ğ¿.

1:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

invokes

FDinRte,â„“LU

with

input

âŸ¨ğ‘âŸ©ğ¿
ğ‘

to learn

output âŸ¨ğ‘¦âŸ©ğµ.
ğ‘

2:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

invokes

FMğ¿UX

with

inputs

âŸ¨ğ‘âŸ©ğ¿
ğ‘

and âŸ¨ğ‘¦âŸ©ğµ
ğ‘

to

learn âŸ¨ğ‘§âŸ©ğ¿ and sets âŸ¨ReLU(ğ‘)âŸ©ğ¿ = âŸ¨ğ‘§âŸ©ğ¿.

ğ‘

ğ‘

ğ‘

Security trivially follows in

2 1

-OTğœ‚ -hybrid.

Communication

com-

plexity is 2(ğœ† + 2ğœ‚).

A.4 Protocol for B2A

We describe our protocol for realizing FBğ‘›2A formally in Algo-

rithm 7. For correctness, we need to show that ğ‘‘ = Reconstğ¿ (âŸ¨ğ‘‘âŸ©0ğ‘›, âŸ¨ğ‘‘âŸ©1ğ‘›)

= âŸ¨ğ‘âŸ©0ğµ + âŸ¨ğ‘âŸ©1ğµ âˆ’ 2âŸ¨ğ‘âŸ©0ğµ âŸ¨ğ‘âŸ©1ğµ. By correctness of

2 1

-COTğœ‚ , ğ‘¦1

=

ğ‘¥

+

âŸ¨ğ‘âŸ©0ğµ âŸ¨ğ‘âŸ©1ğµ. Using this, âŸ¨ğ‘‘âŸ©0ğ‘› = âŸ¨ğ‘âŸ©0ğµ + 2ğ‘¥ and âŸ¨ğ‘‘âŸ©1ğ‘› = âŸ¨ğ‘âŸ©1ğµ âˆ’ 2ğ‘¥ âˆ’

2âŸ¨ğ‘âŸ©0ğµ âŸ¨ğ‘âŸ©1ğµ. Security follows from the security of

2 1

-COTğœ‚

and com-

munication required is ğœ† + ğœ‚ bits.

A.3 Protocol for Multiplexer

We describe our protocol for realizing FMğ‘›UX in Algorithm 6.

First we argue correctness. Let ğ‘ = Reconstğµ (âŸ¨ğ‘âŸ©0ğµ, âŸ¨ğ‘âŸ©1ğµ) =

âŸ¨ğ‘âŸ©0ğµ âŠ• âŸ¨ğ‘âŸ©1ğµ. By correctness of

2 1

-OTğœ‚ , ğ‘¥1

=

âˆ’ğ‘Ÿ0 +ğ‘ Â· âŸ¨ğ‘âŸ©0ğ‘›. Similarly,

ğ‘¥0 = âˆ’ğ‘Ÿ1 + ğ‘ Â· âŸ¨ğ‘âŸ©1ğ‘›. Hence, Reconstğ‘› (âŸ¨ğ‘§âŸ©0ğ‘›, âŸ¨ğ‘§âŸ©1ğ‘›) = ğ‘§0 + ğ‘§1 = ğ‘ Â· ğ‘.

B PROTOCOL FOR ReLU
We describe our ReLU protocol for the case where the input and output shares are over Zğ¿ in Algorithm 8, and note that the case of Zğ‘› follows similarly. It is easy to see that the correctness and

15

security of the protocol follow in the (FDinRte,â„“LU, FMğ¿UX)âˆ’hybrid.

Communication complexity. We first look at the complexity of Î iRnetL,â„“U,

which involves a call to FDinRte,â„“LU and FMğ¿UX. FDinRte,â„“LU has the same

communication

as

FMâ„“ âˆ’IL1L ,

which

requires

ğœ†(â„“

âˆ’

1)

+

13

1 2

(â„“

âˆ’

1)

âˆ’

2ğœ† âˆ’ 22 bits if we assume ğ‘š = 4 and ğ‘š | (â„“ âˆ’ 1), and exclude

optimization (3.1.1) in the general expression from Section 3.1.2.

FMğ¿UX incurs a cost of 2ğœ† + 4â„“ bits, bringing the total cost to ğœ†â„“ +

17

1 2

â„“

âˆ’

ğœ†

âˆ’

35

1 2

bits,

which

can

be

rewritten

as

<

ğœ†â„“

+

18â„“ .

We

get

our best communication for â„“ = 32 (with all the optimizations) by

taking ğ‘š = 7 for the Î 3M1ILL invocation inside Î iDnRt,e3L2U, which gives

us a total communication of 3298 bits.

Now, we look at the complexity of Î rRienLgU,ğ‘›, which makes calls to

FDriRnegL,ğ‘›U and FMğ‘›UX. The cost of FDriRnegL,ğ‘›U is 2ğœ†+4 bits for

4 1

-OT1, plus

3 2

ğœ†

(ğœ‚

+

1)

+

27(ğœ‚

+

1)

âˆ’

4ğœ†

âˆ’

44

bits

for

2

invocations

of

FMğœ‚+IL1L,

where

ğ‘ƒ1â€™s input is the same in both invocations and the same assumptions

are made as for the expression of FMâ„“âˆ’IL1L above. The cost of FMğ‘›UX is

2ğœ†

+

4ğœ‚

bits,

and

thus,

the

total

cost

is

3 2

ğœ†

(ğœ‚

+

1)

+

31ğœ‚

âˆ’

13,

which

can

be rewritten as

<

3 2

ğœ†

(ğœ‚

+ 1)

+ 31ğœ‚. Concretely, we get the

best

communication for ğœ‚ = 32 by taking ğ‘š = 7 for the millionaire

invocations, getting a total communication of 5288 bits.

C PROOF OF DIVISION THEOREM
Here, we prove Theorem 4.1.

Proof. From Equation 2, we can write rdiv(âŸ¨ğ‘âŸ©ğ‘›, ğ‘‘) as:
ğ‘–

rdiv(

âŸ¨ğ‘âŸ©ğ‘›,
ğ‘–

ğ‘‘

)

=ğ‘›

idiv(ğ‘ğ‘–

âˆ’

1{ğ‘ğ‘–

â‰¥

ğ‘›â€²}

Â· ğ‘›, ğ‘‘)

=ğ‘›

idiv

(ğ‘1
ğ‘–

Â·ğ‘‘

+ ğ‘0
ğ‘–

âˆ’ 1{ğ‘ğ‘–

â‰¥

ğ‘›â€²}

Â·

(ğ‘›1

Â·ğ‘‘

+ ğ‘›0), ğ‘‘)

=ğ‘›

ğ‘1
ğ‘–

âˆ’

1{ğ‘ğ‘–

â‰¥

â€²
ğ‘›

}

Â·

ğ‘›1

+ idiv(ğ‘ğ‘–0

âˆ’ 1{ğ‘ğ‘–

â‰¥

â€²
ğ‘›

}

Â·

ğ‘›0,

ğ‘‘

),

(3)

for ğ‘– âˆˆ {0, 1}. ğ‘ğ‘¢ can be expressed as ğ‘ğ‘¢ = ğ‘0 + ğ‘1 âˆ’ ğ‘¤ Â· ğ‘›, where the wrap-bit ğ‘¤ = 1{ğ‘0 + ğ‘1 â‰¥ ğ‘›}. We can rewrite this as:

ğ‘ğ‘¢ = ğ‘0 + ğ‘1 âˆ’ ğ‘¤ Â· ğ‘› = (ğ‘10 + ğ‘11 âˆ’ ğ‘¤ Â· ğ‘›1) Â· ğ‘‘ + (ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0) = (ğ‘10 + ğ‘11 âˆ’ ğ‘¤ Â· ğ‘›1 + ğ‘˜) Â· ğ‘‘ + (ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0 âˆ’ ğ‘˜ Â· ğ‘‘), (4)

for some integer ğ‘˜ such that 0 â‰¤ ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0 âˆ’ ğ‘˜ Â· ğ‘‘ < ğ‘‘. Similar to Equation 3 and from Equation 4, we can write rdiv(ğ‘, ğ‘‘) as:

rdiv(ğ‘, ğ‘‘) =ğ‘› ğ‘10 + ğ‘11 âˆ’ ğ‘¤ Â· ğ‘›1 + ğ‘˜ âˆ’ 1{ğ‘ â‰¥ ğ‘›â€²} Â· ğ‘›1

+ idiv(ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0 âˆ’ ğ‘˜ Â· ğ‘‘ âˆ’ 1{ğ‘ â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘)

=ğ‘›

ğ‘10

+

ğ‘11

âˆ’

ğ‘¤

Â·

ğ‘›1

âˆ’

1{ğ‘

â‰¥

â€²
ğ‘›

}

Â·

ğ‘›1

+ idiv(ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0 âˆ’ 1{ğ‘ â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘). (5)

From Equations 3 and 5, we have the following correction term:

ğ‘ =ğ‘› rdiv(ğ‘, ğ‘‘) âˆ’ rdiv(âŸ¨ğ‘âŸ©0ğ‘›, ğ‘‘) âˆ’ rdiv(âŸ¨ğ‘âŸ©1ğ‘›, ğ‘‘)

=ğ‘›

1{ğ‘0

â‰¥

ğ‘›â€²}

+

1{ğ‘1

â‰¥

â€²
ğ‘›

}

âˆ’ğ‘¤

âˆ’

1{ğ‘

â‰¥

ğ‘›â€²}

Â· ğ‘›1

+ idiv(ğ‘00 + ğ‘01 âˆ’ ğ‘¤ Â· ğ‘›0 âˆ’ 1{ğ‘ â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘)

(6)

âˆ’ idiv(ğ‘00 âˆ’ 1{ğ‘0 â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘) + idiv(ğ‘01 âˆ’ 1{ğ‘1 â‰¥ ğ‘›â€²} Â· ğ‘›0, ğ‘‘)

=ğ‘› ğ‘1 Â· ğ‘›1 + ğ‘0 âˆ’ ğµ

(7)

16

# 1{ğ‘0 â‰¥ ğ‘›â€²} 1{ğ‘1 â‰¥ ğ‘›â€²} 1{ğ‘ğ‘¢ â‰¥ ğ‘›â€²} ğ‘¤ ğ‘1 ğ‘0

1

0

2

0

3

0

4

0

5

1

6

1

7

1

8

1

0 0 1 1 0 0 1 1

0 1 0 1 0 1 0 1

0 0 1 0 1 0 1 1

0 -1 0 0 0 0 1 0

ğ´ğ´01â€²â€²â€² ğ´ğ´ğ´ğ´ğ´ğ´111112â€²â€²â€²â€²â€²

Table 8: Truth table for the correction terms ğ‘0 and ğ‘1 in the

proof of division theorem (Appendix C).

Let

â€²
ğ´
ğ‘–

=

idiv(ğ‘00

+

ğ‘01

âˆ’

ğ‘–

Â·

ğ‘›0,

ğ‘‘).

Then

the

values

of

the

correction

terms ğ‘1 and ğ‘0 are as summarized in Table 8.

From the table, we have ğ‘1 = corr and can rewrite the correction

term as ğ‘ =ğ‘› corr Â· ğ‘›1 + ğ‘0 âˆ’ ğµ. Thus, adding corr Â· ğ‘›1 âˆ’ ğµ mod ğ‘› to

rdiv(âŸ¨ğ‘âŸ©0ğ‘›, ğ‘‘) + rdiv(âŸ¨ğ‘âŸ©1ğ‘›, ğ‘‘) accounts for all the correction terms except ğ‘0 mod ğ‘›.
Now all that remains to be proven is that ğ‘0 = 1 âˆ’ ğ¶. Let

ğ¶0 = 1{ğ´ < ğ‘‘ }, ğ¶1 = 1{ğ´ < 0}, and ğ¶2 = 1{ğ´ < âˆ’ğ‘‘ }. Then,
we have ğ¶ = ğ¶0 + ğ¶1 + ğ¶2. Note from the theorem statement that ğ´ = ğ‘00 + ğ‘01 and ğ´ = ğ‘00 + ğ‘01 âˆ’ 2 Â· ğ‘›0 for the cases corresponding to rows 1 and 8 respectively from the table, while ğ´ = ğ‘00 + ğ‘01 âˆ’ ğ‘›0 for the rest of cases. Thus, it is easy to see that ğ‘0 = idiv(ğ´, ğ‘‘). Also note that âˆ’2 Â· ğ‘‘ + 2 â‰¤ ğ´ â‰¤ 2 Â· ğ‘‘ âˆ’ 2, implying that the range of ğ‘0 is {âˆ’2, âˆ’1, 0, 1}. Now we look at each value assumed by ğ‘0 separately

as follows:

â€¢ ğ‘0 = âˆ’2: In this case, we have (ğ´ < âˆ’ğ‘‘), implying ğ¶0 = ğ¶1 = ğ¶2 = 1, and 1 âˆ’ ğ¶ = âˆ’2.
â€¢ ğ‘0 = âˆ’1: In this case, we have (âˆ’ğ‘‘ â‰¤ ğ´ < 0), implying

ğ¶0 = ğ¶1 = 1, ğ¶2 = 0 and 1 âˆ’ ğ¶ = âˆ’1. â€¢ ğ‘0 = 0: In this case, we have (0 â‰¤ ğ´ < ğ‘‘), implying ğ¶0 =
1, ğ¶1 = ğ¶2 = 0 and 1 âˆ’ ğ¶ = 0. â€¢ ğ‘0 = 1: In this case, we have (ğ‘‘ â‰¤ ğ´), implying ğ¶0 = ğ¶1 =
ğ¶2 = 0 and 1 âˆ’ ğ¶ = 1.

Thus, ğ‘ =ğ‘› corr Â· ğ‘›1 + (1 âˆ’ ğ¶) âˆ’ ğµ =ğ‘› rdiv(ğ‘, ğ‘‘) âˆ’ rdiv(âŸ¨ğ‘âŸ©0ğ‘›, ğ‘‘) âˆ’

rdiv(âŸ¨ğ‘âŸ©1ğ‘›, ğ‘‘).

â–¡

D PROTOCOL FOR GENERAL DIVISION
We describe our protocol for general division formally in Algorithm 9. As discussed in Section 4.2.2, our protocol builds on Theorem 4.1 and we compute the various sub-terms securely using our new protocols. Let ğ›¿ = âŒˆlog 6ğ‘‘âŒ‰. We compute the shares of corr over both Zğ‘› and ZÎ” (Step 15). We write the term ğ¶ as (DReLU(ğ´ âˆ’ ğ‘‘) âŠ• 1) + (DReLU(ğ´) âŠ• 1) + (DReLU(ğ´ + ğ‘‘) âŠ• 1), which can be computed using three calls to FDinRte,ğ›¿LU (Step 19) and FBğ‘›2A (Step 20) each.
Correctness and Security. First, ğ‘š = Reconstğµ (âŸ¨ğ‘šâŸ©0ğµ, âŸ¨ğ‘šâŸ©1ğµ) = Reconstğµ (âŸ¨ğ›¼âŸ©0ğµ, âŸ¨ğ›¼âŸ©1ğµ) = 1{ğ‘ â‰¥ ğ‘›â€²}. Next, similar to Algorithm 5, Reconstğ¿ (âŸ¨corrâŸ©0ğ¿, âŸ¨corrâŸ©1ğ¿) = corr = ReconstÎ” (âŸ¨corrâŸ©0Î”, âŸ¨corrâŸ©1Î”), where corr is as defined in Theorem 4.1. Given the bounds on value of ğ´ (as discussed above), it easy to see that Steps 16&17 compute arithmetic shares of ğ´, and ğ´0 = (ğ´ âˆ’ ğ‘‘), ğ´1 = ğ´, ğ´2 =

Algorithm 9 Integer ring division, Î rDinIVg,ğ‘›,ğ‘‘ :

Input:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

holds âŸ¨ğ‘âŸ©ğ‘›, where ğ‘
ğ‘

âˆˆ

Zğ‘› .

Output:

For ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

learns

âŸ¨ğ‘§âŸ©ğ‘›
ğ‘

s.t.

ğ‘§

=

rdiv(ğ‘, ğ‘‘).

1:

For ğ‘

âˆˆ

{0,

1},

let

ğ‘ğ‘ ,

ğ‘0
ğ‘

,

ğ‘1
ğ‘

âˆˆ Z and ğ‘›0, ğ‘›1, ğ‘›â€² âˆˆ Z be as defined

in Theorem 4.1. Let ğœ‚ = âŒˆlog(ğ‘›)âŒ‰, ğ›¿ = âŒˆlog 6ğ‘‘âŒ‰, and Î” = 2ğ›¿ .

2:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

invokes FDriRnegL,ğ‘›U

with input

âŸ¨ğ‘âŸ©ğ‘›
ğ‘

to learn

3:

output For ğ‘ âˆˆ

âŸ¨ğ›¼

âŸ©ğµ
ğ‘

.

Party

ğ‘ƒğ‘

{0, 1}, ğ‘ƒğ‘ sets

sets ğ‘¥ğ‘ =

âŸ¨ğ‘šâŸ©ğµ =
ğ‘
1{âŸ¨ğ‘âŸ©ğ‘›
ğ‘

âŸ¨ğ›¼âŸ©ğµ âŠ• â‰¥ ğ‘›ğ‘â€²}.

ğ‘.

4: ğ‘ƒ0 samples âŸ¨corrâŸ©0ğ‘› â†$ Zğ‘› and âŸ¨corrâŸ©0Î” â†$ ZÎ”.

5: for ğ‘— = {00, 01, 10, 11} do

6: ğ‘ƒ0 computes ğ‘¡ ğ‘— = (âŸ¨ğ‘šâŸ©0ğµ âŠ• ğ‘—0 âŠ• ğ‘¥0) âˆ§ (âŸ¨ğ‘šâŸ©0ğµ âŠ• ğ‘—0 âŠ• ğ‘—1) s.t. ğ‘— = (ğ‘—0||ğ‘—1).

7: if ğ‘¡ ğ‘— âˆ§ 1{ğ‘¥0 = 0} then

8:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ‘› âˆ’âŸ¨corrâŸ©0ğ‘› âˆ’ 1 and ğ‘Ÿ ğ‘— =Î” âˆ’âŸ¨corrâŸ©0Î” âˆ’ 1.

9: else if ğ‘¡ ğ‘— âˆ§ 1{ğ‘¥0 = 1} then

10:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ‘› âˆ’âŸ¨corrâŸ©0ğ‘› + 1 and ğ‘Ÿ ğ‘— =Î” âˆ’âŸ¨corrâŸ©0Î” + 1.

11: else

12:

ğ‘ƒ0 sets ğ‘  ğ‘— =ğ‘› âˆ’âŸ¨corrâŸ©0ğ‘› and ğ‘Ÿ ğ‘— =Î” âˆ’âŸ¨corrâŸ©0Î”.

13: end if

14: end for

15:

ğ‘ƒ0 & ğ‘ƒ1 invoke an instance of

4 1

-OTğœ‚+ğ›¿

where ğ‘ƒ0

is

the sender

with inputs {ğ‘  ğ‘— ||ğ‘Ÿ ğ‘— }ğ‘— and ğ‘ƒ1 is the receiver with input âŸ¨ğ‘šâŸ©1ğµ ||ğ‘¥1.

ğ‘ƒ1 sets its output as âŸ¨corrâŸ©1ğ‘› ||âŸ¨corrâŸ©1Î”.

16:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

sets âŸ¨ğ´âŸ©Î”
ğ‘

=Î”

ğ‘0
ğ‘

âˆ’

(ğ‘¥ğ‘

âˆ’ âŸ¨corrâŸ©Î”) Â· ğ‘›0.
ğ‘

17:

For ğ‘

âˆˆ

{0, 1}, ğ‘ƒğ‘

sets âŸ¨ğ´0âŸ©ğ‘Î”

=Î”

âŸ¨ğ´âŸ©Î” âˆ’ ğ‘
ğ‘

Â· ğ‘‘, âŸ¨ğ´1âŸ©ğ‘Î”

=

âŸ¨ğ´âŸ©Î”,
ğ‘

and

âŸ¨ğ´2âŸ©ğ‘Î”

=Î”

âŸ¨ğ´âŸ©Î”
ğ‘

+ğ‘

Â· ğ‘‘.

18: for ğ‘— = {0, 1, 2} do

19:

For

ğ‘

âˆˆ

{0,

1},

ğ‘ƒğ‘

invokes

FDinRte,ğ›¿LU

with

input

âŸ¨ğ´

ğ‘—

âŸ©Î”
ğ‘

to

learn

output

âŸ¨ğ›¾

ğ‘—

âŸ©ğµ
ğ‘

.

Party

ğ‘ƒğ‘

sets

âŸ¨ğ¶ â€²âŸ©ğµ
ğ‘—ğ‘

=

âŸ¨ğ›¾

ğ‘—

âŸ©ğµ
ğ‘

âŠ•

ğ‘.

20: For ğ‘ âˆˆ {0, 1}, ğ‘ƒğ‘ invokes an instance of FBğ‘›2A with input

âŸ¨ğ¶ â€²âŸ©ğµ
ğ‘—ğ‘

and

learns

âŸ¨ğ¶

ğ‘—

âŸ©ğ‘›
ğ‘

.

21: end for

22:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

sets âŸ¨ğ¶âŸ©ğ‘›
ğ‘

=

âŸ¨ğ¶0âŸ©ğ‘ğ‘›

+

âŸ¨ğ¶1

âŸ©ğ‘›
ğ‘

+

âŸ¨ğ¶2 âŸ©ğ‘ğ‘› .

23:

For ğ‘

âˆˆ {0, 1}, ğ‘ƒğ‘

sets ğµğ‘

= idiv(ğ‘0
ğ‘

âˆ’ ğ‘¥ğ‘

Â· ğ‘›0, ğ‘‘).

24:

ğ‘ƒğ‘

sets âŸ¨ğ‘§âŸ©ğ‘›
ğ‘

=ğ‘›

rdiv ( âŸ¨ğ‘âŸ©ğ‘› ,
ğ‘

ğ‘‘)

+

âŸ¨corrâŸ©ğ‘›
ğ‘

Â·

ğ‘›1

+

ğ‘

âˆ’

âŸ¨ğ¶ âŸ©ğ‘›
ğ‘

âˆ’

ğµğ‘

,

for

ğ‘ âˆˆ {0, 1}.

(ğ´ + ğ‘‘), respectively. Now, invocation of FDinRte,ğ›¿LU on shares of ğ´ğ‘—

(Step 19) returns boolean shares of ğ›¾ = (1 âŠ• MSB(ğ´ğ‘— )) over ğ›¿ bit

integers, which is same as 1 âŠ• 1{ğ´ğ‘—

<

0}

over

Z.

Hence,

ğ¶â€²
ğ‘—

=

Reconstğµ

( âŸ¨ğ¶

â€² ğ‘—

âŸ©0ğµ

,

âŸ¨ğ¶

â€²âŸ©1ğµ

)

=

1{ğ´ ğ‘—

<

0}. By correctness of FBğ‘›2A,

step 22 computes arithmetic shares of ğ¶ as defined in Theorem 4.1.

In step 23, ğµ0 + ğµ1 =ğ‘› ğµ as defined. Hence, correctness holds and

âŸ¨ğ‘§âŸ©ğ‘› are shares of rdiv(ğ‘, ğ‘‘).
ğ‘
Given that âŸ¨corrâŸ©0ğ‘› and âŸ¨corrâŸ©0Î” are uniformly random, security

of

the

protocol

is

easy

to

see

in

(

4 1

-OTğœ‚+ğ›¿ , FDinRte,ğ›¿LU, FBğ‘›2A)-hybrid.

Communication complexity. Î rDinIVg,ğ‘›,ğ‘‘ involves a single call to FDriRnegL,ğ‘›U

and

4 1

-OTğœ‚+ğ›¿ ,

and

three

calls

each

to

FDinRte,ğ›¿LU

and

FBğ‘›2A.

From

Appendix

B,

we

have

the

cost

of

FDriRnegL,ğ‘›U

as

3 2

ğœ†ğœ‚

+ 27ğœ‚

âˆ’

ğœ† 2

âˆ’

13

bits.

4 1

-OTğœ‚+ğ›¿

and

3

Ã—

FBğ‘›2A

cost

2ğœ†

+

4

Â·

(ğœ‚

+

ğ›¿)

and

3ğœ†

+

3ğœ‚

bits

respectively.

Since

the

cost

of

FDinRte,â„“LU

is

ğœ†â„“

+

13

1 2

â„“

âˆ’

3ğœ†

âˆ’

35

1 2

bits

(see

Appendix

B),

3

Ã—

FDinRte,ğ›¿LU

requires

3ğœ†ğ›¿

+

40

1 2

ğ›¿

âˆ’

9ğœ†

âˆ’

106

1 2

bits

of communication. Thus, the overall communication of Î rDinIVg,ğ‘›,ğ‘‘ is

3 2

ğœ†ğœ‚

+

34ğœ‚

+

3ğœ†ğ›¿

+

44

1 2

ğ›¿

âˆ’

4

1 2

ğœ†

âˆ’

119

1 2

,

which

can

be

rewritten

as

<

(

3 2

ğœ†

+

34)

Â·

(ğœ‚

+

2ğ›¿

)

.

Concretely, we

get

the

best communication for

Î rDinIVg,ğ‘›,49 (ğœ‚ = 32) by setting ğ‘š = 7 in all our millionaire invocations,

which results in a total communication of 7796 bits.

Note that for the case of â„“-bit integers, our division protocol

would require a call to FDinRte,â„“LU and

4 1

-OTâ„“+ğ›¿ ,

and

three

calls

each

to FDinRte,ğ›¿LU and FBğ¿2A. The cost of FDinRte,â„“LU and 3 Ã— FDinRte,ğ›¿LU are as

mentioned in the previous paragraph, and the cost of

4 1

-OTâ„“ +ğ›¿

and FBğ¿2A are 2ğœ† + 4 Â· (â„“ + ğ›¿) and 3ğœ† + 3â„“ bits respectively. Thus, the

overall

communication

is

ğœ†â„“

+

3ğœ†ğ›¿

+

20

1 2

â„“

+

44

1 2

ğ›¿

âˆ’

7ğœ†

âˆ’

142

bits,

which can be rewritten as < (ğœ† + 21) Â· (â„“ + 3ğ›¿). By setting ğ‘š = 8 in

all our millionaire invocations, we get the best communication of 5570 bits for Î iDnItV,32,49.

E INPUT ENCODING
Neural network inference performs computations on floatingpoint numbers, whereas the secret-sharing techniques only work for integers in a ring Zğ‘›, for any ğ‘› âˆˆ N.12
To represent a floating-point number ğ‘¥ âˆˆ Q in the ring Zğ‘›, we encode it as a fixed-point integer ğ‘ = âŒŠğ‘¥ Â· 2ğ‘  âŒ‹ mod ğ‘› with scale ğ‘ . Fixed-point arithmetic is performed on the encoded input values (in the secure domain) and the same scale ğ‘  is maintained for all the intermediate results. The ring size ğ‘› and the scale ğ‘  are chosen such that the absolute value of any intermediate result does not exceed the bound âŒŠğ‘›/2âŒ‹ and there is no loss in accuracy (refer Appendix I).

F IMPROVEMENT TO GAZELLEâ€™S

ALGORITHM

Gazelle [43] proposed two methods for computing convolutions,

namely, the input rotations and the output rotations method. The

only difference between the two methods is the number of (homomorphic) rotations required13. In this section, we describe an

optimization to reduce the number of rotations required by the

output rotations method.

Let ğ‘ğ‘– and ğ‘ğ‘œ denote the number of input and output channels

respectively, and ğ‘ğ‘› denote the number of channels that can fit in

a single ciphertext. At a high level, the output rotations method

works as follows: after performing all the convolutions homomor-

phically, we have ğ‘ğ‘– Â· ğ‘ğ‘œ /ğ‘ğ‘› intermediate ciphertexts that are to

be accumulated to form tightly packed output ciphertexts. Since

most of these ciphertexts are misaligned after the convolution, they

must be rotated in order to align and pack them. The intermediate

ciphertexts can be grouped into ğ‘ğ‘œ /ğ‘ğ‘› groups of ğ‘ğ‘– ciphertexts each,

such that the ciphertexts within each group are added (after align-

ment) to form a single ciphertext. In [43], the ciphertexts within

each

group

are

rotated

(aligned)

individually,

resulting

in

â‰ˆ

ğ‘ğ‘–

Â·

ğ‘ğ‘œ ğ‘ğ‘›

rotations. We observe that these groups can be further divided into

12Note that this includes the case of â„“-bit integers when ğ‘› = 2â„“ . 13The number of homomorphic additions also differ, but they are relatively very cheap.

17

Benchmark

Bitwidth

Scale

TF Top 1

Fixed Top 1

TF Top 5

Fixed Top 5

SqueezeNet

32

ResNet50

37

DenseNet121 32

9 55.86 55.90 79.18 79.22 12 76.47 76.45 93.21 93.23 11 74.25 74.35 91.88 91.90

Table 10: Summary of the accuracy achieved by fixed-point

code vs input TensorFlow (TF) code.

Benchmark
SqueezeNet ResNet50 DenseNet121

Garbled Circuits LAN WAN Comm
0.2 2.0 36.02 0.4 3.9 96.97 17.2 179.4 6017.94
(a) over Z2â„“

Our Protocol LAN WAN Comm
0.1 0.8 1.84 0.1 0.8 2.35 0.5 3.5 158.83

Benchmark

Garbled Circuits

Our Protocol

LAN WAN Comm LAN WAN Comm

SqueezeNet 0.2 2.2 39.93 0.1 ResNet50 0.4 4.2 106.22 0.1 DenseNet121 19.2 198.2 6707.94 0.6

0.9 1.92 1.0 3.82 4.4 214.94

(b) over Zğ‘›

Table 9: Performance comparison of Garbled Circuits with our protocols for computing Avgpool layers. Runtimes are in seconds and communication numbers are in MiB.

ğ‘ğ‘› subgroups of ğ‘ğ‘– /ğ‘ğ‘› ciphertexts each, such that ciphertexts within

a subgroup are misaligned by the same offset. Doing this has the

advantage that the ğ‘ğ‘– /ğ‘ğ‘› ciphertexts within each subgroup can first

be added and then the resulting ciphertext can be aligned using

a single rotation. This brings down the number of rotations by a

factor

of

ğ‘ğ‘– /ğ‘ğ‘›

to

â‰ˆ

ğ‘ğ‘›

Â·

ğ‘ğ‘œ ğ‘ğ‘›

.

With our optimization, the output rotations method is better

than the input rotations method when ğ‘“ 2 Â· ğ‘ğ‘– > ğ‘ğ‘œ , where ğ‘“ 2 is the

filter size, which is usually the case.

G COMPLEXITY OF OUR BENCHMARKS
The complexity of the benchmarks we use in Section 7 is summarized as follows:
â€¢ SqueezeNet: There are 26 convolution layers of maximum filter size 3 Ã— 3 and up to 1000 output channels. The activations after linear layers are ReLUs with size of up to 200,704 elements per layer. All ReLU layers combined have a size of

2,033,480. Additionally, there are 3 Maxpool layers and an Avgpool169 layer (Avgpool with pool size 169). â€¢ ResNet50: There are 53 convolution layers of maximum filter size 7 Ã— 7 and a peak output channel count of 2048. Convolution layers are followed by batch normalization and then ReLUs. There are 49 ReLU layers totaling 9,006,592 ReLUs, where the biggest one consists of 802,816 elements. Moreover, ResNet50 also has Maxpool layers and an Avgpool49. â€¢ DenseNet121: There are 121 convolution layers with maximum filter dimension of 7 Ã— 7 and up to 1000 output channels. Similar to ResNet50, between 2 convolution layers, there is batch normalization followed by ReLU. The biggest ReLU layer in DenseNet121 has 802,816 elements and the combined size of all ReLU layers is 15,065,344. In addition, DenseNet121 consists of a Maxpool, an Avgpool49 and 3 Avgpool4 layers.
H GARBLED CIRCUITS VS OUR PROTOCOLS
FOR Avgpool
In this section, we compare our protocols with garbled circuits for evaluating the Avgpool layers of our benchmarks, and the corresponding performance numbers are given in Table 9. On DenseNet121, where a total of 176, 640 divisions are performed, we have improvements over GC of more than 32Ã— and 45Ã— in the LAN and the WAN setting, respectively, for both our protocols. However, on SqueezeNet and ResNet50, the improvements are smaller (2Ã— to 7Ã—) because these DNNs only require 1000 and 2048 divisions, respectively, which are not enough for the costs in our protocols to amortize well. On the other hand, the communication difference between our protocols and GC is huge for all three DNNs. Specifically, we have an improvement of more than 19Ã—, 27Ã—, and 31Ã— on SqueezeNet, ResNet50, and DenseNet121 respectively, for both our protocols.
I FIXED-POINT ACCURACY OF OUR
BENCHMARKS
In this section, we show that the accuracy achieved by the fixedpoint code matches the accuracy of the input TensorFlow code. Table 10 summarizes the bitwidths, the scales, and the corresponding TensorFlow (TF) and fixed-point accuracy for each of our benchmarks. Since our truncation and division protocols lead to faithful implementation of fixed-point arithmetic, accuracy of secure inference is the same as the fixed-point accuracy.

18

