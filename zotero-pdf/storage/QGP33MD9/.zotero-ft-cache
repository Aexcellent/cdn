A FULLY HOMOMORPHIC ENCRYPTION SCHEME
A DISSERTATION SUBMITTED TO THE DEPARTMENT OF COMPUTER SCIENCE
AND THE COMMITTEE ON GRADUATE STUDIES OF STANFORD UNIVERSITY
IN PARTIAL FULFILLMENT OF THE REQUIREMENTS FOR THE DEGREE OF
DOCTOR OF PHILOSOPHY
Craig Gentry September 2009

c Copyright by Craig Gentry 2009 All Rights Reserved
ii

I certify that I have read this dissertation and that, in my opinion, it is fully adequate in scope and quality as a dissertation for the degree of Doctor of Philosophy.
(Dan Boneh) Principal Adviser
I certify that I have read this dissertation and that, in my opinion, it is fully adequate in scope and quality as a dissertation for the degree of Doctor of Philosophy.
(John Mitchell)
I certify that I have read this dissertation and that, in my opinion, it is fully adequate in scope and quality as a dissertation for the degree of Doctor of Philosophy.
(Serge Plotkin)
Approved for the University Committee on Graduate Studies.
iii

Abstract
We propose the ﬁrst fully homomorphic encryption scheme, solving a central open problem in cryptography. Such a scheme allows one to compute arbitrary functions over encrypted data without the decryption key – i.e., given encryptions E(m1), . . . , E(mt) of m1, . . . , mt, one can eﬃciently compute a compact ciphertext that encrypts f (m1, . . . , mt) for any eﬃciently computable function f . This problem was posed by Rivest et al. in 1978.
Fully homomorphic encryption has numerous applications. For example, it enables private queries to a search engine – the user submits an encrypted query and the search engine computes a succinct encrypted answer without ever looking at the query in the clear. It also enables searching on encrypted data – a user stores encrypted ﬁles on a remote ﬁle server and can later have the server retrieve only ﬁles that (when decrypted) satisfy some boolean constraint, even though the server cannot decrypt the ﬁles on its own. More broadly, fully homomorphic encryption improves the eﬃciency of secure multiparty computation.
Our construction begins with a somewhat homomorphic “boostrappable” encryption scheme that works when the function f is the scheme’s own decryption function. We then show how, through recursive self-embedding, bootstrappable encryption gives fully homomorphic encryption. The construction makes use of hard problems on ideal lattices.
iv

Acknowledgments
This thesis would have been impossible without the support and mentoring of my advisor, Dan Boneh. Even after several years of working with him, I am constantly surprised by his amazing intelligence, inﬁnite energy, boundless optimism, and genuine friendliness. I wish I could incorporate more of his qualities. I have limited optimism about my chances.
In a presentation to my fellow Ph.D. admits four years ago, Dan highlighted fully homomorphic encryption as an interesting open problem and guaranteed an immediate diploma to anyone who solved it. Perhaps I took him too literally. He certainly neglected to mention how much writing would be involved. But I have never gone wrong following his advice.
I have also received a lot of input and support from my friends in the IBM Crypto Group, where I’ve interned for the past couple of summers, and where I will be working permanently – namely, Ran Canetti (now at Tel Aviv University), Rosario Gennaro, Shai Halevi, Charanjit Jutla, Hugo Krawczyk, Tal Rabin, and Vinod Vaikuntanathan (postdoc). These discussions have led to signiﬁcant performance optimizations. Also, Tal Rabin has been particularly helpful in terms of optimizing my own performance, so that I could ﬁnally ﬁnish the thesis.
I have had helpful discussions and received comments and suggestions from many other people, including (non-exhaustively): Boaz Barak, Marten van Dijk, Shaﬁ Goldwasser, Iftach Haitner, Michael Hamburg, Susan Hohenberger, Yuval Ishai, Yael Tauman Kalai, Vadim Lyubashevsky, Daniele Micciancio, Chris Peikert, Oded Regev, Alon Rosen, Amit Sahai, Adam Smith, Salil Vadhan, and Brent Waters.
This work was supported by the NSF, a Stanford Graduate Fellowship and an IBM PhD fellowship.
v

Contents

Abstract

iv

Acknowledgments

v

1 Introduction

1

1.1 A Very Brief and Informal Overview of Our Construction . . . . . . . . . . 2

1.2 What is Fully Homomorphic Encryption? . . . . . . . . . . . . . . . . . . . 5

1.3 Bootstrapping a Scheme that Can Evaluate its Own Decryption Circuit . . 7

1.4 Ideal Lattices: Ideally Suited to Construct Bootstrappable Encryption . . . 10

1.5 Squashing the Decryption Circuit: The Encrypter Starts Decryption! . . . . 15

1.6 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

1.7 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

1.8 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2 Deﬁnitions related to Homomorphic Encryption

27

2.1 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

2.2 Computational Security Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . 31

3 Previous Homomorphic Encryption Schemes

34

4 Bootstrappable Encryption

43

4.1 Leveled Fully Homomorphic Encryption from Bootstrappable Encryption, Generically 43

4.2 Correctness, Computational Complexity and Security of the Generic Construction 48

4.3 Fully Homomorphic Encryption from KDM-Secure Bootstrappable Encryption 51

4.4 Fully Homomorphic Encryption from Bootstrappable Encryption in the Random Oracle Model 5

vi

5 An Abstract Scheme Based on the Ideal Coset Problem

57

5.1 The Ideal Coset Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

5.2 An Abstract Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

5.3 Security of the Abstract Scheme . . . . . . . . . . . . . . . . . . . . . . . . 62

6 Background on Ideal Lattices I: The Basics

63

6.1 Basic Background on Lattices . . . . . . . . . . . . . . . . . . . . . . . . . . 63

6.2 Basic Background on Ideal Lattices . . . . . . . . . . . . . . . . . . . . . . . 65

6.3 Probability Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68

7 A Somewhat Homomorphic Encryption Scheme

69

7.1 Why Lattices? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69

7.2 Why Ideal Lattices? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

7.3 A Geometric Approach to Maximizing the Circuit Depth that Can Be Evaluated 70

7.4 Instantiating the Ring: The Geometry of Polynomial Rings . . . . . . . . . 72

7.5 Instantiating Encrypt and Minimizing rEnc . . . . . . . . . . . . . . . . . . . 75 7.6 Instantiating Decrypt and Maximizing rDec . . . . . . . . . . . . . . . . . . . 75 7.7 Security of the Concrete Scheme . . . . . . . . . . . . . . . . . . . . . . . . 77

7.8 How Useful is the Somewhat Homomorphic Scheme By Itself? . . . . . . . . 79

8 Tweaks to the Somewhat Homomorphic Scheme

81

8.1 On the Relationship between the Dual and the Inverse of an Ideal Lattice . 82

8.2 Transference Lemmas for Ideal Lattices . . . . . . . . . . . . . . . . . . . . 85

8.3 Tweaking the Decryption Equation . . . . . . . . . . . . . . . . . . . . . . . 86

8.4 A Tweak to Reduce the Circuit Complexity of the Rounding Step in Decryption 88

9 Decryption Complexity of the Tweaked Scheme

90

10 Squashing the Decryption Circuit

98

10.1 A Generic Description of the Transformation . . . . . . . . . . . . . . . . . 98

10.2 How to Squash, Concretely . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

10.3 Bootstrapping Achieved: The Decryption Circuit for the Transformed System 102

11 Security

104

11.1 Regarding the Hint Given in Our “Squashing” Transformation . . . . . . . 104

vii

11.2 Counterbalancing Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . 113

12 Performance and Optimizations

115

12.1 Simple Optimizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116

12.2 Basic Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

12.3 More Optimizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

13 Background on Ideal Lattices II

125

13.1 Overview of Gaussian Distributions over Lattices . . . . . . . . . . . . . . . 125

13.2 The Smoothing Parameter . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

13.3 Sampling a Lattice According to a Gaussian Distribution . . . . . . . . . . 128

13.4 Ideal Factorization in Polynomial Rings . . . . . . . . . . . . . . . . . . . . 129

14 The Somewhat Homomorphic Scheme Revisited

132

14.1 Using Gaussian Sampling in Encrypt . . . . . . . . . . . . . . . . . . . . . . 132

14.2 Generating an Ideal with Very Small Norm . . . . . . . . . . . . . . . . . . 133

14.3 Proof of Security Based on the Inner Ideal Membership Problem (IIMP) . . 135

14.4 Success Ampliﬁcation: Proof of Security Based on the Modiﬁed IIMP (MIIMP)136

14.5 Basing Security on a Search Problem: Bounded Distance Decoding Via Hensel Lifting138

14.6 Toward Reducing the SIVP to the BDDP: Regev’s Quantum Reduction . . 141

14.7 Summary of Security Results for this Construction So Far . . . . . . . . . . 143

14.8 Looking Forward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143

15 Background on Ideal Lattices III

145

15.1 Lemmata Regarding Vectors Nearly Parallel to e1 . . . . . . . . . . . . . . 145 15.2 Distribution of Prime Ideals . . . . . . . . . . . . . . . . . . . . . . . . . . . 148

16 Random Self-Reduction of Ideal Lattice Problems

151

16.1 A New Type of Worst-Case / Average-Case Connection for Lattices . . . . 151

16.2 Our Average-Case Distribution . . . . . . . . . . . . . . . . . . . . . . . . . 153

16.3 How to “Randomize” a Worst-Case Ideal . . . . . . . . . . . . . . . . . . . 154

16.4 Why Does the Reduction Require a Factoring Oracle? . . . . . . . . . . . . 157

16.5 Application to our Fully Homomorphic Encryption Scheme . . . . . . . . . 159

viii

17 How to Randomize a Worst-Case Ideal

161

17.1 The RandomizeIdeal Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 161

17.2 Is the Ideal Random? The Proof of Theorem 16.3.4 . . . . . . . . . . . . . . 162

17.3 Reduction of WBDDP to HBDDP and Worst-case IVIP to Average-Case IVIP164

17.4 An Alternative Way to Randomize an Ideal . . . . . . . . . . . . . . . . . . 166

18 KeyGen per the Average Case Distribution

175

18.1 The Secret Key . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175

18.2 Adapting Kalai’s Algorithm to Generate a Random Factored Ideal . . . . . 177

19 Basing Security on Worst-case SIVP in Ideal Lattices

181

19.1 Relationship Among Instances of IVIP . . . . . . . . . . . . . . . . . . . . . 182

19.2 Reduction of SIVP to IVIP . . . . . . . . . . . . . . . . . . . . . . . . . . . 183

20 Circuit Privacy

188

Bibliography

190

ix

List of Tables
x

Chapter 1
Introduction
We propose a solution to the old open problem of constructing a fully homomorphic encryption scheme. This notion, originally called a privacy homomorphism, was introduced by Rivest, Adleman and Dertouzous [120] shortly after the invention of RSA by Rivest, Shamir, and Adleman [121]. Basic RSA is a multiplicatively homomorphic encryption scheme – i.e., given RSA public key pk = (N, e) and ciphertexts {ψi ← πie mod N }, one can eﬃciently compute i ψi = ( i πi)e mod N , a ciphertext that encrypts the product of the original plaintexts. One imagines that it was RSA’s multiplicative homomorphism, an accidental but useful property, that led Rivest et al. [120] to ask a natural question: What can one do with an encryption scheme that is fully homomorphic: a scheme E with an eﬃcient algorithm EvaluateE that, for any valid public key pk, any circuit C (not just a circuit consisting of multiplication gates as in RSA), and any ciphertexts ψi ← EncryptE (pk, πi), outputs
ψ ← EvaluateE (pk, C, ψ1, . . . , ψt) ,
a valid encryption of C(π1, . . . , πt) under pk? Their answer: one can arbitrarily compute on encrypted data – i.e., one can process encrypted data (query it, write into it, do anything to it that can be eﬃciently expressed as a circuit) without the decryption key. As an application, they suggested private data banks. A user can store its data on an untrusted server in encrypted form. Later, it can send a query on the data to the server, whereupon the server can express this query as a circuit to be applied to the data, and use the EvaluateE algorithm to construct an encrypted response to the user’s query, which the user then decrypts. We obviously want the server’s response here to be more concise than the trivial
1

CHAPTER 1. INTRODUCTION

2

solution, in which the server just sends all of the encrypted data back to the user to process on its own.
Cryptographers have accumulated a long assortment of “killer” applications for fully homomorphic encryption since then. (See Section 1.8.) However, until now, we did not have a viable construction.
1.1 A Very Brief and Informal Overview of Our Construction
Imagine you have an encryption scheme with a “noise parameter” attached to each ciphertext, where encryption outputs a ciphertext with small noise – say, less than n – but decryption works as long as the noise is less than some threshold N n. Furthermore, imagine you have algorithms Add and Mult that can take ciphertexts E(a) and E(b) and compute E(a + b) and E(a ∗ b), but at the cost of adding or multiplying the noise parameters. This immediately gives a “somewhat homomorphic” encryption scheme that can handle circuits of depth roughly log log N − log log n.
Now suppose that you have an algorithm Recrypt that takes a ciphertext E(a) with noise N < N and outputs a “fresh” ciphertext E(a) that also encrypts a, but which has
√ noise parameter smaller than N . This Recrypt algorithm is enough to construct a fully homomorphic scheme out of the somewhat homomorphic one! In particular, before we Add or Mult E(a) and E(b), we can apply Recrypt to E(a) and E(b) to ensure that their noise parameters are small enough so that the noise parameter of E(a ∗ b) is less than N , and so on recursively.
In our construction, we give a somewhat homomorphic encryption scheme. We then show how to modify it so that its decryption circuit has multiplicative depth at most log log N − log log n − 1 – i.e., less depth than what the scheme can handle. It turns out that a somewhat homomorphic encryption scheme that has this self-referential property of being able to handle circuits that are deeper than its own decryption circuit – in which case we say the somewhat homomorphic encryption scheme is “bootstrappable” – is enough to obtain the Recrypt algorithm, and thereby fully homomorphic encryption! In Chapter 1.3 and Chapter 4, we give more details on why bootstrappability is enough.
Our somewhat homomorphic encryption scheme, described in Chapters 5 and 7, uses “ideal lattices”. In our exposition, we try to defer the need for technical details about lattices for as long as possible. For now, we mention that we looked to ideal lattices as

CHAPTER 1. INTRODUCTION

3

a way to construct a bootstrappable encryption scheme for two reasons. First, the circuit complexity of the decryption algorithms in typical lattice based encryption schemes is very low, especially compared to schemes like RSA or ElGamal, which rely on exponentiation, an operation that we do not know how to parallelize well. Second, since ideal lattices correspond to ideals in polynomial rings, they inherit natural Add and Mult operations from the ring. (Additionally, ideal lattices are also appealing since we can base security on standard “hard” problems over ideal lattices, which, as far as we know, are typically just as hard as problems over general lattices.)
However, it takes some work to make our somewhat homomorphic scheme bootstrappable – i.e., to make the depth of decryption circuit shallower than what the scheme can handle. In Chapters 8 and 10, we describe how to modify the scheme to make the decryption circuit suﬃciently shallow. Conceptually, our techniques here are similar to those used in server-aided cryptography, where (for example) a user with a slow device wants to delegate most of the decryption work to a server without allowing the server to completely decrypt on its own. In our modiﬁcation, we place a “hint” about the secret key inside the public key. This hint is not enough to decrypt a ciphertext output by the original scheme, but it can be used to “process” the ciphertext – i.e., construct a new ciphertext (that encrypts the same thing) that can be decrypted by a very shallow circuit. To prove that this hint is not too revealing, we require a second computational hardness assumption, similar to ones that have been studied in the context of server-aided cryptography.
Just to leave you with a ﬂavor of what our somewhat homomorphic encryption scheme looks like, consider the following secret key encryption scheme which merely uses integers. The key is an odd integer p > 2N . An encryption of a bit b is simply a random multiple of p, plus a random integer B with the same parity as b – i.e., B is even if b = 0 and is odd if b = 1. A bit more concretely, the ciphertext is c = b + 2x + kp, where x is a random integer in (−n/2, n/2), and k is an integer chosen from some range. You decrypt by setting b ← (c mod p) mod 2, where (c mod p) is the number in (−p/2, p/2) that equals c modulo p. Actually, (c mod p), which is the “noise parameter” in this scheme, will be in [−n, n], since b + 2x is in that range. However, decryption would have worked correctly as long as b + 2x ∈ [−N, N ] ⊂ (−p/2, p/2). (As an aside relevant to bootstrapping, we mention that computing c mod p can be done by a very shallow circuit, with depth logarithmic in the bit-lengths of c and p.)
Now consider what happens when you add two ciphertexts. You get a ciphertext that

CHAPTER 1. INTRODUCTION

4

has a similar format to the original ones. Speciﬁcally,
c ← c1 + c2 = b1 + b2 + 2(x1 + x2) + (k1 + k2)p = b1 ⊕ b2 + 2x + kp
for some integers x and k. Decryption recovers b1 ⊕ b2 as long as (b1 + 2x1) + (b2 + 2x2) ∈ [−N, N ]. Multiplication also gives ciphertexts with a similar format.
c ← c1 ∗ c2 = b1 ∗ b2 + 2(b1x2 + b2x1 + 2x1x2) + kp = b1 ∗ b2 + 2x + kp
for some integers x and k. Decryption works whenever (b1 + 2x1) ∗ (b2 + 2x2) ∈ [−N, N ]. A crucial advantage of replacing integers in the scheme above with ideal lattices is that
an ideal lattice has many representations or “bases”. Some bases are “good” and can be used as the secret key, while some are “bad” and can be used as the public key – i.e., they are good enough to be used for encryption, but not decryption. So, ideal lattices give us a public key scheme. On the other hand, it is unclear whether the integer p in the toy scheme above can be represented in a way that is useful for encryption but not decryption (nor is security clear even for the secret key version of the scheme).
But, for a moment, imagine that there are good and bad representations of p, such the bad representation can be used in encryption but cannot be used to distinguish whether an integer is close to a multiple of p or is uniform modulo p. How would we prove security? If there is an adversary A that can break semantic security, B uses A to decide which distribution an integer m comes from as follows: give A the challenge ciphertext c = b + 2m + kp for random k. If m is close to a multiple of p, then so is 2m, and the closest p-multiple is an even distance away; in particular, b + 2m ∈ [−N, N ] mod p and b + 2m mod p = b, the challenge ciphertext decrypts correctly to b, and A should guess b with non-negligible advantage. But if m is uniform modulo p, then so is 2m (since p is odd), c is independent of b, and A has no advantage. Basically, B can distinguish the distribution that m came from by observing whether A guesses correctly with non-negligible advantage. In Chapter 5, we provide a conceptually similar proof of our ideal lattice scheme based on the ideal coset problem (ICP).
Over the next few Sections, we provide more details about our construction, its security and applications, but still somewhat informally.

CHAPTER 1. INTRODUCTION

5

1.2 What is Fully Homomorphic Encryption?
Our ultimate goal is to construct a fully homomorphic encryption scheme E. First, let us discuss what it means to be fully homomorphic.
At a high-level, the essence of fully homomorphic encryption is simple: given ciphertexts that encrypt π1, . . . , πt, fully homomorphic encryption should allow anyone (not just the key-holder) to output a ciphertext that encrypts f (π1, . . . , πt) for any desired function f , as long as that function can be eﬃciently computed. No information about π1, . . . , πt or f (π1, . . . , πt), or any intermediate plaintext values, should leak; the inputs, output and intermediate values are always encrypted.
Formally, there are diﬀerent ways of deﬁning what it means for the ﬁnal ciphertext to “encrypt” f (π1, . . . , πt). The minimal requirement is correctness. A fully homomorphic encryption scheme E should have an eﬃcient algorithm EvaluateE that, for any valid E key pair (sk, pk), any circuit C, and any ciphertexts ψi ← EncryptE (pk, πi), outputs
ψ ← EvaluateE (pk, C, ψ1, . . . , ψt) such that DecryptE (sk, ψ) = C(π1, . . . , πt)
This minimal requirement does not seem to be suﬃcient, however, since it permits the trivial solution, where ψ simply consists of (C, ψ1, . . . , ψt) – i.e., where the EvaluateE algorithm does not “process” the input ciphertexts at all.
There are a couple of diﬀerent ways of excluding the trivial solution. One way is to require circuit privacy – i.e., (roughly) that the output of EvaluateE reveals nothing (at least computationally) about the circuit C that it took as input. If circuit privacy is the only additional requirement, then fully homomorphic encryption (under this deﬁnition) can easily be achieved by using a two-ﬂow oblivious transfer (OT) protocol in combination with Yao’s garbled circuit [129, 130]. Typically two-ﬂow OT protocols use an additively homomorphic encryption scheme, and the OT query consists of a ciphertext ψ in this encryption scheme. In the fully homomorphic scheme, Evaluate(pk, C, ψ1, . . . , ψt) constructs a Yao garbling C† of C, uses the OT queries ψ1, . . . , ψt to construct OT responses ψ1∗, . . . , ψt∗ designed to obliviously transfer Yao keys associated to the t input wires in C†, and outputs (C†, ψ1∗, . . . , ψt∗). To decrypt this ciphertext, the key holder “decrypts” the OT responses ψ1∗, . . . , ψt∗ to recover Yao keys for the input wires, and then evaluates the garbled circuit. Sanders, Young and Yung [122] and Beaver [14] show how to achieve statistical circuit privacy, but only for limited classes of circuits – namely, NC1 and NLOGSPACE.

CHAPTER 1. INTRODUCTION

6

The more interesting way of excluding the trivial solution is to require (roughly) that the ciphertext encrypting C(π1, . . . , πt) should “look like” an “ordinary” ciphertext, as long as C(π1, . . . , πt) is a single bit (or element of the same plaintext space that contains {πi}). For example, the size of the ciphertext output by Evaluate(pk, C, ψ1, . . . , ψt) should not depend on C. We focus on this deﬁnition. Actually, we use a stronger requirement: that DecryptE be expressible by a circuit DE , which takes a (formatted) secret key and (formatted) ciphertext as input, and whose size is (a ﬁxed) polynomial in the security parameter. Of course, this implies that there is an upper bound on the ciphertext size that depends only on the security parameter, and is independent of C. After describing a scheme that meets this deﬁnition, we will also describe how to achieve (statistical) circuit privacy (Chapter 20).
To some, it is surprising that such a thing as fully homomorphic encryption is possible even in principle. To see that it is possible, it may be helpful to understand fully homomorphic encryption in terms of a physical analogy – e.g., a photograph developer’s darkroom. The developer applies a particular function f to Alice’s ﬁlm when he develops it – i.e., the sequence of steps to develop the ﬁlm. In principle, he does not need to see anything to apply this procedure, though in practice darkrooms are typically not completely dark. Of course, this analogy is inadequate in that one may ask: why can’t the developer walk out of the darkroom and look at the ﬁnished product? Imagine that the developer is blind. Then, one may ask: why can’t someone else look at the ﬁnished product? Imagine that everyone in the world besides Alice is blind. “Sight” is Alice’s secret key, and (in this world) it is impossible for anyone else to simulate vision. Although imagining physical analogies should convince you that the notion of fully homomorphic encryption is not a logical fallacy, it seems diﬃcult to construct a perfect physical analogue of fully homomorphic encryption that is not rather far-fetched.
To try another physical analogy, suppose that the owner of a jewelry store (Alice) wants her employees to assemble raw precious materials (diamonds, gold, etc.) into ﬁnished products, but she is worried about theft. She addresses the problem by constructing glove boxes for which only she has the key, and she puts the raw materials inside. Using the gloves, an employee can manipulate the items inside the box. Moreover, an employee can put things inside the box – e.g., a soldering iron to use on the raw materials – even though he cannot take anything out. Also, the box is transparent, so that an employee can see what he is doing. (In this analogy, encryption means that the employee is unable to take something out of the box, not that he is unable to see it.) After the employee is done,

CHAPTER 1. INTRODUCTION

7

Alice can recover the ﬁnished product at her leisure by using her key. This analogy is inadequate in the sense that the glove box might become quite cluttered, whereas in the fully homomorphic encryption scheme only the ﬁnal product need remain. In other words, to improve the analogy, imagine that the employee has some way to make any item in the glove box (of his choosing) disappear (even though he still cannot extract the item).
1.3 Bootstrapping a Scheme that Can Evaluate its Own Decryption Circuit
Now that we have clariﬁed our goal (fully homomorphic encryption), let us try to ﬁnd a steppingstone. Suppose that, a priori, we have a scheme E that is only guaranteed to be correct for some subset CE of circuits – i.e.,
DecryptE (sk, EvaluateE (pk, C, ψ1, . . . , ψt)) = C(π1, . . . , πt)
is guaranteed to hold only if C ∈ CE (and, as before, ψi ← EncryptE (pk, πi)). Can we use E to construct a scheme E∗ that is fully homomorphic?
In Chapter 4, we show that the answer is yes. Suppose that CE contains just two circuits: DE and the augmentation of DE by NAND (i.e., a NAND gate connecting two copies of DE ), where DE is the circuit associated to the decryption algorithm.1 If E has this self-referential property of being able to evaluate its own (augmented) decryption circuit, we say that E bootstrappable. We show that bootstrappable encryption implies leveled fully homomorphic encryption – i.e., that DE plus the NAND-augmentation of DE constitute a “complete” set of circuits:
Theorem 1.3.1 (Informal). If E is bootstrappable, then, for any integer d, one can construct a scheme E(d) that can evaluate any circuit (consisting of NAND gates) of depth d. The decryption circuit for E(d) is the same as for E, and the complexity of encryption is also the same. E(d)’s public key size is O(d) times that of E’s. The complexity of EvaluateE(d) is polynomial in the security parameter and linear in the circuit size. If E is semantically secure against chosen plaintext attacks, then so is EvaluateE(d).
One drawback of E(d) is that its public key is O(d) times that of E’s public key. Since
1We use NAND because any circuit can be expressed in terms of NAND gates. We could instead augment the decryption circuit by a diﬀerent set of universal gates.

CHAPTER 1. INTRODUCTION

8

E(d) has this unwanted dependence on d, we say that it is merely leveled fully homomorphic. Under certain assumptions, we can make the E(d) public key size be independent of d, in which case we say the derived scheme is fully homomorphic.
Why should the fact that E can evaluate (augmentations of) DE be so powerful? Suppose that the distributions of EvaluateE (pk, C, ψ1, . . . , ψt) and EncryptE (pk, C(π1, . . . , πt)) are diﬀerent. In particular, suppose that there is an “error” associated with each ciphertext, that ciphertexts output by EncryptE have small error, that ciphertexts output by EvaluateE have larger error that increases with the depth of the circuit being evaluated, and that eventually (as the depth of the circuit being evaluated increases) the “error” becomes so large that applying DecryptE to the ciphertext results in a decryption error. (In fact, this is the case in our initial ideal lattice construction.) Intuitively, as we are evaluating a circuit and the implicit “error” becomes large, we would like to “refresh” the ciphertext so that the error becomes small again. Obviously, we could refresh a ciphertext if we could completely decrypt it, simply by generating an entirely new and fresh ciphertext that encrypts the same thing, but we want a way to refresh that does not require the secret key. This is the idea behind bootstrapping: we do decrypt the ciphertext, but homomorphically!
Speciﬁcally, suppose E is bootstrappable, with plaintext space P = {0, 1}, and that circuits are boolean. Suppose we have a ciphertext ψ1 that encrypts π under pk1, which we want to refresh. So that we can decrypt it homomorphically, suppose we also have sk1, the secret key for pk1, encrypted under a second public key pk2: let sk1j be the encryption of the jth bit of sk1. Consider the following algorithm.
RecryptE (pk2, DE , sk1j , ψ1).
Set ψ1j ←R EncryptE (pk2, ψ1j) Output ψ2 ← EvaluateE (pk2, DE , sk1j , ψ1j )
Above, Evaluate takes in the bits of sk1 and ψ1, each encrypted under pk2. Then, E is used to evaluate the decryption circuit homomorphically. The output ψ2 is thus an encryption under pk2 of DecryptE (sk1, ψ1) = π.2 In other words, Recrypt decrypts homomorphically using the encrypted secret key, thus obtaining a new ciphertext that encrypts the same thing as the original one.
2Recrypt implies a one-way multi-use proxy re-encryption scheme [19]. We discuss this in more detail in Section 1.8.

CHAPTER 1. INTRODUCTION

9

Notice how π is doubly encrypted at one point, and we use EvaluateE to remove the inner encryption. Applying the decryption circuit DE removes the “error” associated to the ﬁrst ciphertext under pk1, but EvaluateE simultaneously introduces a new “error” while evaluating the ciphertexts under pk2. Intuitively, we have made progress as long as the second error is shorter. Note that revealing the encrypted secret key bits sk1j does not compromise semantic security; these encrypted secret key bits are indistinguishable from encryptions of 0 as long as E is semantically secure by a standard hybrid argument. This hybrid argument breaks down if pk1 = pk2. However, if E securely encrypts key-dependent messages (is KDM-secure) [18, 68, 22] – i.e., roughly, if providing a ciphertext that encrypts a function of the secret key does not hurt security – then Recrypt can have a “self-loop” of encrypted secret keys.
Of course, our goal is to perform nontrivial homomorphic operations on underlying plaintexts, not merely to obtain refreshed encryptions of the same plaintext. If we can also evaluate a NAND augmentation of the decryption circuit, then we can generate an encryption of (π1 NAND π2) under pk2 using the encrypted secret key (sk1 under pk2) together with the two ciphertexts encrypting π1 and π2, respectively, under pk1. By recursively performing this type of operation on all ciphertexts at a given level in the circuit, we can evaluate a d-depth circuit of NANDs. If E is KDM-secure, the derived scheme is fully homomorphic (rather than leveled fully homomorphic). In the random oracle model, we show that a bootstrappable encryption scheme implies a scheme that is both bootstrappable and KDM-secure, and thus implies a fully homomorphic encryption scheme.
Constructing an eﬃcient (leveled) fully homomorphic encryption scheme without using bootstrapping, or using some relaxation of it, remains an interesting open problem.
Again, it may be helpful to view bootstrapping in terms of a physical analogy, although it will, of course, be even more far-fetched. Recall Alice, our jewelry store owner. Imagine that Alice’s glove boxes are defective; after an employee uses the gloves for 1 minute, the gloves stiﬀen and become unusable. Unfortunately for Alice, even her fastest employee cannot assemble some of the more intricate designs in under a minute. But Alice is not only paranoid, but also smart. To an employee that is assembling an intricate design, she gives him (like before) a glove box containing the raw materials, but also several additional glove boxes. Each of these additional glove boxes holds a copy of her master key. To assemble the intricate design, the employee manipulates the materials in box #1 until the gloves stiﬀen. Then, he places box #1 inside box #2, where the latter box already contains

CHAPTER 1. INTRODUCTION

10

a master key. Using the gloves for box #2, he opens box #1 with the master key, extracts the partially assembled trinket, and continues the assembly within box #2 until its gloves stiﬀen. He then places box #2 inside box #3, and so on. When the employee ﬁnally ﬁnishes his assembly inside box #n, he hands the box to Alice. Of course, this trick will not work unless the employee can open box #i within box #(i + 1), and have time to make a little bit of progress on the assembly, all before the gloves of box #(i + 1) stiﬀen. This is analogous to the requirement for a bootstrappable encryption scheme E – that the complexity of E’s (augmented) decryption circuit is less than what E can homomorphically evaluate.
We assumed that it was safe to use a single master key that opens all boxes. But maybe it is not safe; maybe an employee could use the gloves for box #2, together with master key inside that box, to open the box from the inside, extract the key, and use it to open box #1 and steal the jewels. However, Alice can avoid this circumstance by using distinct keys for the boxes, and placing the key for box #1 inside box #2, the key for box #2 inside box #3, and so on. This is analogous to the question of whether the encryption scheme is KDM-secure.
As before, the physical analogy only goes so far. In the physical case, box #i would grow as i increases, and consequently the extraction time would also grow, but our encryption scheme does not have analogous deﬁciencies. And, again, in our physical analogy, encryption corresponds to being unable to physically access the contents of the box. So, it is not a valid attack for the employee to copy the master key based on what he can see through the transparent box. Accordingly, it might be helpful to think of each key as having a certain secret chemical composition which cannot be readily ascertained while the key is inside the box, and that a key opens its associated box through a chemical reaction.
1.4 Ideal Lattices: Ideally Suited to Construct Bootstrappable Encryption
The notion of bootstrappability gives us a new angle on constructing fully homomorphic encryption: it suggests we should look at encryption schemes whose decryption algorithms have low circuit complexity. Within the bootstrappability framework, it does not make much sense to look at exponentiation-based schemes, since exponentiation (as used in RSA, for example) is not even known to be in NC. On the other hand, encryption schemes using lattices or linear codes have very simple decryption algorithms typically dominated by a

CHAPTER 1. INTRODUCTION

11

matrix-vector multiplication, an operation in NC1. In this paper, we focus on constructing

a lattice-based scheme (though we view, say, a code-based construction as an interesting

possibility).

Of course, it is not enough to minimize the circuit complexity of decryption; we also must

maximize the evaluative capacity of the scheme, so that the scheme can evaluate its own

(augmented) decryption circuit. While one can easily construct an additively homomorphic

scheme from ordinary lattices, we need a scheme with both additive and multiplicative

homomorphisms to evaluate general circuits. This consideration leads us to focus on ideal

lattices.

In Chapter 7, we describe our initial homomorphic encryption scheme based on ideal

lattices. However, one can understand the scheme reasonably well just in terms of rings

and ideals (no lattices). Rings and ideals are simple algebraic objects. Examples of rings

are Z (the integers) and the polynomial ring Z[x]/(f (x)), consisting of the residues of

integer polynomials modulo a monic polynomial f (x). Rings are closed under addition ‘+’,

multiplication ‘×,’ and additive inverse, and have an additive identity ‘0’ and multiplicative

identity ‘1.’ An ideal I of a ring R is a subset I ⊆ R such that

t j=1

ij

× rj

∈

I

for

any

i1, . . . , it ∈ I and r1, . . . , rt ∈ R. For example, (2) is an ideal of Z consisting of the set

of even numbers. An example ideal in Z[x]/(f (x)) is (a(x)), the set of multiples of a(x)

(reduced modulo f (x)). However, by these examples, we do not mean to imply that ideals

are necessarily principal; they may not be generated by a single element. If I is a proper

subset of R, we can talk about a coset of I within R; e.g., 1 + (2) is a coset consisting of

the odd numbers. The element x ∈ R is in the coset y + I if x − y ∈ I. Many of the

previous constructions of (partially) homomorphic encryption use rings and ideals, at least

implicitly; see Chapter 3.

As a ﬁrst approximation, here is how a fully homomorphic encryption scheme based on

rings and ideals might work. The public key pk contains an ideal I and a plaintext space P,

where the latter basically consists of a set of “distinguished representatives” of the cosets

of I; the secret key sk consists of some “secret knowledge” concerning I. To encrypt π ∈ P, the encrypter sends ψ ←R π + I, a “random” member of the coset π + I. The decrypter

uses its secret knowledge to recover the “distinguished representative” π (distinguished with

respect to P) of the coset π + I. To add and multiply ciphertexts, we simply use the ring

CHAPTER 1. INTRODUCTION

12

operations ‘+’ and ‘×’:
Add(pk, ψ1, ψ2) = ψ1 + ψ2 ∈ (π1 + π2) + I Mult(pk, ψ1, ψ2) = ψ1 × ψ2 ∈ (π1 × π2) + I
Ring operations on ciphertexts induce mod-I operations on the underlying plaintexts. In general, for an arithmetized mod-I circuit C, we would have
EvaluateE (pk, C, ψ1, . . . , ψt) ∈ C(π1, . . . , π1) + I
The semantic security of this scheme relies on the hardness of an ideal membership problem – i.e., given π and ψ, is ψ − π ∈ I? This is the approach of the Polly Cracker scheme by Fellows and Koblitz, described in Chapter 3.
The ﬁrst approximation above does not work for ideal lattices, unfortunately, since the ideal membership problem is not hard. An ideal lattice, as used in this paper, is simply an ideal in Z[x]/(f (x)), f (x) of degree n; each such ideal I can be represented by a lattice generated by the columns of a lattice basis BI , an n × n matrix. It so happens that, for any basis BI of any lattice (not just an ideal lattice) I and any v ∈ Zn, there is a unique, eﬃciently-computable distinguished representative v mod BI . In particular, it holds that v mod BI = v − BI · B−I 1 · v , where B−I 1 is the matrix inverse of BI and · rounds to the nearest integer vector. To ﬁnd the distinguished representative for r ∈ R modulo BI , one computes r mod BI where r is the coeﬃcient vector of r. To test whether r is a member of I, one simply tests whether r mod BI = 0 mod BI . Thus, the ideal membership problem is easy.
So, we use a diﬀerent approach that involves two ideals. Everybody can use a common ideal I, represented by basis BI . Then, each user generates their own ideal J, with secret and public bases BsJk and BpJk, that is relatively prime to I (i.e., I + J = R). As before, the plaintext space P consists of distinguished representatives of the cosets of I. The public key pk also includes the description of a distribution D. To encrypt π ∈ P, the encrypter sets π∗ ←D π + I, and sends ψ ← π∗ mod BpJk. In other words, the ciphertext has the form ψ = π + i + j for i ∈ I and j ∈ J, where π + i comes from the speciﬁed distribution D. The decrypter sets
π ← (ψ mod BsJk) mod BI

CHAPTER 1. INTRODUCTION

13

For decryption to work, the secret key BsJk should be chosen so as to be compatible with the distribution D, so that π + i is always the distinguished representative of π + i + J with respect to BsJk. In this case, the mod-BsJk operation returns π + i, after which π is recovered easily. This decryption criterion becomes more complicated as we add and
multiply ciphertexts using the basic ring operations. For arithmetized circuit C that uses
addition and multiplication modulo I (w.r.t. basis BI ), we have:
EvaluateE (pk, C, ψ1, . . . , ψt) = C(ψ1, . . . , ψt) ∈ C(π1 + i1, . . . , πt + it) + J
where i1, . . . , it ∈ I. (The above is an abuse of notation, since on the left C consists of gates that add and multiply the underlying plaintexts modulo I, while in the middle and on the
right C uses the ring operations ‘+’ and ‘×’, but we will use this for now.) In this case, for
decryption to work, we need C(π1 + i1, . . . , πt + it) to be the distinguished representative of C(π1 + i1, . . . , πt + it) + J w.r.t. BsJk. We can reverse this statement, and say that the set CE of circuits that the scheme E evaluates correctly consists of those circuits for which C(π1 + i1, . . . , πt + it) is always the distinguished representative of C(π1 + i1, . . . , πt + it) + J w.r.t. BsJk when BsJk is generated according to KeyGenE and πk and ik are chosen according to EncryptE . In this case, the mod-BsJk operation recovers C(π1 + i1, . . . , πt + it), after which the decrypter easily recovers C(π1, . . . , πt) by reducing modulo BI .
This characterization of CE becomes less nebulous when, in the context of lattices, we give a geometric interpretation to C(π1 +i1, . . . , πt +it) as a vector indicating the ciphertext vector’s “error” or “oﬀset” from the lattice J. In this setting, the distinguished representatives of the cosets of J w.r.t. the basis BsJk are precisely the points in Zn that are contained inside the parallelepiped P(BsJk) = {x ∈ Rn : x = xi · bi, xi ∈ [−1/2, 1/2)} associated to the basis BsJk = {bi}. Decryption works as long as the “error vector” is never so long that it falls outside of P(BsJk).3 Once we specify some radius rDec such that the parallelepiped P(BsJk) always contains a ball of radius rDec inside it (for any J generated according to KeyGen), and also specify a radius rEnc such that (in EncryptE ) the vector π∗ ←D π + I always falls within a ball of radius rEnc, the bootstrappability question becomes: is C(x1, . . . , xt) ∈ B(rDec) whenever xi ∈ B(rEnc) for all i and C is an (augmented)
3If the error vector does fall outside P(BsJk), the mod-BsJk operation in decryption returns C(π1 + i1, . . . , πt + it) + j for some nonzero j ∈ J, and the subsequent reduction modulo I is unlikely to return C(π1, . . . , πt), since J is relatively prime to I. Interestingly, NTRU [69] uses relatively prime ideals in a similar way.

CHAPTER 1. INTRODUCTION

14

decryption circuit? We can upper-bound the length of C(x1, . . . , xt) for arithmetic circuit C recursively
by upper-bounding the “expansion” caused by additions and multiplications. Roughly speaking, we can say that Add operations do not increase the length of the error vector much: if ψ1 ∈ x1 + J and ψ2 ∈ x2 + J, then Add(pk, ψ1, ψ2) ∈ (x1 + x2) + J, where x1 + x2 ≤ x1 + x2 by the triangle inequality. Mult operations are more expensive; we can show that, for any polynomial ring R, there is a parameter γMult(R) such that x1 × x2 ≤ γMult(R) · x1 · x2 ; γMult(R) may be, e.g., polynomial in n. (For the Mult operation, vector xi is interpreted as the polynomial in R whose coeﬃcient vector is xi.) Essentially, constant-fan-in Mult gates cause at least as much expansion as polynomial-fanin Add gates. In the worst case, Mult gates cause the length of the error vector essentially to square with each additional level of the circuit, limiting the circuit depth that the scheme can evaluate to (roughly) log log rDec.
Theorem 1.4.1 (Informal). Suppose X ⊆ B(rX ) and Y ⊇ B(rY ), rX ≥ 1. Then, C(x1, . . . , xt) ∈ Y for all x1, . . . , xt ∈ X and all arithmetic (over R) circuits with multiplicative fan-in of 2, additive fan-in of up to γMult(R), and depth up to
log log rY − log log(γMult(R) · rX )
I.e., E correctly evaluates all such circuits of depth up to log log rDec −log log(γMult(R)·rEnc).
So, can we express the (augmented) decryption circuit with depth at most (roughly) log log rDec? Unfortunately, the answer appears to be ‘no,’ though it is a close call. Specifically, the dominant computation in decryption is (BsJk)−1 · ψ , which occurs within the computation of ψ mod BsJk. Roughly speaking, to ensure that the rounding is correct, one must use a suﬃcient number of bits of precision. Then, the high precision of each numbernumber multiplication that occurs within the matrix-vector multiplication forces us to use a high-depth circuit. Speciﬁcally, two k-bit numbers can be multiplied together using a O(log k)-depth circuit (with constant fan-in). The precision we seem to need is roughly log det(J) > n · log rDec bits, and therefore we need about a O(log n + log log rDec)-depth circuit.
Unfortunately, for this initial scheme, it seems that no matter how the parameters are set, the decryption circuit is always slightly too complex for the scheme to evaluate.4
4However, we do not prove this. It remains possible that the decryption circuit of this initial scheme can

CHAPTER 1. INTRODUCTION

15

This problem is diﬃcult to ﬁx post hoc, in part due to the self-referential nature of the bootstrapability property: intuitively, if one expands the set of circuits that E can “handle” in an eﬀort to include DE , one seemingly must increase the complexity of DecryptE to accommodate, thereby making the circuit DE more complex, possibly such that DE always elusively falls outside of the expanded set. To obtain a bootstrappable encryption scheme, it seems necessary to change the decryption algorithm fundamentally.
1.5 Squashing the Decryption Circuit: The Encrypter Starts Decryption!
To reduce the decryption complexity without aﬀecting the “evaluative capacity” of the scheme at all, our approach, given in Chapter 10, is to enable the encrypter to start decryption, thereby easing the burden on the decrypter. Interestingly, the setting is similar to server-aided cryptography, where a user oﬄoads some portion of a computationally intensive cryptographic task, such as decryption, onto an untrusted server; in our case, the encrypter itself plays the server’s role.
Abstractly, if E∗ is our original homomorphic encryption scheme, with public and secret keys (pk∗, sk∗), the modiﬁed scheme E uses an algorithm that we call SplitKey to generate a “hint” τ about sk∗, which it puts in the E public key. Also, E uses a new algorithm ExpandCT. The encrypter uses this algorithm, in combination with the hint τ , to transform a preliminary ciphertext ψ∗ output by E∗ into an “expanded ciphertext” that can be decrypted by a shallower circuit. Here is the abstract transformation in detail; since it is abstract, it is obviously not explained at this point why the expanded ciphertext is easier to decrypt. KeyGenE (λ). Runs (pk∗, sk∗) ←R KeyGenE∗(λ) and (sk, τ ) ←R SplitKeyE (sk∗, pk∗). The secret key is sk. The public key pk is (pk∗, τ ).
EncryptE (pk, π). Runs ψ∗ ← EncryptE∗(pk∗, π). It then sets ψ to include ψ∗ and the output of ExpandCTE (pk, ψ∗). (ExpandCTE makes heavy use of τ .)
DecryptE (sk, ψ). Uses sk and expanded ciphertext to decrypt more eﬃciently. DecryptE (sk, ψ) should work whenever DecryptE∗(sk∗, ψ∗) works. AddE (pk, ψ1, ψ2). Extracts (ψ1∗, ψ2∗) from (ψ1, ψ2), computes ψ∗ ← AddE∗(pk∗, ψ1∗, ψ2∗), and sets ψ to include ψ∗ and the output of ExpandCTE (pk, ψ∗). MultE (pk, ψ1, ψ2) is analogous.
be expressed in a way that makes the scheme bootstrappable.

CHAPTER 1. INTRODUCTION

16

We (half facetiously) say that the “encrypter starts decryption” because it uses the secretkey-related value τ to expand the ciphertext in a way that helps reduce the decrypter’s circuit complexity. The introduction of τ into the public key provides a “hint” about the secret key sk of the original scheme E∗. However, it is easy to see that E is semantically secure as long as E∗ is, as long as the following SplitKey distinguishing problem is hard: given (pk∗, sk∗, τ ), distinguish whether τ was generated as the output of SplitKeyE (sk∗, pk∗) (as it should be), or as the output of SplitKeyE (⊥, pk∗), where ⊥ is some distinguished symbol that is independent of sk∗. In the latter case, τ gives no additional information about sk∗ that could weaken security.
Theorem 1.5.1 (Informal). If there is an algorithm A that breaks the squashed scheme with non-negligible probability, then there is either an algorithm B1 that breaks the original scheme or an algorithm B2 that solves the SplitKey distinguishing problem with non-negligible advantage.
Concretely, we actually apply a couple of technical “tweaks” to our original ideal-latticebased construction before we apply the above transformation. In one tweak, we show how to simplify the decryption equation in the original scheme from (ψ∗ mod BsJk) mod BI = (ψ∗−BsJk· (BsJk)−1·ψ∗ ) mod BI to (ψ∗− vJsk×ψ∗ ) mod BI where ‘×’ is ring multiplication and vJsk ∈ Qn. The new secret key vJsk is slightly weaker than the original one, which forces us to reduce rDec by a polynomial factor (which is insigniﬁcant if rDec is super-polynomial anyway, as it is required to be to obtain our fully homomorphic scheme). Other than that, the modiﬁcation has no eﬀect on the correctness or security of the scheme. The purpose of the tweak is merely to reduce the size of the tag τ introduced by the above transformation. (We will discuss what τ is in concrete terms momentarily.) The second tweak is to limit the set of “permitted circuits” to those for which the length of the “error” vector never exceeds rDec/2, rather than rDec. The purpose of this tweak is to ensure that the coeﬃcients of the vector vJsk × ψ∗ are bounded away from half-integers when ψ∗ is a valid ciphertext. In particular, all of the coeﬃcients will be within 1/4 of an integer; this allows us to simplify the decryption circuit while still ensuring that the rounding operation vJsk × ψ∗ yields the correct answer. Aside from very slightly reducing the evaluative capacity of the scheme, this tweak also has no negative eﬀect.
Now, in our concrete instantiation of SplitKeyE , τ is a random set S (with ω(n), but poly(n), members) of vectors {ui} that has a sparse subset T (with ω(1), but o(n), members)

CHAPTER 1. INTRODUCTION

17

whose sum is vJsk modulo I; the new secret key sk is the subset T , encoded as a 0/1-vector in {0, 1}|S|. Distinguishing whether or not the vectors in S are completely uniform and independent of sk∗ is a lattice-related problem, whose search version (actually ﬁnding the subset) has been studied in the context of server-aided cryptography [91, 114, 106, 96, 105]. We discuss this problem a bit more in the next Section.
In the modiﬁed scheme, ExpandCTE outputs {ci ← ui × ψ∗ mod BI : ui ∈ S}. To oversimplify, DecryptE sums up the values ci that correspond to elements of T , thereby obtaining vJsk × ψ∗ mod BI , and then rounds to the nearest integer vector. This summation can be performed in depth (roughly) log |T |, regardless of what n is. By choosing |T | small enough, smaller than the depth of the circuits that the scheme can evaluate (which is unaﬀected by this transformation), the scheme becomes bootstrappable.
The previous paragraph oversimpliﬁes some details. First, the summation of the |T | vectors and the rounding are performed together; the fact that the ultimate result is rounded and taken modulo I allows us to maintain fewer bits of precision in the intermediate computations. The fact that we are promised that the ﬁnal result is close to an integer vector (due to one of our tweaks), ensures that the rounded result is correct despite the limited precision. Also, we actually still add |S| vectors together, but with the promise that only |T | of them are nonzero. (We have this promise because, after when we multiply in the secret key sk ∈ {0, 1}|S|, which has Hamming weight |T |, it zeroizes all but |T | of the ciphertext components). Why can we add |T | vectors in only (roughly) log |T | depth, regardless of the size of |S|, when we have the promise that only |T | of the |S| vectors are nonzero (and the other promises, like the fact that we only need the result rounded, and then modulo I)? Essentially, the reason is that summing |S| numbers basically reduces (in terms of circuit depth) to computing the Hamming weight of a vector in x ∈ {0, 1}|S| and expressing the ﬁnal result in binary – i.e., in {0, 1}s+1 for s = log |S| . The binary expression of the Hamming weight of x turns out to be simply (e2s(x1, . . . , x|S|) mod 2, e2s−1(x1, . . . , x|S|) mod 2, . . . , e20(x1, . . . , x|S|) mod 2), where ei is the ith elementary symmetric polynomial. If the Hamming weight is guaranteed to be at most |T |, we need not bother computing the polynomials of degree higher than 2 log |T | , and consequently need less depth.
Theorem 1.5.2 (Informal). The decryption circuit of E with the tweaks followed by the above transformation can be expressed as a circuit of depth c · (log |T |)1+o(1) for some constant c. The scheme becomes bootstrappable when this value is less than log log(rDec/2) −

CHAPTER 1. INTRODUCTION

18

log log(γMult(R) · rEnc).
For example, suppose rDec = 2nc for some c < 1 and γMult(R) · rEnc = poly(n). In this case, the scheme becomes bootstrappable when |T | ≤ n(c /c)−o(1).
Devising a physical analogy for our technique for squashing the decryption circuit is rather diﬃcult, but suppose that, in Alice’s jewelry store, a key opens a glove box through a chemical reaction. To unlock a box, the employee uses the gloves to rub the key against the inner box until the box dissolves. However, the reaction is too slow; the gloves stiﬀen before the box dissolves. To address this situation, Alice gives the employee some accelerants, a diﬀerent one for each box, that the employee can apply to the outside of box #i right before placing it inside box #(i+1). The accelerants speed up the chemical reaction between the key and the box, so that the reaction ﬁnishes before the gloves stiﬀen. The chemical composition of the accelerant provides some information about the chemical composition of her key, but not enough information for an employee to construct a key on his own. Notice that the employee should apply the accelerant to box #i while it is still outside of box #(i + 1); to apply it while box #i is inside box #(i + 1) would pointlessly waste the usability of the gloves for box #(i + 1).
1.6 Security
The semantic security of our scheme against chosen plaintext attacks relies on the hardness of two problems; the ﬁrst underlies the original somewhat homomorphic scheme (before the squashing), and the second arises from the addition of the secret key “hint” τ to the public key. CCA1 security for fully homomorphic encryption remains an open problem, while CCA2 security is impossible due to the extreme malleability of ciphertexts.
We prove the security of our somewhat homomorphic construction in two ways. The ﬁrst way is provided for simplicity. Speciﬁcally, in Chapter 5 (and more concretely in Chapter 7), we provide a succinct reduction to a fairly natural problem that may be viewed as a decisional version of the closest vector problem (CVP) or bounded distance decoding problem (BDDP). Roughly, the problem is as follows: given an ideal lattice J and a vector t, decide whether (1) t is unusually close to the lattice or (2) t is in a uniformly random coset of the lattice, given the promise that one of these is the case. The idea is that if t is in the ﬁrst category, the simulator can use t to construct a valid ciphertext vector (which is also quite close to the lattice, but a little bit further away than t), but if t is in the

CHAPTER 1. INTRODUCTION

19

second category, the ciphertext will be completely independent of the challenge plaintext; the latter case makes use of the fact that I and J are relatively prime.
This reduction, while simple, is not entirely satisfying. First, the problem is not worstcase, but rather average-case: in particular, J is generated using an algorithm IdealGen that is part of the scheme’s KeyGen algorithm. Second, it would be preferable to base security on a search problem rather than a decision problem. Finally, although the problem seems natural, it is not as well-established as other problems over lattices.
So, beginning in Chapter 14, we describe a slightly diﬀerent version of the scheme, along with a chain of security reductions that bases security on a search version of BDDP. Given access to a factoring oracle, we also base security on the worst-case shortest independent vector problem (SIVP) over ideal lattices. Since a factoring oracle can be instantiated eﬃciently using quantum computation, this result says that if there is an eﬃcient algorithm that breaks the semantic security of scheme with non-negligible advantage, then there is an eﬃcient quantum algorithm that solves ideal-lattice SIVP.
Theorem 1.6.1 (Informal). If there is an algorithm that breaks the somewhat homomorphic scheme with probability , then there is a classical algorithm that solves average-case BDDP over ideal lattices for an approximation factor (rDec/rEnc) · poly(n, γMult(R), 1/ ), where the average-case distribution is the same as the distribution of ideals output by KeyGenE . There is also a quantum algorithm (or a classical algorithm that uses a factoring oracle) that solves worst-case SIVP over ideal lattices for an approximation factor (rDec/rEnc) · poly(n, γMult(R), 1/ ). In both cases, the ring R over which ideals are deﬁned remains ﬁxed.
The introduction of τ into the public key induces a second problem that we must assume is hard, an instance of the SplitKey distinguishing problem: roughly, given vJsk, distinguish whether S is entirely random, or has a sparse |T |-member subset of vectors that sums to vJsk. We will refer to this as a sparse vector subset sum problem (SVSSP). If |T | is too small, there are obvious brute force attacks on the SVSSP, along with some more sophisticated time-space tradeoﬀs [114, 128, 33], that take time essentially exponential in |T |. Also, if |S| is so small that the subset sum solution is unique, then one can apply lattice reduction attacks similar to those used against low-density knapsacks [106, 105]. However, if |T | = ω(1) and |S| is suﬃciently large (but still polynomial in n), the brute force attacks take super-polynomial time; also, the lattice reduction attacks break down, since there will be an exponential number of subset sum solutions, and lattice reduction has trouble extracting the sparse solution from the non-sparse ones.

CHAPTER 1. INTRODUCTION

20

Interestingly, our two assumptions counterbalance each other: basically, if one adjusts the scheme’s parameters to make one problem harder, the other problem becomes easier. Using a crude analysis, the breaking time for the second problem using known attacks is roughly 2|T |. (Here we ignore constants and logarithmic factors in the exponent.) Also, to enable the somewhat homomorphic ideal lattice scheme to evaluate circuits of depth O(log |T |) as needed to permit bootstrappability, we need the approximation factor for the ﬁrst problem to be roughly 2|T |. Using the rule of thumb that a lattice problem for approximation factor 2k takes time about 2n/k, the breaking time for the ﬁrst problem is roughly 2n/|T |. Setting |T | ← √n ensures that it takes time at least 2√n to break either problem using known attacks. To make this breaking time truly exponential in the security parameter λ, we need the lattice dimension to be n ≈ λ2. Of course, this analysis does not apply to the somewhat homomorphic scheme, which does not use bootstrapping and relies only on the ﬁrst assumption, and therefore can use lattices of smaller dimension.
Even this counterbalancing of our assumptions can be viewed through the prism of our physical analogy (Alice’s jewelry store) if one squints suﬃciently hard. One way that Alice’s employees might try to extract a key from a box is simply by cutting through the gloves. To prevent this attack, one would like the gloves to be stiﬀer. On the other hand, making the gloves stiﬀer reduces their usability, and so we need a faster chemical reaction between keys and boxes. This forces Alice to give her employees a better accelerant, which provides more precise information about the chemical composition of her keys, and therefore makes it easier for her employees to duplicate a key chemically. By making one attack more diﬃcult, she is forced to make the other easier.
1.7 Performance
When we run Evaluate(pk, C, Ψ) over a circuit C and ciphertexts Ψ, the computational complexity of this algorithm is exactly the complexity of computing C non-homomorphically times a factor that is polynomial in the security parameter λ. The degree of this polynomial is rather high. If one wants 2λ security against known attacks on the two problems that underlie the security of our scheme, the required computation per gate is quasi-linear in λ6. While high, this does not seem entirely unreasonable when one considers that, to get 2λ security against the number ﬁeld sieve, one should use an RSA modulus whose bit-length is quasi-linear in λ3, in which case a full exponentiation takes time quasi-linear in λ6, even

CHAPTER 1. INTRODUCTION

21

when one uses fast FFT multiplication. See Chapter 12 for more details. The story is very diﬀerent if we only require super-polynomial security: in this case, n
can be quasi-linear in the security parameter λ, |T | can be polylogarithmic in n, S quasilinear in n, and ciphertexts can be represented by a quasi-linear (in n) number of bits. In this case, the complexity of Recrypt (and hence the computation per gate) can be quasi-linear in λ3.
Also, for relatively shallow circuits, where bootstrapping (and hence homomorphically evaluating the decryption circuit is unnecessary), the scheme is very practical: one obtains exponential security and, there is a constant c such that one can evaluate circuits of multiplicative depth c · log λ with computation per gate that is quasi-linear in λ1+c. The computation is quasi-linear in λ for constant depth circuits.
1.8 Applications
The most natural applications of fully homomorphic encryption are in the two-party setting. A simple example is making encrypted queries to search engines. To perform an encrypted search, Alice generates a public key pk for the fully homomorphic encryption scheme, and generates ciphertexts ψ1, . . . , ψt that encrypt her query π1, . . . , πt under pk. (For example, each πi could be a bit of her query.) Now, let the circuit C express the server’s search function. The server sets ψi∗ ← Evaluate(pk, Ci, ψ1, . . . , ψt), where Ci is the sub-circuit of C that computes the ith bit of the output. (We note that, in practice, the evaluation of Ci∗ and Cj∗ may share intermediate results, in which case it would be needlessly ineﬃcient to run independent instances of the Evaluate algorithm.) The server sends these ciphertexts to Alice. We know, by the correctness requirement, that Decrypt(sk, ψi∗) = Ci(π1, . . . , πt). These latter values constitute precisely the answer to Alice’s query, which she recovers through decryption.
Another natural application is searching over encrypted data. In this scenario, Alice stores her ﬁles on a server (e.g., on the Internet), so that she can conveniently access her ﬁles without needing her own computer. However, she encrypts her ﬁles, because otherwise the server could read or leak her private data. Let bits π1, . . . , πt represent the ﬁles, which are encrypted in the ciphertexts ψ1, . . . , ψt. Suppose that later Alice wants to download all of her encrypted ﬁles that satisfy a query – e.g., all ﬁles containing the ‘homomorphic’ within 5 words of ‘encryption’, but not the word ‘evoting’. She sends her query to the

CHAPTER 1. INTRODUCTION

22

server, which expresses it as a circuit C. The server sets ψi∗ ← Evaluate(pk, Ci, ψ1, . . . , ψt) and sends these ciphertexts to Alice. Alice decrypts them to recover C(π1, . . . , πt), the (bits of the) ﬁles that satisfy her query. (In this application, as in the encrypted search application, Alice needs to provide an upper bound on the number of bits that the response should have, and the server’s encrypted response will be padded or truncated to that upper bound.)
Let us compare fully homomorphic encryption to a previous general solution for secure two-party computation – namely, “Yao’s garbled circuit”. The problem with Yao’s protocol is that the communication complexity is proportional to the size of the circuit C. This makes the protocol rather unattractive in both of the scenarios discussed above (encrypted search and searching encrypted data). In the encrypted search scenario, the search engine would need to send Alice a huge garbled circuit whose size is proportional to the data being searched. In the scenario of searching on encrypted data, Alice would need to send a circuit whose size is proportional to the size of her data; if such communication complexity could be tolerated, then the server might as well just transmit all of Alice’s encrypted ﬁles to her without “processing” those ﬁles at all, and let Alice ﬁgure out which ﬁles she wants. With fully homomorphic encryption, the communication complexity is much less. In particular, the communication needed, other than pk, is simply the number of bits need to express Alice’s (cleartext) query and the server’s (cleartext) response, each multiplied by the size of the security parameter, since each cleartext bit becomes a ciphertext. Actually, for the inputs to the circuit – e.g., Alice’s query – we can do even better; the scheme’s communication overhead here can be only additive, rather than multiplicative. Yao’s protocol has the advantage of hiding the circuit, but it easy to tweak our fully homomorphic encryption scheme so that it provides unconditional circuit privacy.
Despite nearly minimal communication eﬃciency, our fully homomorphic encryption scheme does add a fair amount of computational overhead, so asynchronous application scenarios may be more appropriate in practice. An asynchronous example is spam ﬁltering of encrypted emails: given an email encrypted using our scheme under Alice’s public key, Alice’s email server can homomorphically apply its spam ﬁlter to the email to obtain an encryption of ‘0’ (indicating the email is not spam) or ‘1’ (indicating that it is). Later, Alice decrypts this single ciphertext to recover a bit b, and only decrypts the rest of the email if b = 0.
Regarding multiparty computation, we already know that we can securely compute any

CHAPTER 1. INTRODUCTION

23

function. More speciﬁcally, one can construct eﬃcient secure protocols for any multiparty computation in which there is an honest majority [56], assuming only the existence of trapdoor permutations. By “eﬃcient,” we do not mean that these protocols are necessarily practical. We mean only that the communication and computational complexity of the secure protocol equals the computational complexity of the insecure protocol times some factor that is polynomial in the security parameter and number of parties.
But why should the communication complexity of secure multiparty computation depend at all on computational complexity of the function being computed? Naor and Nissim [103] showed that, as one would expect, it is possible to construct a secure protocol whose communication complexity is polynomial in the security parameter and the communication complexity of the insecure protocol, but their method has a severe shortcoming: the computational complexity of their scheme is exponential (in the worst case) in the communication complexity. In eliminating one type of unwanted dependence, it introduces another.
Previous work leaves a fundamental question unanswered: can we make a protocol secure while leaving both the communication and the computational complexity unchanged, up to a factor polynomial in the security parameter? With fully homomorphic encryption, the answer is essentially ‘yes.’ More precisely, the answer is ‘yes’ if we relax the deﬁnition of communication complexity to include the bit-lengths of the output functions (which normally would not necessarily be included, since they are not communicated).
Extending our application of fully homomorphic encryption from the two-party setting to the multiparty setting is not entirely trivial, since, in the two-party setting, Bob prevented Alice from seeing any intermediate values encrypted under Alice’s key simply by ﬁnishing the computation himself, and sending back the ﬁnal encrypted value to Alice; in the multiparty setting, it is less clear how one prevents Alice from seeing intermediate value encrypted under her key. So, we use an approach initially proposed by Franklin and Haber [45], and further developed by Cramer, Damgard and Nielsen [35] (see also [39]) – namely, basing secure multiparty computation on threshold homomorphic encryption. The idea is simple. The parties must use some (other) scheme for secure computation to set up a public key for the fully homomorphic encryption scheme and distribute shares of the secret key; this introduces additive communication and computational overhead that is independent of the insecure protocol. After setup, they perform exactly the communications and computations that they would in the insecure protocol, except on encrypted data; fully homomorphic encryption ensures that, if a party was able to perform computations locally in the insecure

CHAPTER 1. INTRODUCTION

24

protocol, it is also able to in the secure protocol. Afterwards, they use some scheme for secure computation to perform threshold decryption on the encrypted outputs; again, this overhead is independent of the insecure protocol, except insofar as it depends on the bitlengths of the function outputs. Cramer et al.’s scheme is dependent on the number of multiplication gates in the circuit because these could not be performed homomorphically. With a fully homomorphic encryption scheme, we avoid this problem, and fully realize their high-level concept of an “arithmetic black box.”
To handle malicious parties, we can use Naor and Nissim’s [103] transformation from a protocol for multiparty SFE with semi-honest parties to a protocol for malicious ones via a compiler that is communication-preserving – i.e., the transformation adds communication polynomial in the security parameter and polylogarithmic in the inputs. (The security parameter should be at least logarithmic in the size of the inputs anyway; otherwise, the work needed to break the scheme would be less than the work needed to process the inputs.) The essential ideas of this transformation come from Kilian’s construction of zero-knowledge arguments [78, 79] and Arora et al.’s PCP theorem [8].
The literature mentions numerous other applications where fully homomorphic encryption would be useful. For example, Goldreich and Ostrovsky [57] consider software protection, show that any program can be converted to a pair consisting of an encrypted program and a CPU with λ bits of “shielded” memory, where λ is the security parameter, which defeats “experiments” by an adversary that might either attempt the determine the values that are stored and retrieved from memory, or try to determine the program’s “access pattern” – i.e., its attempts to change the values. In their scheme, there is only a logarithmic blow-up in the computation time; however, the shielded CPU needs to be accessed for any nontrivial computation. With a fully homomorphic encryption scheme, the program and values can remain encrypted throughout the computation until the end. The shielded CPU only needs to be accessed to perform the decryption of the ﬁnal output.
Goldwasser, Kalai and Rothblum [59] introduce the concept of one-time programs, in which they make minimal use of hardware to ensure that a program is used only once. Their approach is essentially to encrypt the program using Yao’s garbled circuit, and have a secure device perform the decryption (a toggle bit is used to ensure that this decryption happens only once). One shortcoming of their approach is that the size of the encrypted program is proportional to the maximal running time of the program. With a fully homomorphic encryption scheme, one can construct an (encrypted) one-time program whose

CHAPTER 1. INTRODUCTION

25

size is proportional to the original program. Essentially, one simply encrypts the program using the fully homomorphic encryption scheme, and runs it homomorphically, using the device to perform the ﬁnal decryption. The party running the program also needs to generate a NIZK, veriﬁable by the device, that proves that the ﬁnal ciphertext was validly constructed by running the encrypted program P on permitted inputs; again, we can use Kilian’s communication-eﬃcient zero-knowledge arguments here [78, 79].
Ostrovsky and Skeith [109] propose the notion of public-key obfuscation – i.e., where a sort of obfuscation is achieved simply by encrypting the program; somehow, one then runs the encrypted program, and afterwards decrypts the output. With a fully homomorphic encryption scheme, running the encrypted program is straightforward. Currently, there is a lot of excitement about applications such as web services and cloud computing, where fully homomorphic encryption would permit remote computations on encrypted data with complete privacy.
We have already mentioned the notion of proxy re-encryption in Chapter 1.3. In a proxy re-encryption [19, 29, 71, 70], the idea is that Alice wants to publish a tag τ that will permit anyone to convert a ciphertext encrypted under her public key pkA into an encryption of the same message under Bob’s public key pkB. Previous proxy re-encryption schemes have some shortcomings. They either are not unidirectional (i.e., Alice’s tag can also be used to convert ciphertexts under pkB to ciphertexts under pkA, and Alice and Bob must cooperate to produce τ ), or they are not multi-use (i.e., it is impossible to construct a sequence of tags τ1, τ2, . . . that allows anyone to convert ciphertexts under pkA to pkB, pkB to pkC, and so on indeﬁnitely, without the ciphertexts growing in size). Recursive application of our Recrypt algorithm gives the ﬁrst unidirectional multi-use proxy re-encryption scheme.
With fully homomorphic encryption, one can construct non-interactive zero knowledge proofs (NIZKs) of small size. For example, suppose that Alice wants to prove that π1, . . . , πt is a satisfying assignment of a boolean circuit C. Alice generates a public key pk for the fully homomorphic encryption scheme, the input ciphertexts {ψi ← Encrypt(pk, πi)}, and the output ciphertext ψ∗ ← Evaluate(pk, C, ψ1, . . . , ψt). The NIZK that her assignment is satisfying consists of NIZK proofs, under any NIZK scheme, that pk, {ψi} and ψ∗ are wellformed, where well-formedness for the ciphertexts means that each ψi is a valid encryption of ‘0’ or ‘1’, and ψ∗ is a valid encryption of ‘1’. The veriﬁer checks the NIZKs for wellformedness, and conﬁrms that ψ∗ = Evaluate(pk, C, ψ1, . . . , ψt). Intuitively, the NIZK proof works because, if the veriﬁer believes that pk and the input ciphertexts are well-formed, then

CHAPTER 1. INTRODUCTION

26

the correctness of the encryption scheme implies that the output ciphertext can encrypt ‘1’ only if C(π1, . . . , πt) = 1. The size of this NIZK proof is proportional to the number of inputs to the circuit, but is otherwise independent of the size of the circuit.
For many interesting applications, we do not need the full power of our scheme; rather, a simpler, more eﬃcient version of our scheme that evaluates circuits of logarithmic multiplicative depth suﬃces. For example, consider private information retrieval from an m-bit database. The querier can simply encrypt the index that it wants using log m ciphertexts. The database’s response corresponds to a (log m)-degree formula evaluated over these ciphertexts, which (essentially) can be computed using a (log log m)-depth circuit. We can evaluate such shallow circuits using the somewhat homomorphic scheme that we sketched in Chapter 1.4, without requiring either bootstrapping or “squashing the decryption circuit.” This basic scheme compares well with the pairing-based scheme of Boneh-Goh-Nissim, which can essentially evaluate quadratic formulas; our basic scheme can also do essentially an arbitrary number of additions, but with greater multiplicative depth. In general, when the function to be evaluated is highly parallel, the bootstrapping step may be unnecessary, permitting better eﬃciency.
Clearly, several of these applications relate to obfuscation, but the precise relationship between fully homomorphic encryption and obfuscation is unclear. We know that general obfuscation is impossible under a certain deﬁnition of obfuscation [12], but obfuscation may be possible under a weaker, but still meaningful, deﬁnition. We also know that general obfuscation (under essentially any reasonable deﬁnition) would imply fully homomorphic encryption: it would suﬃce to obfuscate circuits that take ciphertexts encrypting π1 and π2 and output appropriately distributed ciphertexts encrypting π1 + π2 and π1 × π2. Since general obfuscation would imply fully homomorphic encryption, it seems reasonable to guess that a general obfuscation technique (if one exists) would employ some of the techniques (bootstrapping, etc.) that we use here to construct fully homomorphic encryption. Unlike a fully homomorphic encryption scheme, however, an obfuscated circuit should allow one to compute an unencrypted output. If one is to build a general obfuscation scheme from fully homomorphic encryption, the question becomes: how can one provide, as part of the obfuscated circuit, some sort of decryption key that allows recovery of the ﬁnal output, in such a way that this decryption key does not permit decryption of interior nodes of the circuit, thereby unraveling the entire obfuscation.

Chapter 2
Deﬁnitions related to Homomorphic Encryption
2.1 Basic Deﬁnitions
A conventional public-key encryption scheme E consists of three algorithms: KeyGenE , EncryptE , and DecryptE . KeyGenE is a randomized algorithm that takes a security parameter λ as input, and outputs a secret key sk and public key pk; pk deﬁnes a plaintext space P and ciphertext space C. EncryptE is a randomized algorithm that takes pk and a plaintext π ∈ P as input, and outputs a ciphertext ψ ∈ C. DecryptE takes sk and ψ as input, and outputs the plaintext π. The computational complexity of all of these algorithms must be polynomial in λ. Correctness is deﬁned as follows: if (sk, pk) ←R KeyGenE , π ∈ P, and ψ ←R EncryptE (pk, π), then DecryptE (sk, ψ) → π.
In addition to the three conventional algorithms, a homomorphic encryption scheme E has a (possibly randomized) eﬃcient algorithm EvaluateE , which takes as input the public key pk, a circuit C from a permitted set CE of circuits, and a tuple of ciphertexts Ψ = ψ1, . . . , ψt for the input wires of C; it outputs a ciphertext ψ ∈ C. Informally, the functionality that we want from EvaluateE is that, if ψi “encrypts πi” under pk, then ψ ← EvaluateE (pk, C, Ψ) “encrypts C(π1, . . . , πt)” under pk, where C(π1, . . . , πt) is the output of C on inputs π1, . . . , πt.
There are diﬀerent ways of formalizing the functionality “encrypts C(π1, . . . , πt).” A minimal requirement is correctness.
27

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 28
Deﬁnition 2.1.1 (Correctness of Homomorphic Encryption). We say that a homomorphic encryption scheme E is correct for circuits in CE if, for any key-pair (sk, pk) output by KeyGenE (λ), any circuit C ∈ CE , any plaintexts π1, . . . , πt, and any ciphertexts Ψ = ψ1, . . . , ψt with ψi ← EncryptE (pk, πi), it is the case that:
if ψ ← EvaluateE (pk, C, Ψ) , then DecryptE (sk, ψ) → C(π1, . . . , πt)
except with negligible probability over the random coins in EvaluateE .
By itself, mere correctness fails to exclude trivial schemes. In particular, suppose we deﬁne EvaluateE (pk, C, Ψ) to just output (C, Ψ) without “processing” the circuit or ciphertexts at all, and DecryptE to decrypt the component ciphertexts and apply C to results. This scheme is correct, but uninteresting. We can address this shortcoming by upper-bounding the length of ciphertexts output by EvaluateE . One way to do this is by placing an upper bound on the size of the decryption circuit DE for the scheme E that depends only on the security parameter, as in the following deﬁnition.
Deﬁnition 2.1.2 (Compact Homomorphic Encryption). We say that a homomorphic encryption scheme E is compact if there is a polynomial f such that, for every value of the security parameter λ, E’s decryption algorithm can be expressed as a circuit DE of size at most f (λ).
Deﬁnition 2.1.3 (“Compactly Evaluates”). We say that a homomorphic encryption scheme E “compactly evaluates” circuits in CE if E is compact and also correct for circuits in CE .
We can consider various relaxations of compactness, since homomorphic encryption schemes in which the ciphertext size grows sub-linearly with the size of the circuit are still interesting for many applications. For example, we could permit the sizes of the secret key and ciphertexts to grow polynomially with the depth of the circuit. We will informally call such schemes “quasi-compact.”
Now, we deﬁne fully homomorphic encryption as follows.
Deﬁnition 2.1.4 (Fully Homomorphic Encryption). We say that a homomorphic encryption scheme E is fully homomorphic if it compactly evaluates all circuits.
One may consider this deﬁnition to be too strong, because, as mentioned above, quasicompactness could suﬃce; we avoid using quasi-compactness in our deﬁnition both because

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 29
it is tedious to formalize, and we will rarely use the notion anyway. A second reason that it is too strong is because it excludes leveled schemes, which only evaluate circuits of depth up to some d, and whose public key length may be poly(d); hence, the following relaxation.
Deﬁnition 2.1.5 (Leveled Fully Homomorphic Encryption). We say that a family of homomorphic encryption schemes {E(d) : d ∈ Z+} is leveled fully homomorphic if, for all d ∈ Z+, they all use the same decryption circuit, E(d) compactly evaluates all circuits of depth at most d (that use some speciﬁed set of gates), and the computational complexity of E(d)’s algorithms is polynomial in λ, d, and (in the case of EvaluateE ) the size of the circuit C.
(We assume the set of gates that compose the circuit is understood.) While fully homomorphic encryption, as we have deﬁned it, seems highly nontrivial to achieve, one still might consider our deﬁnition to be too weak, since it does not require circuit privacy.
Deﬁnition 2.1.6 ((Statistical) Circuit Private Homomorphic Encryption). We say that a homomorphic encryption scheme E is circuit-private for circuits in CE if, for any keypair (sk, pk) output by KeyGenE (λ), any circuit C ∈ CE , and any ﬁxed ciphertexts Ψ = ψ1, . . . , ψt that are in the image of EncryptE for plaintexts π1, . . . , πt, the following distributions (over the random coins in EncryptE , EvaluateE ) are (statistically) indistinguishable:
EncryptE (pk, C(π1, . . . , πt)) ≈ EvaluateE (pk, C, Ψ)
The obvious correctness condition must still hold.
We prefer to consider circuit privacy to be a property that is separate from, and complementary to, full homomorphism. However, we will eventually show how to make our lattice-based fully homomorphic encryption scheme circuit private. Our technique will be to use a public (i.e., not using the secret key) algorithm RandomizeCTE that, applied post hoc, induces the same distribution (statistically) to ciphertexts output by EncryptE and EvaluateE , while preserving correctness. (See Chapter 20.)
The motivating setting for statistical circuit privacy is two-party computation in the honest-but-curious setting, where Alice holds a circuit, and Bob holds sk. Alice may want her output ciphertext to reveal nothing about her circuit, even though Bob chooses the input ciphertexts. She can hide her circuit by applying RandomizeCTE to the ciphertext output by EvaluateE before sending result to Bob. When sk is shared, one may also deﬁne

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 30
a computational version of circuit privacy, but this is covered by the semantic security of encryption scheme, deﬁned in the next Section.
For most applications, it is acceptable to reveal some limited information about the circuit, such as an upper bound on the number of levels. (Since any circuit is a directed acyclic graph, its gates can be topologically sorted and partitioned into levels, such that each wire extends from one gate to a gate with a higher level number.) Accordingly, we deﬁne the following slight relaxation of circuit privacy.
Deﬁnition 2.1.7 (Leveled Circuit Private Homomorphic Encryption). Like circuit private homomorphic encryption, except that there can be a diﬀerent distribution associated to each level, and the distributions only need to be equivalent if they are associated to the same level (in the circuit).
Unlike circuit privacy, leveled circuit privacy, by itself, does not imply compactness. That is, in a leveled circuit private homomorphic encryption scheme, it is possible for the ciphertext size to grow exponentially with the number of levels. In fact, this is precisely the case in some previous circuit-private schemes, such as SYY [122].
An interesting open question is the extent to which fully homomorphic encryption, as we have deﬁned it, already implies circuit-private fully homomorphic encryption. Intuitively, given a ciphertext ψ that encrypts π, we can “randomize” ψ using the homomorphism – e.g., by repeatedly adding encryptions of ‘0’ – to obtain new encryptions of π. Since the fully homomorphic encryption scheme is compact, this randomization occurs within a non-expanding ciphertext space. One may hope that these randomizations induce a nice, connected, expander-like graph, and that therefore a small number of randomizations results in a statistically random encryption of π. However, the deﬁnition of fully homomorphic encryption does not seem even to imply that this graph is connected. It would be nice to state some natural minimal generic property, in addition to full homomorphism, that would imply circuit privacy. (Certainly, the property that adding an encryption of ‘0,’ or multiplying in an encryption of ‘1,’ completely “randomizes” the ciphertext would be suﬃcient, but in this case circuit privacy is an uninteresting tautology.)
In the deﬁnitions above, we have focused on circuits, but one may also consider programs that use other representation models. For example, one may consider weaker models – e.g., formulas, branching programs, OBDDs, ﬁnite automata, decision trees, and truth tables – and consider the eﬃciency of a homomorphic encryption scheme with respect to one of these

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 31

models. For example, although an encryption scheme that is additively homomorphic will not be able to evaluate general circuits eﬃciently, such a scheme can be used to construct a single-server private information retrieval (PIR) scheme with sub-linear communication; such a PIR scheme, in turn, can be viewed as homomorphic encryption scheme that permits the (eﬃcient) evaluation of a truth table with an output ciphertext that is sub-linear in the size of the table. Ishai and Paskin [73] describe a scheme in which Evaluate takes a branching program (BP) P as input; ﬁnite automata, decision trees, and OBDDs can be eﬃciently represented as BPs. The ciphertext output by their Evaluate algorithm depends polynomially on the number of input ciphertexts and on the depth of the BP, but not on its size. On the other hand, since a program may allow loops, it may permit a more compact representation of the circuit.

2.2 Computational Security Deﬁnitions

For an ordinary public key encryption scheme, security against adaptive chosen-ciphertext attacks (CCA2) is captured in the following game.
Setup. The challenger runs (sk, pk) ←R KeyGenE (λ) and gives pk to the adversary A. It sets ψ∗ ← ⊥.
Queries. A issues decryption queries on ciphertexts ψi = ψ∗. The challenger responds with the output of DecryptE (sk, ψi). Queries can occur before or after the challenge. Challenge. A generates two plaintexts π0∗, π1∗ ∈ P and sends these to the challenger. The challenger sets b ←R {0, 1} and ψ∗ ←R EncryptE (pk, πb∗). It sends ψ∗ to A. Guess. A sends b ∈ {0, 1} to the challenger. A wins the game if b = b.

Security against “lunchtime attacks” – i.e., CCA1 security – is modeled by a game similar to above, except that A may make queries only before the challenge. In the game for semantic security, A is not permitted to make any queries.
In each case, we deﬁne A’s advantage in attacking the scheme E as

Adv(A, E, λ) =

Pr[b

=

b

]

−

1 2

The probability is over the random bits used by the challenger and the adversary.

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 32
Deﬁnition 2.2.1 (Semantic Security against (CPA, CCA1, CCA2) attacks). We say E is semantically secure against (CPA, CCA1, CCA2) attacks if no polynomial time (CPA, CCA1, CCA2)-adversary A breaks E with advantage non-negligible in the security parameter λ.
When referring simply to “semantic security,” we mean semantic security against chosen plaintext attacks.
We deﬁne the CCA2, CCA1, and semantic security games for a homomorphic encryption scheme as being identical to the original games, except that now the ciphertext space is potentially larger – i.e., the support of EvaluateE rather the support of EncryptE ; A can draw its queries from this larger space. Also, A has more freedom in requesting its challenge. The natural way to deﬁne the Challenge phase is that A sends the challenger some circuit C ∈ CE with some number k = poly(λ) of inputs, and two sets of plaintexts, (π01, . . . , π0k), (π11, . . . , π1k) ∈ Pk; the challenger sets b ←R {0, 1} and outputs ψ∗ ←R EvaluateE (pk, C, ψb1, . . . , ψbk) where ψbi ←R EncryptE (pk, πbi). However, since the adversary can run EvaluateE itself, we can simplify the Challenge phase by having the adversary just request the input ciphertexts ψb1, . . . , ψbk.
Clearly, the only diﬀerence between the semantic security games for ordinary public key encryption and homomorphic encryption is that, in the latter, the adversary can request more ciphertexts in the Challenge phase. By a hybrid argument [16], an algorithm A that that breaks the semantic security in the game above with advantage can be used to construct an algorithm B that breaks the semantic security in the original game with advantage /k; B’s is roughly k times that of A [52]. Thus, to prove semantic security of a homomorphic encryption scheme, we can just use the semantic security game for ordinary public key encryption.
The same is true for CCA1 and CCA2 security, as long as the scheme is circuit-private. (Circuit privacy ensures that the ciphertext space is the same in both games, thus allowing B to forward A’s decryption queries to the challenger, and forward the responses back to A.)
Unfortunately, a scheme that has nontrivial homomorphisms cannot be CCA2 secure, because it is malleable. Benign malleability [6] and replayable CCA [30], two relaxed notions of CCA2 security, permit only transformations that preserve the underlying plaintext. Prabhakaran and Rosulek [115] formalize a notion of “homomorphic-CCA security,” which permits certain nontrivial operations on a plaintext while remaining nonmalleable with respect to other operations; they present a construction based on pairings. However, their

CHAPTER 2. DEFINITIONS RELATED TO HOMOMORPHIC ENCRYPTION 33
approach does not extend (in fact, they provide some impossibility results) to schemes that permit certain operations on multiple ciphertexts. Finding meaningful relaxations of CCA2 security in this domain, and particularly for fully homomorphic encryption, is an open area.
There do not seem to be inherent reasons why a homomorphic encryption scheme cannot have semantic or CCA1 security. In particular, “Cramer-Shoup lite” [36] is CCA1 and homomorphic (for one operation). However, we restrict our focus to semantic security, and leave ﬁnding a CCA1-secure fully homomorphic encryption scheme as an interesting open problem.

Chapter 3
Previous Homomorphic Encryption Schemes
Basic RSA [121] was the ﬁrst homomorphic encryption scheme: given ciphertexts ψ1 = π1e mod N and ψ2 = π2e mod N , one can compute a ciphertext ψ ← ψ1·ψ2 = (π1·π2)e mod N that encrypts the product of the original plaintexts. However, basic RSA is deterministic, and therefore not even semantically secure. Despite the lack of semantic security, RSA’s multiplicative homomorphism is still useful for many applications.
Rivest, Adleman, and Dertouzos [120] were the ﬁrst to explore the possibilities of fully homomorphic encryption, which they called a “privacy homomorphism”, and they proposed several candidate schemes. However, these early candidates have been broken [25].
Homomorphic encryption schemes that are not semantically secure, like textbook RSA and some proposals in [120], may also have stronger attacks on their one-wayness. In particular, Boneh and Lipton [23] proved that any algebraic privacy homomorphism over a ring Zn can be broken in sub-exponential time under a (reasonable) number theoretic assumption, if the scheme is deterministic or oﬀers an equality oracle. See also [92]. In the quantum setting, the situation is even worse. van Dam, Hallgen and Ip [37] proved that, with quantum computation, any deterministic algebraic privacy homomorphism with an equality oracle can be broken in polynomial time.
The ﬁrst scheme with a proof of semantic security based on a well-deﬁned assumption
34

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

35

was proposed by Goldwasser-Micali [61] in the paper that introduced the notion of semantic security. Some other additively homomorphic encryption schemes with proofs of semantically security are Benaloh [17], Naccache-Stern [102], Okamoto-Uchiyama [108], Paillier [110], and Damgard-Jurik [38]. ElGamal [42] is multiplicatively homomorphic. Some semantically secure schemes that allow both addition and multiplication include BonehGoh-Nissim [21], which permits computation of quadratic formulas (e.g., 2-DNFs) over ciphertexts, and “Polly Cracker” by Fellows and Koblitz [44], which permits computation of arbitrary circuits over ciphertexts, but where the ciphertext size blows up exponentially with the depth of the circuit. For expository purposes, and since one can easily ﬁnd other surveys of homomorphic encryption, we characterize these “conventional” homomorphic encryption schemes (although perhaps Polly Cracker is less conventional) as all falling within a certain abstract framework, with security abstractly based on an ideal membership problem. We will review these schemes in more detail momentarily. This description will help highlight how our construction is fundamentally diﬀerent, abstractly relying on an ideal coset problem that we deﬁne in Chapter 7.
It is also known that one can construct additively homomorphic encryption schemes from lattices or linear codes [60, 113, 77, 94, 95, 7]. The lattice-based scheme [95] and the Reed-Solomon-code-based scheme by Armknecht and Sadeghi [7] also allow multiplications, though with exponential expansion in ciphertext size. Such schemes have a diﬀerent ﬂavor from the more “conventional” schemes above, because ciphertexts implicitly contain an “error” that grows as ciphertexts are added together. Thus, ciphertexts output by Evaluate do not have the same distribution as ciphertexts output by Encrypt, and at some point the error may become large enough to cause incorrect decryption. For this reason, the homomorphism is sometimes referred to as a “pseudohomomorphism” [77, 94, 95] or a “bounded homomorphism” [113]. (We use diﬀerent terminology; see Chapter 2.) We will not discuss these schemes in detail here, since the main technical complication – managing the size of the “error” – is also central to our scheme, where it will require an even closer analysis because our multiplicative homomorphism using ideal lattices expands the “error” quite rapidly.
van Dijk [40] describes a technique that they call “interval obfuscation” which can be viewed as a symmetric homomorphic encryption scheme. It uses a secret integer modulus M and a secret integer s that is relatively prime to M . A ‘0’ is encrypted as s · x mod M for some x ∈ [1, a], where a is a “small” integer, while a ‘1’ is encrypted as s· x mod M for some

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

36

x ∈ [b + 1, b + a], where b is a “large” integer (but still small in comparison to M ). One can cryptocompute a homogeneous polynomial of degree d logarithmic in the security parameter by simply adding or multiplying the ciphertexts modulo M . The recipient decrypts c by setting c ← c/sd mod M (to remove the blinding factor) and then outputting c /bd ; the idea is that each monomial which is a product of 1’s will be represented by some integer that approximately equals bd after the blinding factor is removed, while the monomials for which the product is 0 will be represented by much smaller integers that can be ignored. One can view their scheme as using a one-dimensional ideal lattice – namely, the ideal (M ) in the integers – while our somewhat homomorphic construction in Chapter 7 is conceptually somewhat similar but uses an n-dimensional ideal lattice. At a high level, the reason M must be kept private in their scheme (while we can reveal a basis for the lattice in our scheme) is that lattice problems over one-dimensional lattices are not hard. An initial version of van Dijk’s scheme succumbed to attacks that used lattice reduction to recover M . It is an open question as to whether the security of a variant of van Dijk’s scheme can be based on a natural hard problem.
Finally, there are schemes that use a singly homomorphic encryption scheme to construct a scheme that can perform more complicated homomorphic operations [122, 73]. Sanders, Young and Yung (SYY) [122] show that one can use a circuit-private additively homomorphic encryption scheme to construct a circuit-private scheme that can handle arbitrary circuits, where the ciphertext size increases exponentially with the depth of the circuit. Their scheme can therefore feasibly evaluate NC1 circuits.
Ishai and Paskin [73] show how to evaluate branching programs, and with much smaller ciphertexts than SYY. In their scheme Evaluate outputs a ciphertext whose length is proportional to the length of the branching program. This remains true even if the size of the branching program is very large – e.g., super-polynomial. However, the computational complexity of their scheme is proportional to the size; Barrington [13] tells us that boundedwidth polynomial-size branching programs recognize exactly those languages in NC1.
In more detail, Ishai and Paskin use a “leveled” approach to evaluate a branching program, like we will use a leveled approach to evaluate circuits (see Chapter 4), though the details are very diﬀerent. A (deterministic) branching program (BP) P is deﬁned by a DAG from a distinguished initial node in which each nonterminal node has two outgoing edges labeled 0 and 1, and where the terminal nodes also have labels. To compute P (x) where the binary representation of x is x1 · · · x , one starts at the distinguished node, and

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

37

traverses the DAG in the natural way dictated by x1 · · · x to reach a terminal node, and outputs that node’s label as P (x). The size of the BP is the number of nodes; the length is the length of the longest path. One can topologically arrange the nodes into levels, such that the number of levels is at most one more than the length of the BP, and the edges are all directed downward. BPs are relatively powerful; ﬁnite automata, decision trees, and ordered binary decision diagrams all have polynomial-size BPs.
To evaluate a BP, Ishai and Paskin essentially use 1-out-of-2 string OT recursively. Speciﬁcally, suppose Alice has a BP with levels, and Bob has an input x = x1 · · · x ∈ {0, 1} for which he wants to obtain P (x). Bob constructs 1-out-of-2 string OT queries qi, which respectively correspond to his bits xi. Using Bob’s queries, Alice evaluates her BP from the bottom-up. In particular, suppose N is a node at level − 1 with children N 0 and N 1 with labels L0 and L1. Alice uses q , L0 and L1 to construct a string-OT response R that implicitly “encrypts” label Lx ; she then sets R to be the label of N . In this fashion, she gives labels to all of the nodes at level − 1, and then (recursively) to nodes at higher levels using Bob’s other OT queries. Alice’s ultimate response is the label associated to the distinguished node. This ﬁnal label looks something like a multiple encryption in onion routing, and Bob “decrypts” it as such – using his secret knowledge to recover the label for x1, then x1x2, and so on. The length of Alice’s response grows (at least) linearly with for essentially the same reason that this happens in onion-routing: each layer of “encryption” has additive communication overhead. Using a communication-eﬃcient string-OT scheme – e.g., one built from the length-ﬂexible additively homomorphic Damgard-Jurik encryption scheme [38, 84] – the ciphertext expansion per level is exactly linear. On the other hand, Alice’s computation is proportional to the size of the BP, since she must construct OT responses even for “irrelevant” nodes in the BP.
To summarize to current state of aﬀairs as far we know, in terms of schemes that oﬀer more than a single homomorphism and oﬀer a proof of semantic security, we have the schemes by Fellow and Koblitz [44], Melchor et al. [95], Armknecht and Sadeghi [7], and Sanders et al. [122], and related work [14, 83, 85, 86] where ciphertext size grows exponentially with the multiplicative (and sometimes also additive) depth of the circuit. In Boneh-Goh-Nissim [21] and Ishai-Paskin [73], Evaluate outputs small ciphertexts but handles a limited class of circuits – quadratic formulas, or circuits which correspond to branching programs of manageable size.

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

38

Now, we review the more “conventional” homomorphic encryption schemes whose semantic security can be based on a natural problem, like Goldwasser-Micali and Paillier. Since our scheme will rely heavily on properties of algebraic rings and ideals, we explain how these previous schemes implicitly use these objects. By describing previous schemes using these abstractions, we will see how the semantic security of most of these schemes relies on the hardness of an ideal membership problem – i.e., determining whether a member of the ring is also a member of the ideal.
Basically, a ring is a mathematical object like a ﬁeld, except that not every element has a multiplicative inverse. Examples include the integers Z, or the integers modulo a composite integer N : Z/N Z. Rings have an additive identity ‘0’, a multiplicative identity ‘1’, allow additive inverses, and are closed under addition and multiplication. An ideal I of a ring R is a subset of R that is closed under addition, and is also closed under multiplication with elements of R. An example is the ideal (2) of Z, the set of even numbers; multiplying an element of (2) with an element of Z gives an element in (2). For ideal I ⊂ R, R/I is the ring of cosets of I in R; e.g., if R = Z and I = (2), R/I consists of the cosets 0 + (2) (the even integers, the additive identity of R/I) and 1 + (2) (the odd integers, the multiplicative identity of R/I).
With these abstractions, we can say that many previous homomorphic encryption schemes fall within the following framework. (Essentially, this abstract framework is explicit in Fellows’ and Koblitz’s description of Polly Cracker [44].)

KeyGen(λ). Generates some representation of a ﬁnite ring R with an eﬃcient ‘+’ operation, and possibly an eﬃcient ‘×’ operation. It also ﬁxes an ideal I of R. The plaintext space P is a set of distinguished representatives of R/I. The secret key is a function f : R → P such that f (r) is the distinguished representative of r + I. The public key pk includes the encoding of R and an algorithm SampI to sample (eﬃciently) from I. Encrypt(pk, π). Set i ←R SampI (R) and ψ ← π + i. Decrypt(sk, ψ). Output f (ψ).
Add(ψ1, ψ2). Output ψ1 + ψ2. Mult(ψ1, ψ2). Output ψ1 × ψ2.

For example, in Goldwasser-Micali, KeyGen generates a modulus N = pq for p = 2p + 1

and q = 2q + 1, and a number x ∈ (Z/N Z)∗ whose Legendre symbols are

x p

=

x q

= −1.

In terms of the abstract framework, the underlying ring R is Z/(2p q ), which corresponds to

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

39

the powers of x modulo N . The underlying ideal I is (2), the set of quadratic residues, even powers of x. The plaintext space is {0, 1}, represented as {x0, x1}. The function f : R → P on input r ∈ R (i.e., xr) is given by outputting the distinguished representative of r + (2). Sampling from I is eﬃcient. Also, the ‘+’ operation is eﬃcient, though the ‘×’ operation is not; hence, the scheme is only additively homomorphic.
Remark 3.0.2. The abstract framework hides some issues regarding how plaintexts are represented. For example, as applied to Goldwasser-Micali, the framework would say plaintext space is {x0, x1}, versus the usual {0, 1}. For Goldwasser-Micali, this is ﬁne since the encrypter can easily map the latter representation to the former. This is the case with the other schemes as well.
Remark 3.0.3. Of course, a lot of complexity is hidden in the function f . GoldwasserMicali uses Legendre symbols. Paillier uses a more elaborate approach. Some schemes, such as Boneh-Goh-Nissim (described below) can use only a small (polynomial-sized) subset of the potential plaintext space because the function f involves an otherwise infeasible computation – e.g., discrete logarithm.
It is easy to see that the abstract scheme is semantically secure assuming the following ideal membership problem is hard.
Deﬁnition 3.0.4 (Ideal Membership Problem (IMP)). According to a prescribed distribution, the challenger generates an encoding of R, an ideal I, and an algorithm SampI that samples from I. It sets a bit b ←R {0, 1}. If b = 0, it sets x ←R SampI (R). If b = 1, it sets x ←R R. The problem is to guess b given (x, R, SampI ) – i.e., essentially to decide whether or not x is a member of I.
Theorem 3.0.5. If there is an algorithm A that breaks the semantically security of the abstract scheme with advantage , then there is an algorithm B that solves the IMP with advantage /2.
Proof. Given instance (x, R, SampI ) of IMP, B includes (R, SampI ) in pk, which it sends to A. A requests a challenge ciphertext on one of π0, π1 ∈ P. B sets β ←R {0, 1}, and sends the challenge ψ ← πβ + x to A. A sends guess β , and B sends guess b ← β ⊕ β to the challenger.
If b = 0, then B’s simulation is perfect; in particular, the challenge is a valid encryption of πβ. In this case, A should guess β with advantage , and thus b = b with advantage .

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

40

If b = 1, x is random in R, and thus the challenge ciphertext is a random element of R, independent of β. In this case, β is independent of β, and so b is independent of b, so that B’s advantage is 0. Overall, B’s advantage is /2.
Obviously, Goldwasser-Micali uses quadratic residuosity as its version of the IMP. Benaloh is similar to Goldwasser-Micali, but uses ideals of the form (m) for m = 2 where m divides φ(N ). In Paillier, the ring is Z/(p q N ), the ideal is (N ), and it is based on the N -th residuosity problem. Damgard-Jurik extends Paillier to the ring is Z/(p q N k) and uses the ideal is (N k). Okamoto-Uchiyama uses a modulus of the form N = p2q, and uses the ring Z/(pp q ) and the ideal Z/(p).
The above schemes can all be said to be based on a subgroup (or subset) membership problem [?], since only one operation (namely addition, which is instantiated as group multiplication) is actually being used. Two schemes that make more use of the ring structure are Polly Cracker [44] and Boneh-Goh-Nissim (BGN) [21].
The Polly Cracker scheme was proposed by Fellows and Koblitz [44]. They state essentially the abstract framework above and propose an instantiation of it using the polynomial ring R = Fq[x1, . . . , xn]. The ideal I is presented as a set of generating polynomials P = {pi(x1, . . . , xn)} having a common (secret) root (a1, . . . , an); the ideal I is the set of all polynomials of the form pi(x) · ri(x) for ri(x) ∈ R. To sample from I, one uses the generators, though there is plenty of freedom here in setting the sampling distribution since R and I are inﬁnite. The plaintext space is Fq. The abstract function f is instantiated as evaluation of the ciphertext polynomial at (a1, . . . , an), a homomorphism whose kernel contains I.
The security of Polly Cracker in practice still seems to be an open question. Various eﬃcient attacks have been proposed for various sets of parameters [43, 46] – roughly speaking, parameters for which the underlying IMP is not hard because it is possible to recover the common root using Groebner bases. Modiﬁed versions of Polly Cracker have been proposed [83, 85, 86], also with attacks [126]. But there does not seem to be an eﬃcient general attack. See [82] for a survey of Polly Cracker cryptanalysis.
Ciphertext expansion in Polly Cracker is a serious problem. Add simply adds two ciphertext polynomials, and Mult multiplies them. In the worst-case, Mult operations are extremely expensive: the ciphertext length grows doubly-exponentially in the multiplicative depth of the circuit, since each Mult operation can square the number of monomials. Even with respect to the additive depth, the ciphertext size can grow exponentially. It is

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

41

certainly conceivable that some incarnation of Polly Cracker could escape this deﬁciency and still be secure, but so far no such scheme is known.
BGN is a practical scheme that permits homomorphic evaluation of quadratic formulas – i.e., it allows one level of multiplication and an arbitrary number of additions. It is an interesting case because it uses multiple diﬀerent representations of its underlying ring R. Speciﬁcally, KeyGen generates a modulus N = pq, two groups G, G1 of order N with an eﬃciently computable non-degenerate bilinear map e : G × G → G1 (where typically G is an elliptic curve group and G1 is a multiplicative subgroup of a ﬁnite ﬁeld), a generator g of G, and an element h = gp. In terms of the abstract framework, the underlying ring R is Z/(N ), which is represented in the public key both by (G, g) and implicitly (G1, e(g, g)); we will call these the G-representation and the G1-representation. The ideal I is (p), the p-residues; it can be sampled eﬃciently using h. Essentially, the underlying IMP is, given the representations of R, the map e, and the generator of I, to decide whether an element x ∈ R, given in G-representation, is in I. (The BGN paper states its underlying hard problem in a diﬀerent way, without the generator of I, that is equivalent up to a factor of 2 in the adversary’s advantage.)
Adding two ciphertexts in BGN is done in the usual way, but the Mult operation is more interesting. Mult uses the pairing operation, meaning that it can only be applied to two ciphertexts in G-representation, and the output has a G1-representation: i.e., for ψ1 ∈ π1 + (p) and ψ2 ∈ π2 + (p), Mult(ψ1, ψ2) = ψ1 × ψ2 ∈ π1 × π2 + (p), but the latter ciphertext represents the ring element diﬀerently (in G1-representation); concretely, this multiplication in the exponent occurs by computing e(gx, gx) → e(g, g)xy. Since there is no known way to eﬃciently map from the G1-representation back to the G-representation, the scheme is limited to one level of multiplication.
To decrypt a ciphertext gπ+tp in G in BGN, the decrypter computes (gπ+tp)q = gπq, and then DLgq (gπq) = π; it decrypts ciphertexts in G1 similarly. For the discrete logarithm computation to be feasible, π must be from a set of polynomial size – say, a polynomialsized interval centered at 0. However, subject this constraint on the input ciphertexts {ψi} from G, the scheme can homomorphically compute arbitrary polynomial-sized quadratic formulas on {ψi}, and still be able to decrypt the result in polynomial time.
In principle, one can also squeeze ElGamal into the above framework. One can view R as GL(2, Fp), the general linear group of 2 × 2 matrices over Fp, and an ideal Ib ⊂ R as the subset of matrices whose second row is b times the ﬁrst column. Basically, Ib corresponds

CHAPTER 3. PREVIOUS HOMOMORPHIC ENCRYPTION SCHEMES

42

to the set of valid DDH tuples (g, ga, gb, gab) involving b. We can deﬁne addition in R as simply adding the matrices together entry-wise; Ib is closed under addition. This operation is eﬃcient even if matrix is represented “in the exponent,” as in ElGamal, permitting the additive homomorphishm. Multiplication in R is right-multiplication; one can see that right-multiplying a term in Ib with a term in R gives a term in Ib. However, obviously right-multiplication cannot be eﬃcient if the Diﬃe-Hellman problem is hard.
Strictly speaking, however, since none of these schemes aside from Polly Cracker actually makes full use of the ring homomorphism, their dependence on an IMP may be more coincidental than essential. For example, one can modify BGN in a way that preserves the ability to evaluate quadratic formulas, while dispensing with the need to use a composite modulus N , and without using an ideal membership problem; instead, it is based on a “rank” problem similar to the linear assumption. On the other hand, this modiﬁcation would become exponentially ineﬃcient if extended to handle n-degree polynomials over ciphertexts with a hypothetical n-linear map; for this more robust homomorphism, it would seem more eﬃcient to use BGN’s original ideal-membership approach.

Chapter 4
Bootstrappable Encryption
4.1 Leveled Fully Homomorphic Encryption from Bootstrappable Encryption, Generically
Assume we have an encryption scheme E that compactly evaluates some set of circuits CE . We want to use E to construct a homomorphic encryption scheme that can handle arbitrary circuits. In this Chapter we prove a fundamental result: that if CE contains (slight augmentations of) E’s own decryption circuit DE – i.e., if E “compactly evaluates” its (augmented) decryption circuit – then we can use E to construct an eﬃcient scheme that handles circuits of arbitrary depth.
A bit more speciﬁcally, for any integer d, we use E to construct a scheme E(d) that can compactly evaluate circuits of depth up to d. The decryption circuit for E(d) is still DE ; the secret key and ciphertexts are the same size as in E. The public key in E(d) consists of d + 1 public keys from E, together with a chain of encrypted E secret keys – the ﬁrst E secret key encrypted under the second E public key, and so on. In short, the family of schemes {E(d)} is leveled fully homomorphic. We base the semantic security of E(d) on that of E using a hybrid argument; as usual with hybrid arguments, the reduction loses a factor linear in d. In Chapter 4.3, we describe how one can obtain a fully homomorphic encryption scheme (where the public key size does not depend on the maximum number of levels we want to evaluate) by assuming key-dependent-message (KDM) security, speciﬁcally circular-security – i.e., that one can safely encrypt a E secret key under its associated public key.
43

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

44

Since this critical property of E – that it can compactly evaluate (slight augmentations of) its own decryption circuit – is self-referential and universal, we give it the obvious name: bootstrappability. Why should bootstrappability be such a powerful feature? At a high level, the reason is that bootstrappability allows us periodically to “refresh” ciphertexts associated to interior nodes in a circuit; we can refresh for an arbitrary number of levels in the circuit, and thus can evaluate circuits of arbitrary depth. To “refresh” a ciphertext that encrypts a plaintext π under E public key pki, we re-encrypt it under pki+1 and then homomorphically apply the decryption circuit to the result, using the secret key ski that is encrypted under pki+1, thereby obtaining an encryption of π under pki+1. Homomorphically evaluating the decryption circuit decrypts the inner ciphertext under pki, but within homomorphic encryption under pki+1. The implicit decryption “refreshes” the ciphertext, but the plaintext is never revealed; the plaintext is always covered by at least one layer of encryption. Now that the ciphertext is refreshed, we can “continue” correctly evaluating the circuit.
To see how this works mathematically, begin by considering the following algorithm, called Recrypt. For simplicity, suppose the plaintext space P is {0, 1} and DE is a boolean circuit in CE . Let (sk1, pk1) and (sk2, pk2) be two E key-pairs. Let ψ1 be an encryption of π ∈ P under pk1. Let sk1j be an encryption of the j-th bit of the ﬁrst secret key sk1 under the second public key pk2. Recrypt takes as these things as input, and outputs an encryption of π under pk2.
Recrypt(pk2, DE , sk1j , ψ1).
Set ψ1j ←R EncryptE (pk2, ψ1j) where ψ1j is the j-th bit of ψ1 Set ψ2 ← EvaluateE (pk2, DE , sk1j , ψ1j ) Output ψ2
Above, the Evaluate algorithm takes in all of the bits of sk1 and all of the bits of ψ1, each encrypted under pk2. Then, E is used to evaluate the decryption circuit homomorphically. The output ψ2 is thus an encryption under pk2 of DecryptE (sk1, ψ1) → π.
Remark 4.1.1. The Recrypt algorithm implies a proxy one-way re-encryption scheme [19]. Roughly speaking, a one-way proxy re-encryption scheme allows the owner of sk1 to generate a tag that enables an untrusted proxy to convert an encryption of π under pk1 to an encryption of π under pk2, but not the reverse. In our case, the tag is sk1j , the encrypted

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

45

secret key. Strictly speaking, the security model for proxy re-encryption typically requires the security of the delegator’s secret key, even against a collusion of delegatee’s who also get to see the delegating tags. However, this requirement seems unnecessary, since a delegatee will be able to decrypt ciphertexts directed to the delegator anyway.
In the Recrypt algorithm above, the plaintext π is doubly encrypted at one point – under both pk1 and pk2. Depending on the encryption scheme E, however, this double encryption might be overkill. Suppose WeakEncryptE is an algorithm such that the image of WeakEncryptE (pk, π) is always a subset of the image of EncryptE (pk, π). Then we can replace the ﬁrst step of RecryptE with:
Set ψ1j ←R WeakEncryptE (pk2, ψ1j) where ψ1j is the j-th bit of ψ1
Let us call this relaxation RecryptE . The main point of this relaxation is that WeakEncrypt does not need to be semantically secure for RecryptE to be a secure one-way proxy reencryption scheme, or for RecryptE to be useful toward bootstrapping (as we will see below). Thus, depending on E, WeakEncryptE can be very simple – e.g., for some schemes, and in particular for the ideal-lattice-based scheme that we describe later, WeakEncryptE might leave the input “bits” entirely unmodiﬁed. This will unfortunately not help us much in terms of making the encryption scheme bootstrappable; essentially, it will add one circuit level to what E can evaluate. However, it will aﬀect the eventual computational complexity of our scheme, since it will require less computation to apply the decryption circuit homomorphically to ciphertexts in which the outer encryption is weak. Another way of viewing this relaxation is that we only need to be able to evaluate non-uniform decryption circuits, where the ciphertext is “hard-wired” into the circuit (making this circuit simpler than the “normal” decryption circuit that takes the ciphertext (and secret key) as input.
To be bootstrappable, E needs to be able to compactly evaluate not only its decryption circuit, which merely allows recryptions of the same plaintext, but also slightly augmented versions of it, so that we can perform binary operations on plaintexts and make actual progress through a circuit.
Deﬁnition 4.1.2 (Augmented Decryption Circuit). Let DE be E’s decryption circuit, which takes a secret key and ciphertext as input, each formatted as an element of P (λ), where P is the plaintext space. Let Γ be a set of gates with inputs and output in P, which includes the trivial gate (input and output are the same). We call a circuit composed of multiple copies

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

46

of DE connected by a single g gate (the number of copies equals the number of inputs to g) a “g-augmented decryption circuit.” We denote the set of g-augmented decryption circuits, g ∈ Γ, by DE (Γ).
Deﬁnition 4.1.3 (Bootstrappable Encryption Scheme). As before, let CE denote the set of circuits that E can compactly evaluate. We say that E is bootstrappable with respect to Γ if

DE (Γ) ⊆ CE .

For example, if Γ includes the trivial gate and NAND, E is bootstrappable with respect to Γ if CE contains DE and the circuit formed by joining two copies of DE with a NAND gate. Remarkably, as we will show, if there is a scheme E that can compactly evaluate only these two circuits, then there is a scheme that is leveled fully homomorphic.

Remark 4.1.4. We could relax the bootstrappability deﬁnition slightly to say that E only needs to be able to homomorphically evaluate its (augmented) decryption circuit when the input ciphertext is weakly encrypted, similar to the relaxation RecryptE above. But, this makes the deﬁnition of bootstrappable more cumbersome; we will continue with the deﬁnition above, and remind the reader occasionally that the relaxation can be used.

From the informal description above, it should already be somewhat clear how to use a bootstrappable encryption scheme to construct a leveled fully homomorphic one; below, we give a more formal description. Let E be bootstrappable with respect to a set of gates Γ. For any integer d ≥ 1, we use E to construct a scheme E(d) = (KeyGenE(d), EncryptE(d), EvaluateE(d), DecryptE(d)) that can handle all circuits of depth d with gates in Γ. Note that in the description below we encrypt the secret keys in reverse order; the only reason is that this ordering simpliﬁes our description of the recursion in Evaluate. When we refer to the level of a wire in C, we mean the level of the gate for which the wire is an input. We use the notation DE (Γ, δ) to refer to the set of circuits that equal a δ-depth circuit with gates in Γ augmented by DE (copies of DE become inputs to the δ-depth circuit).
KeyGenE(d)(λ, d). Takes as input a security parameter λ and a positive integer d. For = (λ) as in Deﬁnition 4.1.2, it sets

(ski, pki) ←R KeyGenE (λ) skij ←R EncryptE (pki−1, skij)

for i ∈ [0, d] for i ∈ [1, d], j ∈ [1, ]

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

47

where ski1, . . . , ski is the representation of ski as elements of P. It outputs the secret key sk(d) ← sk0 and the public key pk(d) ← ( pki , skij ). Let E(δ) refer to the sub-system that uses sk(δ) ← sk0 and pk(δ) ← ( pki i∈[0,δ], skij i∈[1,δ]) for δ ≤ d.
EncryptE(d)(pk(d), π). Takes as input a public key pk(d) and a plaintext π ∈ P. It outputs a ciphertext ψ ←R EncryptE (pkd, π).
DecryptE(d)(sk(d), ψ). Takes as input a secret key sk(d) and a ciphertext ψ (which should be an encryption under pk0). It outputs DecryptE (sk0, ψ).
EvaluateE(δ)(pk(δ), Cδ, Ψδ). Takes as input a public key pk(δ), a circuit Cδ of depth at most δ with gates in Γ, and a tuple of input ciphertexts Ψδ (where each input ciphertext should be under pkδ). We assume that each wire in Cδ connects gates at consecutive levels; if not, add trivial gates to make it so. If δ = 0, it outputs Ψ0 and terminates. Otherwise, it does the following:
• Sets (Cδ†−1, Ψ†δ−1) ← AugmentE(δ) (pk(δ), Cδ, Ψδ).
• Sets (Cδ−1, Ψδ−1) ← ReduceE(δ−1) (pk(δ−1), Cδ†−1, Ψ†δ−1).
• Runs EvaluateE(δ−1) (pk(δ−1), Cδ−1, Ψδ−1).
AugmentE(δ)(pk(δ), Cδ, Ψδ). Takes as input a public key pk(δ), a circuit Cδ of depth at most δ with gates in Γ, and a tuple of input ciphertexts Ψδ (where each input ciphertext should be under pkδ). It augments Cδ with DE ; call the resulting circuit Cδ†−1. Let Ψ†δ−1 be the tuple of ciphertexts formed by replacing each input ciphertext ψ ∈ Ψδ by the tuple
skδj , ψj , where ψj ← WeakEncryptE(δ−1)(pk(δ−1), ψj) and the ψj’s form the properlyformatted representation of ψ as elements of P. It outputs (Cδ†−1, Ψ†δ−1). ReduceE(δ)(pk(δ), Cδ†, Ψ†δ). Takes as input a public key pk(δ), a tuple of input ciphertexts Ψ†δ (where each input ciphertext should be in the image of EncryptE(δ)), and a circuit Cδ† ∈ DE (Γ, δ + 1). It sets Cδ to be the sub-circuit of Cδ† consisting of the ﬁrst δ levels. It sets Ψδ to be the induced input ciphertexts of Cδ, where the ciphertext ψδ(w) associated to wire w at level δ is set to EvaluateE (pkδ, Cδ(w), Ψ(δw)), where Cδ(w) is the sub-circuit of Cδ† with output wire w, and Ψδ(w) are the input ciphertexts for Cδ(w). It outputs (Cδ, Ψδ).
High-level review of the Evaluate algorithm. We are given a circuit Cd of, say, d levels with gates in Γ. For each input wire w of Cd, there is an associated input ciphertext ψw

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

48

encrypted under pkd. We are also given an encryption scheme E that compactly evaluates circuits in DE (Γ).
Note that we have not assumed that E can evaluate gates in Γ; we have only assumed it can evaluate gates in Γ that are augmented by the decryption circuit. So, our ﬁrst step is to augment Cd by placing copies of DE at the leaves of Cd (as in Augment), thereby constructing Cd†−1. Now, what are the input ciphertexts for our new circuit Cd†−1?
Reconsider the algorithm RecryptE . In RecryptE , we begin with a ciphertext ψ1 encrypting π under pk1 for the single wire w, and an “empty” circuit C1 (since RecryptE doesn’t actually evaluate any gates, it just generates a new encryption of the same plaintext). Our next step was to augment C1 with the decryption circuit DE to obtain C2 ← DE . The input ciphertexts Ψ2 to C2 included the encrypted secret key bits, and the weakly encrypted bits of ψ1. We then showed that the ciphertext generated by ψ2 ← EvaluateE (pk2, C2, Ψ2), which is also associated to wire w, also encrypts π, but now under pk2.
In the full scheme above, the ciphertexts that we associate to the decryption circuit that was attached to wire w are analogous to the ones we used in RecryptE : the encrypted secret key (skd under pkd−1), and the re-encryption ciphertexts of ψw under pkd−1. By the correctness of Recrypt, the ciphertext now associated to w (after performing EvaluateE ) should encrypt the same plaintext as ψw, but now under pkd−1.
The Reduce step simply performs this Evaluate up to the wire w, and one level beyond. We know that Evaluate can correctly continue one level beyond the wire w, because (by assumption) E can evaluate not just the decryption circuit attached to w, but can evaluate a circuit containing one Γ-gate above w. Reduce outputs Cd−1 and ciphertexts associated to Cd−1’s input wires. We have made progress, since Cd−1 is one level shallower than Cd. We perform this entire process d − 1 more times to obtain the ﬁnal output ciphertexts.
Remark 4.1.5. Previously, we said that Evaluate takes as input ciphertexts that are “fresh” outputs of Encrypt. However, we note EvaluateE(δ) also operates correctly on ciphertexts output by Evaluate. (For δ < d above, this is precisely what EvaluateE(δ) does.)
4.2 Correctness, Computational Complexity and Security of
the Generic Construction
Here we state and prove some theorems regarding the generic construction. Regarding correctness, we have the following theorem.

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

49

Theorem 4.2.1. Let E be bootstrappable with respect to a set of gates Γ. Then E(d) compactly evaluates all circuits of depth d with gates in Γ – i.e., if Γ is a universal set of gates, the family E(d) is leveled fully homomorphic.
Proof. (Theorem 4.2.1) First, we deﬁne a convenient notation: let D(δ, w, C, Ψ) denote the plaintext value for wire w in circuit C induced by the decryptions (under skδ) of the ciphertexts Ψ associated to C’s input wires. If C is empty (has no gates), then the input wires are the same as the output wires, and D(δ, w, C, Ψ) just denotes the decryption of the single ciphertext ψ ∈ Ψ associated to w. To prove correctness, it suﬃces to show that

D(d, wout, Cd, Ψd) = D(0, wout, C0, Ψ0)

(4.1)

for every output wire wout of C0 (at level 0). First, when (Cδ†−1, Ψ†δ−1) ← AugmentE(δ)(pk(δ), Cδ, Ψδ), we claim that D(δ, w, Cδ, Ψδ) =
D(δ−1, w, Cδ†−1, Ψ†δ−1) for any wire w at level at most δ−1. This follows from the correctness
of Recrypt (generalized beyond a boolean plaintext space and boolean circuits), and the fact
that circuits Cδ and Cδ†−1 are identical up to level δ − 1. Next, when (Cδ, Ψδ) ← ReduceE(δ)(pk(δ), Cδ†, Ψ†δ), we have D(δ, w, Cδ†, Ψ†δ) = D(δ, w, Cδ, Ψδ)
for any wire at level at most δ. This follows from the correctness of EvaluateE over circuits in DE (Γ), and the fact that circuits Cδ† and Cδ are identical up to level δ.
From these two claims, Equation 4.1 follows.

Note that Γ is arbitrary. For example, each gate in Γ could be a circuit of (ANDs, ORs, NOTs) of depth m and fan-in 2; for this value of Γ, Theorem 4.2.1 implies the scheme correctly evaluates boolean circuits up to depth d · m.
We need to check that the computational complexity of EvaluateE(d) is reasonable – e.g., that recursive applications of Augment do not increase the eﬀective circuit size exponentially.
Theorem 4.2.2. For a circuit C of depth at most d and size s (deﬁned here as the number of wires), the computational complexity of applying EvaluateE(d) to C is dominated by at most s · · d applications of WeakEncryptE and at most s · d applications of EvaluateE to circuits in DE (Γ), where is as in Deﬁnition 4.1.2.
Proof. (Theorem 4.2.2) There is a pre-processing step to ensure that all wires in the circuit connect gates at consecutive levels; clearly, this step increases the number of wires in the

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

50

circuit by at most a multiplicative factor of d. It remains to prove that, for the pre-processed circuit, the computational complexity is dominated by at most s · applications of Encrypt and at most s applications of EvaluateE to circuits in DE (Γ), where s is the size of the pre-processed circuit.
The complexity of AugmentE(δ)(pk(δ), Cδ, Ψδ) is dominated by replacing each ciphertext ψ ∈ Ψδ by the ciphertexts skδj , ψj ; generating the ψj ’s involves |Wδ| · applications of WeakEncryptE , where Wδ is the set of wires at level δ. Summing over all δ, there are at most s · applications of WeakEncryptE .
The complexity of ReduceE(δ)(pk(δ), Cδ†, Ψ†δ) is dominated by the evaluation of Cδ(w) for each w ∈ Wδ, which involves |Wδ| applications of EvaluateE to circuits in DE (Γ). Summing over all δ, there are at most s such applications. The theorem follows.
Finally, assuming the semantic security of E, we prove the semantic security of E(d).
Theorem 4.2.3. Let A be an algorithm that (t, )-breaks the semantic security of E(d). Then, there is an algorithm B that (t , )-breaks the semantic security of E for t ≈ t · and
≥ / (d + 1), for as in Deﬁnition 4.1.2.
Proof. (Theorem 4.2.3) Let (E) be equivalent to E, but with plaintext space P≤ , where Encrypt(E) involves up to invocations of E and a concatenation of the results. We use a hybrid argument to show that B (t , )-breaks the semantic security of (E) for t ≈ t and
≥ /(d + 1), from which the result follows. For k ∈ [0, d], let Game k denote a game against E(d) in which everything is exactly as in the real-world game, except that for all i ∈ [1, k] the challenger sets
(ski, pki) ←R KeyGenE (λ) and skij ←R EncryptE (pki−1, skij)
In other words, for i ∈ [1, k], skij is the encryption (under pki−1) of the j-th bit of a random secret key ski unrelated to ski. Game d + 1 is identical to Game d, except that the challenger ignores b and (π0, π1), generates a random plaintext π of the appropriate length, and encrypts π to construct the challenge ciphertext. Let k denote the adversary’s advantage in Game k.
Since Game 0 is identical to the real world attack, the adversary’s advantage is by assumption. Also, d+1 = 0, since the challenge is independent of b. Consequently, for some

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

51

k ∈ [0, d], it must hold that | k − k+1| ≥ /(d + 1); ﬁx this value of k. B uses A to break (E) as follows. B receives from the challenger a public key pk.
B generates the secret and public values exactly as in Game k, except that it replaces its original value of pkk with pk. Also, if k < d, it generates a dummy key pair (skk+1, pkk+1) ←R KeyGenE (λ), sets π0 ← skk+1 and π1 ← skk+1, and requests a challenge ciphertext (under pk) encrypting either π0, π1 ∈ P . The challenger generates β ←R {0, 1} and sends a tuple of
ciphertexts ψj encrypting the bits πβj . B replaces its original tuple sk(k+1)j with the tuple ψj . One can verify that the public values are generated exactly as in Game k + β.
B sends the public values to A. Eventually, A requests a challenge ciphertext on π0 or π1. B sets b ←R {0, 1}. If k < d,
B sends the values ψj ←R EncryptE (pkd, πbj). If k = d, B generates random π ←R P and asks the challenger for a challenge ciphertext on πb or π. The challenger generates β ←R {0, 1} and encrypts πb or π accordingly, and B forwards the challenge to A. A sends a bit b . B sends bit β ← b ⊕ b to the challenger. One can verify that the challenge is generated as in
Game k + β.
Since B’s simulation has the same distribution as Game k + β, and the probability that
B outputs 0 is k+β. The result follows.

4.3 Fully Homomorphic Encryption from KDM-Secure Boot-
strappable Encryption
The length of the public key in E(d) is proportional to d (the depth of the circuits that can be evaluated). It would be preferable to have a construction E∗ where the public key size is completely independent of the circuit depth, a construction that is fully homomorphic rather than merely leveled fully homomorphic. Here is the obvious way to make the public key pk∗ of E∗ short: for E key pair (sk, pk), pk∗ includes only pk and (the “bits” of) sk encrypted under pk. In other words, we have a cycle (in fact, a self-loop in this example) of encrypted secret keys rather than an acyclic chain. It is clear that E∗ is correct: the recursive algorithm EvaluateE∗ works as before, except that the implicit recryptions generate “refreshed” ciphertexts under the same public key.
Why didn’t we present this construction in the ﬁrst place? Using an acyclic chain of encrypted secret keys allowed us to base the security of E(d) on E using a hybrid argument;

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

52

this hybrid argument breaks down when there is a cycle. In general, a semantically secure encryption scheme is not guaranteed to be KDM-secure – i.e., secure when the adversary can request the encryptions of key-dependent messages, such as the secret key itself. Typically, when we prove an encryption scheme semantically secure, there is not an obvious attack when the adversary is given the encryption of a key-dependent message. However, KDM-security is highly nontrivial to prove. The problem is precisely that the usual hybrid argument breaks down.
Remark 4.3.1. Canetti [27] proposed the acyclic, leveled approach as a way to remove the need for KDM-security. Our initial approach had actually been to use E∗ (with the self-loop), and assume, or try to prove, KDM-security.
Let us review (a restriction of) the deﬁnition of KDM-security. We will say a scheme E is KDM-secure if all polynomial-time adversaries A have negligible advantage in the following KDM-security game.
KDM-Security Game. Setup(λ, n). The challenger sets (ski, pki) ←R KeyGen(λ) for i ∈ [0, n − 1] for integer n = poly(λ). It chooses a random bit b ←R {0, 1}. If b = 0, then for i ∈ [0, n − 1] and j ∈ [1, ], it sets skij ←R EncryptE (pk(i−1) mod n, skij), where skij is the jth “bit” of ski. If b = 1, it generates the skij values as encryptions of random secret keys, unrelated to pk0, . . . , pkn−1. It sends the public keys and encrypted secret keys to A.
Challenge and Guess. Basically as in the semantic security game.
This deﬁnition of KDM-security is a restriction of the general setting [18, 68, 22], where A can select multiple functions f , and request the encryption of f (sk0, . . . , skn−1). However, when E is a bootstrappable encryption scheme, A can use the cycle of encrypted secret keys in our game to generate the encryption of f (sk0, . . . , skn−1) under any pki, as long as f can be computed in polynomial time. Hence, we only need to consider our restricted setting [65]. We have the following theorem.
Theorem 4.3.2. Suppose E is KDM-secure and also bootstrappable with respect to a universal set of gates Γ. Then, E∗, obtained from E as described above (with the self-loop), is semantically secure (and fully homomorphic).
The theorem is a straightforward consequence of the fact that, from any loop of public keys and encrypted secret keys that includes (pk0, sk0), one can compute an encryption of

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

53

sk0 under pk0. There does not seem to be any advantage in having pk∗ contain any cycle of encrypted secret keys other than a self-loop.
Absent proof of KDM-security in the plain model, one way to obtain fully homomorphic encryption from bootstrappable encryption is simply to assume that the underlying bootstrappable encryption scheme is also KDM-secure. This assumption, though unsatisfying, does not seem completely outlandish. While an encrypted secret key is very useful in a bootstrappable encryption scheme – indeed, one may view this as the essence of bootstrappability – we do not see any actual attack on a bootstrappable encryption scheme that provides a self-encrypted key.
4.4 Fully Homomorphic Encryption from Bootstrappable En-
cryption in the Random Oracle Model
Above, we constructed a fully homomorphic encryption E∗ from a bootstrappable encryption scheme E basically by adding a “self-loop” – a E secret key sk encrypted under its corresponding public key pk – to the E∗ public key pk∗. We showed that E∗ should inherit the semantic security of E, under the assumption that E is KDM-secure – in particular, under the assumption that it is “safe” to reveal a direct encryption of a secret key under its own public key (as opposed to some possibly-less-revealing non-identity function of the secret key). Can we provide any evidence that E∗ is semantically secure without this assumption?
Here we provide some evidence in the random oracle model. First, given a leveled fully homomorphic scheme E(d) and a hash function, we deﬁne an intermediate scheme E(d)†. E(d)† is the same as E(d), except for the following. The public key includes a hash function H : P → P . Also, in KeyGen, one generates r ←R P , sets rj ←R EncryptE(d)(pk(d), rj) for j ∈ [1, ], sets σ ← H(r) sk0, and includes ( rj , σ) in the public key. (Assume is some invertible operation such that a b would completely hide b ∈ P if a ∈ P were a one-time pad.) In other words, the E(d)† public key includes some additional information: an encryption of the the secret key sk0, where the encryption uses a hash function that will be treated as a random oracle in the security analysis.
Next, we prove the following theorems. Theorem 4.4.1. If E(d) is semantically secure, then E(d)† is semantically secure in the random oracle model.

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

54

Theorem 4.4.2. Suppose E is leveled circuit-private (in addition to being bootstrappable) and let E(d)† and E∗ be constructed from E as described above. Then, if E(d)† is semantically secure (in the plain model), and the circuit required to compute the hash function H and invert the operation is at most d levels, then E∗ is semantically secure.
The result here should be quite surprising. The scheme E∗ does not even contain a hash function, and yet we are basically claiming that it is secure in the random oracle model! This is the ﬁrst instance that we are aware of where one scheme is proven secure in the random oracle model, and then a second scheme’s security is based on the ﬁrst scheme, even though the second scheme does not use a hash function.
How is this possible? First, let us consider Theorem 4.4.1. This theorem basically just states the previously known result [18] that it is easy to construct a KDM-secure encryption scheme in the random oracle model. This is because the random oracle allows the reduction to construct a “fake” ciphertext purportedly encrypting the secret key, such that the adversary ﬁnds out that it was fake only after it has queried the random oracle; this query gives the reduction all of the information that it needs to solve the underlying problem. In our particular case, E(d)† has a loop among (sk0, pk0), . . . , (skd, pkd), because E(d) reveals direct encryptions of ski under pki−1 for i ∈ [1, d], and E(d)† also reveals an indirect encryption ( rj , σ) of sk0 under pkd (“indirect,” because encryption in E does not normally use a hash function). However, the reduction algorithm in the proof of Theorem 4.4.1 will construct σ simply as a random string – i.e., it does not actually need to know anything about sk0.
Theorem 4.4.2 is perhaps the more surprising result. But the result is actually a simple consequence of the fact that: given a correctly constructed E(d)† public key, the reduction algorithm can generate an E-encryption of sk0 under pk0, as needed for the E∗ public key. How do we generate the latter ciphertext? The reduction algorithm is given rj , an encryption of r under pkd. It simply uses the leveled homomorphism and the circuit corresponding to the hash function H to compute a ciphertext that encrypts H(r) from the ciphertext that encrypts r. Then, given that ciphertext and the value of σ = H(r) sk0, it computes a ciphertext that encrypts sk0 in the natural way – i.e., directly, rather than with the hash function. We assumed that the hash function H and the operation can be computed with a circuit of depth at most d; therefore, our leveled homomorphic scheme E(d) has enough levels to evaluate this circuit. Consequently, we obtain a “natural” encryption of sk0 (i.e., under E) under some public key pki for i ≥ 0, and we can use Recrypt operations

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

55

to obtain a natural encryption of sk0 under pk0. This ciphertext is an output of EvaluateE , but circuit privacy guarantees that the ciphertext is distributed as if it were output directly by EncryptE .
Remark 4.4.3. Although one can view ( rj , σ) as an “encryption” of sk0, this “encryption” function is not the usual encryption function and it might have a very complex decryption circuit, much more complex than DE . In particular, we cannot assume that its decryption circuit is in CE . This why we needed many (d) levels in the leveled scheme to recover sk0, and could not immediately use a self-loop from the outset.
So, if E∗ is secure in the random oracle model despite not using a hash function, does that imply that it is secure in the plain model? Certainly not. The obstacle to this conclusion is obviously that random oracles cannot be instantiated in general [28]. A bit more speciﬁcally, however, the obstacle is that the proof of Theorem 4.4.2 depends crucially on the correctness of the ciphertext ( rj , σ) in E(d)† to construct (homomorphically) an encryption of sk0 under pk0 as needed for the E∗ public key; however, in the proof of Theorem 4.4.1 the ciphertext is not correct (except with negligible probability): the adversary ﬁnds out that it was fake only after it has queried r to the random oracle, giving the reduction all the information it needs.
Proof. (Theorem 4.4.1) Let A be an algorithm that attacks the semantic security of E(d)†; from A, we construct an algorithm B that attacks the semantic security of E(d). B will actually request + 1 challenge ciphertexts; thus, the reduction loses a factor of + 1 under the usual hybrid argument.
The challenger gives B a E(d) public key. It also sets a bit b ←R {0, 1}. B selects two messages r(0), r(1) ∈ P and sends them to the challenger. The challenger sets Ψ ←R {Encrypt(pkd, rj(b)) : j ∈ [1, ]} and sends back Ψ. The following is included in the public key that B sends to A: the public key for E(d) sent by the challenger, the set of ciphertexts Ψ, and σ ←R P .
A requests a challenge ciphertext on one π0, π1 ∈ P. B forwards the query to the challenger, who responds with a ciphertext encrypting πb, which B forwards to A.
Eventually, either A queries some r ∈ {r(0), r(1)} to the random oracle, or A ﬁnishes with a guess b . In the former case, B sets b so that r = r(b ). In either case, B sends b as its guess to the challenger.

CHAPTER 4. BOOTSTRAPPABLE ENCRYPTION

56

Let p be the probability that A queries some r ∈ {r(0), r(1)} to the random oracle. B’s simulation appears perfect to A if it does not query some r ∈ {r(0), r(1)}; in this case, which occurs with probability 1 − p, A’s advantage is at least . Since A’s view is independent of r(1−b), the probability that it queries r(b) to the random oracle is at least p − qH /|P| , where qH is the number of random oracle queries make by A. Overall B’s advantage in guessing b is at least (1 − p) + p − qH /|P| ≥ − qH /|P| .

Proof. (Theorem 4.4.2) The proof is essentially a simple consequence of the fact that, given a public key for E(d)†, it is easy to generate the public key for E∗ homomorphically.
Let A be an algorithm that breaks the semantic security of E∗. We use A to construct an algorithm B that breaks the semantic security of E(d)†.
B receives a E(d)† public key from the challenger. This public key consists of pki i∈[0,δ], skij i∈[1,δ], rj j∈[1, ], and σ = H(r) sk0. From rj , B uses the homomorphism of E(d) to compute ciphertexts Ψ that encrypt H(r). It encrypts σ, and then uses the homomorphism
to recover to obtain an encryption of sk0 from the encryptions of H(r) and σ (inverting the operation). By assumption, these homomorphic operations take at most d levels. If
it takes only δ < d levels, and we obtain an encryption of sk0 under pkd−δ, then we can perform Recrypt operations until we have the desired encryption of sk0 under pk0. By circuit privacy, this ciphertext is distributed properly. B includes the encryption of sk0 under pk0 as the encrypted secret key contained in the public key for E∗ that it provides to A.
A requests a challenge ciphertext on one π0, π1 ∈ P. B forwards the query to the challenger, who responds with a ciphertext encrypting πb. B uses Recrypt operations to obtain an encryption of πb under pk0 and forwards the result to A. A sends a guess b , which B forwards to the challenger.
Clearly, B’s advantage is the same as A’s.

Chapter 5
An Abstract Scheme Based on the
Ideal Coset Problem
Our goal now is to construct a bootstrappable encryption scheme, a scheme that can homomorphically evaluate a rich set of circuits that includes its own decryption circuit, “plus some.” In the past, attempts to construct fully homomorphic encryption have focused solely on maximizing the complexity of the circuits that the scheme can evaluate. Our notion of bootstrapability gives us a diﬀerent way of attacking the problem – by minimizing the complexity of the scheme’s decryption circuit.
Our strategy for minimizing the circuit complexity of decryption is to construct our scheme using ideal lattices, since decryption in lattice-based cryptosystems is typically dominated by a simple operation, such as an easily parallelizable matrix-vector multiplication (in contrast to, say, RSA, where decryption involves exponentiation, an operation not even known to be in NC). We begin describing the ideal-lattice-based scheme in Chapter 7, after providing some basic background on ideal lattices in Chapter 6.
In this Chapter, we describe our strategy for maximizing the “evaluative capacity” of the scheme abstractly, without reference to lattices. Generally speaking, our exposition strategy throughout the paper is to defer technical lattice details for as long as possible. One reason is to make the presentation more modular, and therefore easier to understand. Another reason is that some of our techniques – e.g., bootstrapping, and using techniques from server-aided cryptography to “squash the decryption circuit” – maybe applicable to schemes that use diﬀerent underlying mathematics – e.g., linear codes, or something less similar to lattices.
57

CHAPTER 5. AN ABSTRACT SCHEME BASED ON THE IDEAL COSET PROBLEM58
5.1 The Ideal Coset Problem
We saw in Chapter 3 that many previous homomorphic encryption schemes base security on some ideal membership problem (IMP). For example, in the “Polly Cracker” scheme by Fellows and Koblitz [44], the public key consists of some multivariate polynomials that generate the ideal I of polynomials having a common root x, and π is encrypted by outputting a sample ψ ←R π + I. One can easily see that this is semantically secure if it is hard to distinguish membership in I – in particular, deciding whether ψ −π ∈ I. Unfortunately, one can also see that homomorphic operations, especially multiplication, expand the ciphertext size potentially exponentially in the depth.
Since we will ultimately use lattices, we apparently need a diﬀerent abstract approach, since it is easy to distinguish membership in a lattice L: given a basis B of L and t ∈ Rn, one simply determines whether t mod B = 0 mod B. Instead, we base security on an ideal coset problem (ICP), which we will state abstractly in terms of rings and ideals. Recall that a ring R is an algebraic object that is closed under addition ‘+’ and multiplication ‘×’ and additive inverse, with an additive identity ‘0’ and multiplicative identity ‘1’. An ideal I of a ring R is a subset satisfying a + b ∈ I and r × a ∈ I for all a, b ∈ I and r ∈ R. The sum and product of two ideals I and J are, respectively, {i + j : i ∈ I, j ∈ J} and the additive closure of {i × j : i ∈ I, j ∈ J}. Two ideals I and J are relatively prime if I + J = R. For example, if R = Z, the ideals (2) (the even integers) and (5) (the integers divisible by 5) are relatively prime: (2) + (5) = (1).
Now, the ideal coset problem (ICP) is as follows.
Deﬁnition 5.1.1 (Ideal Coset Problem (ICP)). Fix R, BI , algorithm IdealGen, and an algorithm Samp1 that eﬃciently samples R. The challenger sets b ←R {0, 1} and (BsJk, BpJk) ←R IdealGen(R, BI ). If b = 0, it sets r ←R Samp1(R) and t ← r mod BpJk. If b = 1, it samples t uniformly from R mod BpJk. The problem: guess b given (t, BpJk).
Basically the ICP asks one to decide whether t is uniform modulo J, or whether it was chosen according to a known “clumpier” distribution induced by Samp1. Of course, the ICP will be impossible if Samp1 also samples uniformly modulo J, but the security of our encryption scheme will rely on the ICP being hard for a “clumpier” instantiation of Samp1; the hardness of the problem depends on the particular instantiation of Samp1. Note that it is possible for the ICP to be hard even when the IMP is easy.

CHAPTER 5. AN ABSTRACT SCHEME BASED ON THE IDEAL COSET PROBLEM59
5.2 An Abstract Scheme
We start by describing our initial attempt simply in terms of rings and ideals; we bring in ideal lattices later. In our initial scheme E, we use a ﬁxed ring R that is set appropriately according to a security parameter λ. We also use a ﬁxed basis BI of a ideal I ⊂ R, and an algorithm IdealGen(R, BI ) that outputs public and secret bases BpJk and BsJk of some (variable) ideal J, such that I + J = R – i.e., I and J are relatively prime. We assume that if t ∈ R and BM is a basis for ideal M ⊂ R, then the value t mod BM is unique and can be computed eﬃciently – i.e., the coset t + M has a unique, eﬃciently-computable “distinguished representative” with respect to the basis BM . We use the notation R mod BM to denote the set of distinguished representatives of r + M over r ∈ R, with respect to the particular basis BM of M . We also use an algorithm Samp(BI , x) that samples from the coset x + I.
In the scheme, Evaluate takes as input a circuit C whose gates perform operations modulo BI . For example, an AddBI gate in C takes two terms in R mod BI , and outputs a third term in R mod BI , which equals the sum of the ﬁrst two terms modulo I. KeyGen(R, BI ). Takes as input a ring R and basis BI of I. It sets (BsJk, BpJk) ←R IdealGen(R, BI ). The plaintext space P is (a subset of) R mod BI . The public key pk includes R, BI , BpJk, and Samp. The secret key sk also includes BsJk. Encrypt(pk, π). Takes as input the public key pk and plaintext π ∈ P. It sets ψ ← Samp(BI , π) and outputs ψ ← ψ mod BpJk. Decrypt(sk, ψ). Takes as input the secret key sk and a ciphertext ψ. It outputs
π ← (ψ mod BsJk) mod BI
Evaluate(pk, C, Ψ). Takes as input the public key pk, a circuit C in some permitted set CE of circuits composed of AddBI and MultBI gates and a set of input ciphertexts Ψ. It invokes Add and Mult, given below, in the proper sequence to compute the output ciphertext ψ. (We will describe CE when we consider correctness below. If desired, one could use diﬀerent arithmetic gates.) Add(pk, ψ1, ψ2). Outputs ψ1 + ψ2 mod BpJk. Mult(pk, ψ1, ψ2). Outputs ψ1 × ψ2 mod BpJk.

CHAPTER 5. AN ABSTRACT SCHEME BASED ON THE IDEAL COSET PROBLEM60
Remark 5.2.1. Concerning IdealGen, it is ﬁne if the secret basis BsJk deﬁnes a lattice L(BsJk) for a (possibly fractional) ideal that contains J, rather than being exactly J.
Now, let us consider correctness, which is a highly nontrivial issue in this paper. The following deﬁnitions provide structure for our analysis.
To begin, we observe that the scheme is actually using two diﬀerent circuits. First, Evaluate takes a mod-BI circuit C as input. This circuit is implicitly applied to plaintexts. Second, Evaluate applies a circuit related to C, which we call the generalized circuit, to the ciphertexts; this circuit uses the ring operations (not modulo I).
Deﬁnition 5.2.2 (Generalized Circuit). Let C be a mod-BI circuit. We say generalized circuit g(C) of C is the circuit formed by replacing C’s AddBI and MultBI operations with addition ‘+’ and multiplication ‘×’ in the ring R.
Here are a few more deﬁnitions relevant to Theorem 5.2.6 below, which concerns correctness.
Deﬁnition 5.2.3 (XEnc and XDec). Let XEnc be the image of Samp. Notice that all ciphertexts output by Encrypt are in XEnc +J. Let XDec equal R mod BsJk, the set of distinguished representatives of cosets of J wrt the secret basis BsJk. Deﬁnition 5.2.4 (Permitted Circuits). Let
CE = {C : ∀(x1, . . . , xt) ∈ XEnct, g(C)(x1, . . . , xt) ∈ XDec}
In other words, CE is the set of mod-BI circuits that, when generalized, the output is always in XDec if the inputs are in XEnc. (The value t will of course depend on C.) If CE ⊆ CE , we say that CE is a set of permitted circuits.
Deﬁnition 5.2.5 (Valid Ciphertext). ψ is a valid ciphertext wrt E public key pk and permitted circuits CE if it equals Evaluate(pk, C, Ψ) for some C ∈ CE , where each ψ ∈ Ψ is in the image of Encrypt. The circuit C may be the identity circuit, in which case the output of Evaluate is simply an output of Encrypt.
Finally, we prove correctness with respect to CE .
Theorem 5.2.6. Assume CE is a set of permitted circuits containing the identity circuit. E is correct for CE – i.e., Decrypt correctly decrypts valid ciphertexts.

CHAPTER 5. AN ABSTRACT SCHEME BASED ON THE IDEAL COSET PROBLEM61
Proof. For ciphertexts Ψ = {ψ1, . . . , ψt}, ψk = πk + ik + jk, where πk ∈ P, ik ∈ I, jk ∈ J, and πk + ik ∈ XEnc, we have
Evaluate(pk, C, Ψ) = g(C)(Ψ) mod BpJk ∈ g(C)(π1 + i1, . . . , πt + it) + J
If C ∈ CE , we have g(C)(XEnc, . . . , XEnc) ∈ XDec and therefore
Decrypt(sk, Evaluate(pk, C, Ψ)) = g(C)(π1 + i1, . . . , πt + it) mod BI = g(C)(π1, . . . , πt) mod BI = C(π1, . . . , πt)
as required.
The bottom line is that we have proven that E is correct for permitted circuits, and our goal now is to maximize this set. The permitted circuits are deﬁned somewhat indirectly; they are the circuits for which the “error” g(C)(x1, . . . , xt) of the output ciphertext is small (i.e., lies inside XDec) when the input ciphertexts are in the image of EncryptE . When we begin to instantiate the abstract scheme with lattices and give geometric interpretations of XEnc and XDec, the problem of maximizing CE will have a geometric ﬂavor.
Again, we note the rather confusing fact that C “automatically” reduces the result modulo BI , since it uses mod-BI gates. It does not particularly matter how these mod-BI gates are implemented; in particular, it is more confusing than helpful to imagine a boolean implementation of these gates. Instead, one should just observe that the generalized circuit manages to lazily emulate these gates, reducing its output modulo BI at the end of the computation. C’s mod-BI operations are never actually “implemented;” they only occur implicitly. Later, when we consider whether our scheme is bootstrappable, and analyze the depth of the decryption circuit in terms of mod-BI gates, it will again be tempting to consider how these gates are “implemented.” But in fact these gates are “given” in the sense that they are emulated (without any intermediate reduction steps) by the usual ring operations.

CHAPTER 5. AN ABSTRACT SCHEME BASED ON THE IDEAL COSET PROBLEM62
5.3 Security of the Abstract Scheme
For the following abstract “instantiation” of Samp, and where I is a principle ideal generated by some s ∈ R (and s is encoded in BI ), we provide a simple proof of semantic security based on the ICP. Samp(BI , x). Run r ←R Samp1(R). Output x + r × s.
Obviously, the output is in x + I since s ∈ I.
Theorem 5.3.1. Suppose that there is an algorithm A that breaks the semantic security of E with advantage when it uses Samp. Then, there is an algorithm B, running in about the same time as A, that solves the ICP with advantage /2.
Proof. The challenger sends B a ICP instance (t, BpJk). B sets s, and sets the other components of pk in the obvious way using the ICP instance. When A requests a challenge ciphertext on one of π0, π1 ∈ P, B sets a bit β ←R {0, 1} and sends back ψ ← πβ + t × s mod BpJk. A sends back a guess β , and B guesses b ← β ⊕ β .
If b = 0, we claim that B’s simulation is perfect; in particular, the challenge ciphertext has the correct distribution. When b = 0, we have that t = r + j, where r was chosen according to Samp1 and j ∈ J. So, ψ ← πβ + t × s = πβ + r × s mod BpJk; the ciphertext is thus well-formed. In this case A should have advantage , which translates into an advantage of for B.
If b = 1, then t is uniformly random modulo J. Since the ideal I = (s) is relatively prime to J, t × s is uniformly random modulo J, and consequently ψ is a uniformly random element of R mod BpJk that is independent of β. In this case A’s advantage is 0. Overall, B’s advantage is /2.

Chapter 6
Background on Ideal Lattices I: The Basics
From the abstract construction in Chapter 5, among the objects that we need to make concrete are: the ring R, the ideals I and J, how to compute t mod BM , the algorithms Samp and IdealGen, and a concrete version of the ICP. In this Chapter, we provide some basic background material needed to instantiate these things while using ideal lattices. Later, we will provide more background on ideal lattices as needed.
6.1 Basic Background on Lattices
Let R denote the real numbers, and Z the integers. We write vectors in column form using bold lower-case letters, e.g. v; We write matrices as bold capital letters, e.g., B; bi is the ith column. We use v to denote the Euclidean length of a vector v. For matrix B, we use B to denote the length of the longest column vector in B.
An n-dimensional lattice of rank k ≤ n is
L = L(B) = Bc : c ∈ Zk , B ∈ Rn×k
where the k columns b1, . . . , bk ∈ Rn of the basis are linearly independent. All lattices in this paper are full rank – i.e., k = n. Usually lattices in this paper are sub-lattices of Zn – i.e., the lattice vectors have integer coeﬃcients.
Every lattice has an inﬁnite number of lattice bases. If B1 and B2 are two lattice
63

CHAPTER 6. BACKGROUND ON IDEAL LATTICES I: THE BASICS

64

bases of L, then there is some matrix U that is unimodular (i.e., U has integer entries and

det(U) = ±1) satisfying B1 · U = B2. Since U is unimodular, | det(Bi)| is invariant for diﬀerent bases of L. Since it is invariant, we may refer to det(L). This value is precisely

the size of the quotient group Zn/L if L is an integer lattice.

To basis B of lattice L we associate the half-open parallelepiped P(B) ← {

n i=1

xibi

:

xi ∈ [−1/2, 1/2)}. The volume of P(B) is precisely det(L).

Informally, we say that some bases of L are “good” and some are “bad;” a basis B of L

is “good,” roughly speaking, if the vectors of B are reasonably short and nearly orthogonal.

Of course, for any basis B = {b1, . . . , bn}, it must hold that

n i=1

bi

≥ det(L); roughly

speaking, good bases come closer to reaching equality than bad ones.

For t ∈ Rn, we use t mod B to denote the unique vector t ∈ P(B) such that t − t ∈ L.

Given t and B, t mod B can be computed eﬃciently as t − B · B−1 · t , where · rounds

the coeﬃcients of a vector to the nearest integer. Let dist(L, t) denote minv∈L{ t − v }. Clearly, for any basis B, t mod B ≥ dist(L, t), though again (roughly speaking) “good”

bases come closer to equality.

In some sense, the worst basis of a lattice L is its unique upper-triangular Hermite

normal form HNF(L). Given any basis B of L, one can compute HNF(L) eﬃciently – i.e.,

in time poly(n, log B ). Thus, HNF(L) does not “reveal” more about L’s structure than

any other basis, making HNF(L) a good choice for the public lattice basis to be included

in a public key [97].

The dual lattice of L, denoted L∗, is deﬁned as L∗ = {x ∈ span(L) : ∀v ∈ L, x, v ∈ Z}.

It holds that det(L) · det(L∗) = 1. If B is a basis for the full-rank lattice L, then (B−1)T

(the inverse transpose of B) is a basis of L∗.

The ith successive minimum λi(L) is the smallest radius r such that L contains at least i linearly independent vectors of norm at most r. In particular λ1(L) is the length of the shortest nonzero vector in L. A very good basis may have some of these very short vectors.

The two most well-known lattices problems are the shortest vector problem (SVP) and

closest vector problem (CVP). Here are their approximate versions.

Deﬁnition 6.1.1 (γ(n)-Shortest Vector Problem (SVP)). Given a basis for a lattice L of dimension n, output a nonzero vector v ∈ L of length at most γ(n) · λ1(L).
Deﬁnition 6.1.2 (γ(n)-Closest Vector Problem (CVP)). Given a basis for a lattice L of dimension n and a vector t ∈ Rn, output a nonzero vector v ∈ L such that t − v ≤ γ(n) · dist(L, t).

CHAPTER 6. BACKGROUND ON IDEAL LATTICES I: THE BASICS

65

A close variant of the SVP is the shortest independent vector problem (SIVP), deﬁned as follows.
Deﬁnition 6.1.3 (γ(n)-Shortest Independent Vector Problem (SIVP)). Like the SVP, except one outputs linearly independent v1, . . . , vn ∈ L, all of length at most γ(n) · λn(L).
In a variant of the CVP, one is given the promise that the closest L-vector to t is much closer than any other – e.g., by a factor of γ(n).
Deﬁnition 6.1.4 (γ(n)-Bounded Distance Decoding Problem (BDDP)). Same as γ(n)CVP, but with the promise that there is a unique solution – i.e., (γ(n)+1)·dist(L, t) < λ1(L).
In other words, the BDDP is the CVP under the promise that t is very close to the lattice L, and that in fact the solution v is unique. The solution is unique, since if t − v < λ1(L)/(γ(n)+1), then t−w ≥ v−w − t−v > λ1(L)·γ(n)/(γ(n)+1) > γ(n)·dist(L, t) for all w ∈ L \ {v}. This deﬁnition of the BDDP is non-standard, in the sense that in γ(n)BDDP, γ(n) is typically deﬁned to be an upper bound on the ratio dist(L, t)/λ1(L), whereas we prefer (essentially) to deﬁne it to be a lower-bound on λ1(L)/dist(L, t), since (in our formulation) the problem becomes easier as γ(n) becomes larger (as in γ(n)-SVP, γ(n)-CVP, and γ(n)-SIVP).
Aside from BDDP, the above problems are known to be NP-hard for very small approximation factors. For all of these problems, the best polynomial-time approximation algorithms are variants of the lattice reduction algorithm LLL by Lenstra et al. [81] or Babai’s nearest plane algorithm [13]; these algorithms only work for essentially-exponential (e.g., 2O(n(log log n)/ log n) [5]) approximation factors. As a rough rule of thumb, approximating these lattice problems to within a factor of 2k takes time about 2n/k, using known algorithms [123].
6.2 Basic Background on Ideal Lattices
To our knowledge, the ﬁrst use of ideal lattices in cryptography was the NTRU cryptosystem by Hoﬀstein et al. [69],1 though the connection to lattices was made explicit later in cryptanalysis [34, 93, 47]. None of this cryptanalysis has broken the core average-case problem underlying the scheme. NTRU’s main selling point is eﬃciency; encryption and
1Strictly speaking, NTRU’s lattice has a 2n × 2n basis, where each n × n quadrant generates an ideal lattice.

CHAPTER 6. BACKGROUND ON IDEAL LATTICES I: THE BASICS

66

decryption very fast – much faster than RSA, for example – since the operations involved are simple (multiplications in the ring Zq[x]/(xn − 1) for small integer q), and since n can be reasonably small (several hundreds) since the best known lattice attacks on NTRU take time essentially exponential in n.
Recent cryptography involving ideal lattices [98, 111, 112, 88, 99] is typically framed immediately with reference to Ajtai’s worst-case / average-case connection. In these works, they have been used to construct, for example, hash functions and signature schemes.
Our construction will use the polynomial ring R = Z[x]/(f (x)), where f (x) is a monic polynomial of degree n. We view an element v ∈ R both as a ring element and as a vector – speciﬁcally, the coeﬃcient vector v ∈ Zn. The ideal (v) generated by v directly corresponds to the lattice generated by the column vectors {vi ← v × xi mod f (x) : i ∈ [0, n − 1]}; we call this the rotation basis of the ideal lattice (v). Speciﬁcally, any w ∈ (v) is in the lattice generated by the rotation basis {vi}, since there must be some a for which w = v × a, and then w = i aivi. Conversely, if w is in the lattice generated by {vi}, then w = i aivi for some integers {ai}, which implies that w = v × a in the ring R, where a = i ai · xi. In general, the rotation basis for the product of two elements a, b ∈ Q[x]/(f (x)) is the rotation basis of a × b. Also the matrix-vector product of a rotation basis a with the vector b is the vector a × b.
Generally speaking, an ideal I ⊂ R need not be principal – i.e., have a single generator – and a basis BI of I need not be a rotation basis. Suppose it is generated by v and w. In this case, the ideal is represented by the lattice generated by the columns {v0, . . . , vn−1, w0, . . . , wn−1}, where wi is the vector associated to w × xi. Of course, the vectors in this set will be linearly dependent. A lattice reduction algorithm, such as LLL, will ﬁnd these dependencies and output a basis for the lattice associated to I that contains only linearly independent vectors.
Sometimes we will use inverses in the ring Q[x]/(f (x)). In this case, to avoid complications, we assume f (x) is irreducible and therefore all nonzero terms have inverses. If I is an ideal in R, I−1 is a fractional ideal. I−1 is deﬁned in a somewhat similar way as a dual lattice; it is the set {x ∈ Q[x]/(f (x)) : ∀y ∈ I, x × y ∈ R}. Aside from the fact that I−1 is not necessarily a subset of R, it is exactly like a normal ideal – in particular, it is closed under addition and under multiplication with R-elements. We say that (possibly fractional) ideals I and J are relatively prime if I + J ⊇ R. For example, ideal (2/5) and (3/7) are relatively prime (contain (1)), but (3/5) and (3/7) are not, since (1) is not in (3/35).

CHAPTER 6. BACKGROUND ON IDEAL LATTICES I: THE BASICS

67

For principal ideal (v), the fractional ideal (v)−1 is generated by 1/v, where the inverse is in Q[x]/(f (x)). The determinant associated to the ideal lattice for (v) (we may occasionally refer to this determinant as the norm of the ideal, denoted Nm(I)) is the inverse of the determinant of (1/v). For an ideal I that has multiple generators v1, v2, . . ., the fractional ideal I−1 is the intersection of (1/v1), (1/v2), . . ..
In our constructions, we will use a polynomial ring as deﬁned above. Such rings are called monogenic number rings, or simple algebraic extensions, because they are isomorphic to Z[α] where α is a root of f (x). Algorithmically, such rings are easy to work with, which will be important later for minimizing the complexity of our decryption circuit.
Algebraically, however, a more natural ring would be the ring of integers associated to a number ﬁeld. A number ﬁeld is a ﬁnite extension K = Q(α) of the rationals Q, isomorphic to Q[x]/(f (x)) for some polynomial f (x) irreducible over Q for which f (α) = 0. The ring of integers of a number ﬁeld K is:
OK = {x ∈ K : fQx ∈ Z[x]} , where fQx is the (monic) minimal polynomial of x in Q[x]
While it may not be immediately obvious that OK is even a ring, OQ(α) generally has better algebraic properties than Z[α], most notably that every ideal I of the ring of integers factors uniquely as a product of prime ideals in the ring. Also, all ideals I of OK are “invertible” – i.e., I−1 · I = OK when the inverse I−1 is taken in OK; this is not necessary true in Z[α], where I−1 · I may be a subset of R if Nm(I) is divisible by one of a small number of singular primes whose squares divide the discriminant ∆(f ) of f (x) [127]. Peikert and Rosen [112] show that ideal lattices associated to the ring of integers in ﬁelds with very small root discriminant have very small worst-case / average-case connection factors, only logarithmic (versus polynomial) in n. While their approach is appealing, and most likely can be used in connection with our scheme, we choose instead to use Z[α] because using integer vectors permits us to push complicated details away from the decryption circuit, which is already quite complicated. Also, it is straightforward, though tedious, to simply avoid the singular primes when working with Z[α].
Since all of the hardness assumptions are with respect to a ﬁxed ring R, one must choose it wisely. For example, a seemingly attractive choice for R is the ring Z[x]/(xn − 1). Aside from eﬃciency, this choice in some sense maximizes the multiplicative depth of circuits that our scheme can evaluate, since one can bound the Euclidean length u×v by γMult(R)· u ·

CHAPTER 6. BACKGROUND ON IDEAL LATTICES I: THE BASICS

68

v for γMult(R) = √n; other rings have larger values of γMult(R). We note that the NTRU encryption scheme, whose core hard problem has never been broken, uses this ring (though it uses a lattice basis that consists of 4 quadrants, where each quadrant is a basis of an ideal lattice in R). On the other hand, although there is no known attack against ideal lattice problems in this ring that is completely fatal, there are some attacks that suggest that this ring may be weaker than others. One fairly obvious attack by Gentry [47] works when n is composite; essentially, it reduces a lattice problem over Z[x]/(xcm − 1) to a much more tractable m-dimensional lattice problem over Z[x]/(xm − 1) for small constant c. Generally, one would prefer f (x) to be irreducible. Even when n is prime, Gentry and Szydlo [50] gave an algorithm that can be adapted to take an n-dimensional basis of a principal ideal lattice I of R = Z[x]/(xn − 1), and construct a (n + 1)/2-dimensional lattice basis that contains
√ at least one nonzero I-vector of length at most 2 · λ1(I); if I has an orthonormal basis, their algorithm can ﬁnd it in polynomial time. But again we mention that these attacks are not fatal for Z[x]/(xn − 1). If one simply takes n prime and (easily) avoids ideals with orthonormal bases, the Gentry-Szydlo attack only gives an attack whose running time is at best square root of the original time of attack, which is ﬁne (in principle) if the original time of attack is super-polynomial.

6.3 Probability Background

A family H of hash functions from X to Y , both ﬁnite sets, is said to be 2-universal if

Prh←R H[h(x) = h(x )] = 1/|Y | for all distinct x, x ∈ X. A distribution D is -uniform if its statistical distance from the uniform distribution is at most , where the statistical

diﬀerence

between

two

distributions

D1, D2

is

1 2

x∈X |D1(x) − D2(x)|.

Lemma 6.3.1 (Leftover Hash Lemma [72]). Let H be a family of 2-universal hash functions

from X to Y . Suppose that h ←R H and x ←R X are chosen uniformly and independently.

Then,

(h, h(x))

is

1 2

|Y |/|X|-uniform over H × Y .

Chapter 7
A Somewhat Homomorphic Encryption Scheme
7.1 Why Lattices?
To bootstrap our new notion of bootstrappability, we ask a natural question: where do we ﬁnd encryption schemes that have decryption algorithms with low circuit complexity?
We note that this is not an essential question. Conceivably, E could be tailored so that it evaluates only its (augmented) decryption circuits DE (Γ), or very few gates outside of this small set, even though its decryption circuit is “complex” [58]. However, our approach will be to look for a scheme that evaluates circuits at least as complex as (e.g., in terms of depth) its (augmented) decryption circuit.
Under this approach, it does not make much sense to look at schemes based on factoring or variants of Diﬃe-Hellman, even though there are several homomorphic schemes here – RSA [121], Goldwasser-Micali [61], ElGamal [42], Paillier [110], Boneh-Goh-Nissim [21], etc. In all of these schemes, decryption uses some operation – exponentiation, Legendre symbol computation, pairing – that is not even known to have circuit complexity in NC. For these schemes, we can reduce the depth of the decryption circuit somewhat by using techniques like those described in Section 10, where we oﬄoad some decryption work onto the encrypter, who outputs a longer ciphertext that can be decrypted by a shallower circuit, but we do not see how to reduce the decryption depth enough to make these schemes bootstrappable.
On the other hand, for encryption schemes based on lattices or linear codes, the dominant decryption operation is typically an inner product or matrix-vector multiplication, which is
69

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

70

in NC1 (assuming the bit-length of the coeﬃcients are polynomial in the vector dimension).
7.2 Why Ideal Lattices?
To be bootstrappable, it is not enough that the scheme has a decryption circuit of low complexity; the scheme needs to be able to evaluate that circuit. We already have schemes that can evaluate circuits in NC1. In fact, unless one wants circuit privacy (as in SandersYoung-Yung [122]), “evaluating” circuits of logarithmic depth is completely trivial: one simply outputs the circuit and the “unprocessed” input ciphertexts. So, why is it not trivial to construct a bootstrappable encryption scheme from a lattice-based scheme that has a decryption circuit in NC1?
The problem with the trivial construction, and with SYY, is that they achieve logarithmic depth by permitting the ciphertext size to grow exponentially with the circuit depth. As the ciphertext grows, the decryption circuit must also grow to handle the larger ciphertexts. In short, as one allows larger and larger ciphertexts, the evaluation depth will never “catch up” to the depth of the decryption circuit. To obtain a bootstrappable encryption scheme, it seems necessary to consider encryption schemes that have more complex inherent homomorphisms.
As we will see, while general lattices oﬀer an additive structure, ideal lattices also have a multiplicative structure that will enable us to evaluate deep arithmetic circuits (though we will need more tricks before we ultimately obtain a bootstrappable scheme).
7.3 A Geometric Approach to Maximizing the Circuit Depth that Can Be Evaluated
In Section 5, where we described the abstract scheme, we saw that E correctly evaluates circuit C if the generalized circuit g(C) satisﬁes g(C)(x1, . . . , xt) ∈ XDec for all (x1, . . . , xt) ∈ XEnct. For example, it correctly evaluates the gate AddBI if XEnc + XEnc ⊆ XDec, and the gate MultBI if XEnc × XEnc ⊆ XDec. Our hope is that applying these gates – indeed, even applying high-depth circuits – does not cause to much “expansion,” so that the output of the generalized circuit remains within XDec.
An important reason that we use ideal lattices, versus ideals over general rings, is that lattices permit a clean analysis of XEnc and XDec in terms of Euclidean length. When we

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

71

implement the abstract scheme using a polynomial ring Z[x]/(f (x)) and ideal lattices as summarized above, the sets XEnc and XDec become subsets of Zn. We re-characterize these sets geometrically as follows.
Deﬁnition 7.3.1 (rEnc and rDec). Let rEnc be the smallest value such that XEnc ⊆ B(rEnc), where B(r) is the ball of radius r. Let rDec be the largest such that XDec ⊇ B(rDec).
Now, let us deﬁne a set of permitted circuits CE as follows:
CE = {C : ∀(x1, . . . , xt) ∈ B(rEnc)t, g(C)(x1, . . . , xt) ∈ B(rDec)}
CE is deﬁned like the maximal set CE of permitted circuits in Deﬁnition 5.2.4, but we have replaced XEnc and XDec with B(rEnc) and B(rDec). Clearly, CE ⊆ CE . (At several points later in the paper, we narrow our set of permitted circuits again so as to enable a less complex decryption algorithm.)
For ﬁxed values of rEnc and rDec, what is CE ? This is a geometric problem, and we can bound the Euclidean length g(C)(x1, . . . , xt) by bounding the lengths of u + v and u × v in terms of u and v . For addition, this is easy: using the triangle inequality, we have u + v ≤ u + v for u, v ∈ R. For multiplication, we can prove that u × v ≤ γMult(R) · u · v , where γMult(R) is some factor that is dependent only on the ring R. (See [89] for a diﬀerent deﬁnition of the expansion factor for multiplication.)
The following theorem characterizes the “error expansion” that a circuit can cause based on the circuit’s depth.
Theorem 7.3.2. Suppose rE ≥ 1 and that circuit C’s additive fan-in is γMult(R), multiplicative fan-in is 2, and depth is at most
log log rD − log log(γMult(R) · rE)
Then, C(x1, . . . , xt) ∈ B(rD) for all x1, . . . , xt ∈ B(rE).
In particular, E correctly evaluates circuits of depth up to log log rDec−log log(γMult(R)·rEnc).
Proof. For a d-depth circuit, let ri be an upper-bound on the Euclidean norm of the values at level i, given that rd = rE. By the triangle inequality, an addition (or subtraction) gate at level i outputs some v ∈ R such that v ≤ γMult(R) · ri. A multiplication gate at level i

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

72

outputs some v ∈ R such that v ≤ γMult(R) · ri2. In either case, ri−1 ≤ γMult(R) · ri2, and thus r0 ≤ (γMult(R) · rE)2d. The result follows.
An (oversimpliﬁed) bottom line from Theorem 7.3.2 is that, to maximize the depth of circuits that E can correctly evaluate (see Theorem 5.2.6), we should minimize γMult(R) and rEnc, and maximize rDec. Most of the remainder of this section consists of proposals toward this goal.
7.4 Instantiating the Ring: The Geometry of Polynomial Rings
From Theorem 7.3.2, it seems important to set f (x) so that R = Z[x]/(f (x)) has a reasonably small value of γMult(R). (Recall that γMult(R) is a value such that u × v ≤ γMult(R) · u × v .) The following results show that there are many f (x) for which the associated γMult(R) is only polynomial in n. Lyubashevsky and Micciancio [89] actually already have results of a similar ﬂavor to those in this Section in a full version of a paper using ideal lattices for hash functions [89], for a deﬁnition of “expansion factor” (analogous to our γMult(R)) that is a bit more cumbersome to generalize to high-degree products.
Theorem 7.4.1. Let f (x) be a monic polynomial of degree n. Let F (x) = xn · f (1/x) and g(x) = F (x)−1 mod xn−1. Then, u × v ≤ γMult(R) · u · v for some
√ γMult(R) ≤ 2n · (1 + 2n · f · g )
Proof. (Theorem 7.4.1) Let t(x) ← u(x) · v(x) be the (unreduced) degree 2n − 2 product of u and v. Let t(x) = q(x)f (x) + r(x), where r(x) = t(x) mod f (x) is a polynomial of degree n − 1, and q(x) is a polynomial of degree n − 2. We have u × v = r , the latter term denoting the Euclidean norm of the vector formed by the coeﬃcients of r(x).
Note that each coeﬃcient of t(x), being an inner product of some subset of coeﬃcients √
of u and v, must have norm less than u · v ; overall, t ≤ 2n · u · v . Let T (x) = x2n−2t(1/x), Q(x) = xn−2q(1/x), and R(x) = x2n−2r(1/x). Then, T (x) =
Q(x)F (x) + R(x), where T, Q, F are all integer polynomials with the same degrees and norms as t, q, f . R, which has the same norm as r, is divisible by xn−1, implying that

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

73

Q(x) = T (x)g(x) mod xn−1. Since Q(x) has degree n − 2, this equation implies Q ≤ √
2n · T · g . We have
u×v = r = R ≤ T + Q·F √
≤ T + 2n · Q · F ≤ T + 2n · T · g · F = t · (1 + 2n · f · g )
√ ≤ u · v · 2n · (1 + 2n · f · g )

as required.

To ﬁnd a suitable ring R = Z[x]/(f (x)) for which γMult(R) is small, it suﬃces to ﬁnd an f (x) for which both F (x) and F (x)−1 mod xn−1 have small norms, where F (x) = xn·f (1/x).

This gives us a lot of freedom in choosing f (x).

For example, we can sample f (x) from the large class of polynomials such that f (x) has

small norm and f (x) = xn − h(x) where h(x) is a polynomial of degree at most (n + 1)/2.

√ In this case, for R = Z[x]/(f (x)), one can prove that γMult(R) ≤ 2n · (1 + 2n ·

f

2). One

can generalize this to the case that h(x) has degree at most n − (n − 1)/k for k > 2.

Theorem 7.4.2. Suppose f (x) = xn − h(x) where h(x) has degree at most n − (n − 1)/k for

√ k ≥ 2. Then, for R = Z[x]/(f (x)), it holds that γMult(R) ≤ 2n·(1+2n·(

(k − 1)n f )k).

Proof. Let F (x) = xn · f (1/x) = 1 − xn · h(1/x). Let H(x) = xn · h(1/x). Note that H(x) is divisible by xm for integer m ≥ (n − 1)/k, since h(x) has degree at most n − (n − 1)/k. This fact implies that 1 − H(x)k = 1 mod xn−1. So, g(x) ← F (x)−1 = 1/(1 − H(x)) = (1 − (H(x))k)/(1 − H(x)) mod xn−1, and we have:

g(x)

≤ 1 + H + · · · + Hk−1 ≤ 1 + H + · · · + ((k − 1)n)(k−1)/2 H k−1 ≤ 1 + f + · · · + ((k − 1)n)(k−1)/2 f k−1 ≤ ( (k − 1)n f )k − 1 / ( (k − 1)n f ) − 1

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

74

Since

f

<(

√ (k − 1)n f ) − 1, we have γMult(R) ≤ 2n · (1 + 2n · (

(k − 1)n f )k).

Undoubtedly there are suitable f (x) that do not fall into the class of polynomials above. For example, let a1, . . . , ak, b1, . . . , bk be polynomials, such that for each i, ai = xri − 1 and bi = (1−xrisi)/(1−xri) for some {ri}, {si} where ri·si ≥ n−1 and ri < n−1. Then, for each i, aibi = 1 mod xn−1 (nontrivially) and ai and bi are both quite small. We could set F (x) and g(x) by picking a random subset S ⊆ {1, . . . , k} and setting F (x) ← i∈S ai mod xn−1 and g(x) ← i∈S bi mod xn−1. The Euclidean norms of F and g would be rather small, since the Euclidean norms of the ai’s and bi’s were very small. This technique seems messier than the approach above; the point here is that the approach above is not the only approach.
A simple case is to set f (x) ← xn − 1. For the ring R = Z[x]/(xn − 1), it is easy to show that γMult(R) ≤ √n.
Lemma 7.4.3. Suppose x, y ∈ R = Z[x]/(xn − 1), and let z ← x × y. Then z ≤ √n · x · y .
Proof. Consider the i-th coeﬃcient zi of z; we have
zi = xj · yi−j mod n
j
In particular, since zi is an inner product of (rotated versions of) x and y, we have that |zi| ≤ x · y (for all i). The result follows.

However, such circulant ideal lattices come with the disclaimer, mentioned in Section 6.2, that there are non-fatal but somewhat disconcerting attacks on hard problems over this particular ring.
We also prefer f (x) to be irreducible, so that K = Q(x)/(f (x)) is a ﬁeld. In this case, Z[x]/(f (x)) inherits the nice properties of its overlying ring of integers OK, with some qualiﬁcations. (See Section 6.) Using irreducible f (x) also seems to make R less vulnerable to cryptanalytic attacks, such as that in [47]. If desired, we can get many of the beneﬁts of using Z[x]/(xn − 1) by instead using Z[x]/(f (x)) for f (x) = (xn − 1)/(x − 1), which is irreducible when n is prime.

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

75

7.5 Instantiating Encrypt and Minimizing rEnc
From Theorem 7.3.2, we would like to set rEnc to be as small as possible, consistent with security. Recall that XEnc ⊆ B(rEnc) is the image of the Samp algorithm used in Encrypt, where our security proof (Theorem 5.3.1) holds when Samp(BI , x) runs r ← Samp1(R) and outputs x + r × s, where s is a generator of the ideal I. Let Samp1 be an upper bound on the length of r, drawn according to Samp1. We have
√ rEnc = max{ x + r × s } ≤ n · BI + n · Samp1 · BI
Toward minimizing rEnc, we can choose s to be short – e.g., use s = 2 · e1. The size of Samp1 is a security issue. We need it to be large enough so that the min-
entropy of t mod BpJk in the ICP is large. As a concrete example, one could set Samp1 = n, and have Samp1 sample a uniformly random integer vector in B( Samp1).
Overall, we can take rEnc to be polynomial in n. We note that, even in this case, the plaintext space may be as large as [R : I] = det(I), which can be exponential in n.
There are certainly alternative ways of generating I and instantiating Samp. For example, one may set s in such a way that the Hermite normal form of (s) has all 1’s along the diagonal, except for the upper-left corner, which equals det(I). (This property of the Hermite normal form will always hold when det(I) is prime.) This gives a plaintext space isomorphic to Zdet(I), which may be more useful than the space Zn2 for some application. Also, the image of Samp is not necessarily very “nice” – e.g., it may not be “spherical,” but may rather be distorted in a way that depends on the ring R. In Section 14.1, we discuss a diﬀerent way to instantiate Samp is using Gaussian distributions over lattices.
7.6 Instantiating Decrypt and Maximizing rDec
From Theorem 7.3.2, we would like to set rDec to be as large as possible, consistent with security. Recall that rDec is the radius of the largest sphere centered at 0 that is circumscribed by BsJk. Also, recall our decryption equation.
π = ψ − BsJk · (BsJk)−1 · ψ mod BI
To maximize rDec, one strategy is simply to scale up the parallelepiped BsJk. But this does

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

76

not really buy us anything. For a ﬁxed ratio rDec/rEnc, one can verify that our maximum depth (per Theorem 7.3.2) of log log rDec − log log(γMult(R) · rEnc) decreases as we scale up rDec and rEnc simultaneously. (If we scale up rDec without scaling up rEnc, this increases the approximation factor of the associated bounded distance decoding lattice problem, which hurts security. See Section 7.7.) The important property of BsJk is its shape – i.e., we want the parallelepiped P(BsJk) to be “fat” enough to contain a large sphere. This property is easier to formalize in terms of the inverse matrix (BsJk)−1, whose transpose is a basis (or independent set) of the dual lattice L(BsJk).
Lemma 7.6.1. Let B be a lattice basis and B∗ = (B−1)T . Let r be the radius of the largest sphere, centered at 0, circumscribed by P(B) (permitting tangential overlap). Then, r = 1/(2 · B∗ ). In particular,
rDec = 1/(2 · ((BsJk)−1)T )
Suppose t < rDec; then each coeﬃcient of B−1 · t has magnitude at most 1/2.
Proof. Suppose x < 1/(2 · B∗ ). Each coeﬃcient of B−1 · x is an inner product of x with a column vector of B∗, and therefore has magnitude at most x · B∗ < 1/2. This implies that B−1 · x = 0, that x = (x mod B), and that x ∈ P(B). Now, suppose x > 1/(2 · B∗ ) and is parallel to the longest vector bi in B∗. Then, | bi, x | > 1/2, implying that B−1 · x = 0, and that x = (x mod B), and that x ∈/ P(B).
The relevance of Lemma 7.6.1 is that the decryption equation above is correct when ψ is at most rDec = 1/(2 · ((BsJk)−1)T ) away from a lattice point in J .
It is easy to imagine ad hoc ways of instantiating IdealGen so that the parallelepiped P(BsJk) is “fat” – i.e., contains a sphere whose radius is only polynomially shorter than the parallelepiped’s diameter. For example, one could generate a random vector v and simply set BsJk to be the rotation basis of v, and set BpJk to be the HNF of (v). Very roughly speaking, if v is generated as a vector that is very “nearly parallel” to e1 (i.e., the vector (1, 0, . . . , 0)), then the rotational basis will have rDec within a small (polynomial) factor of λ1(J). More formally, we have the following lemma.
Lemma 7.6.2. Let t ≥ 4 · n · γMult(R) · s. Suppose v ∈ t · e1 + B(s) – i.e., v is in the ball of radius s centered at t · e1. Let B be the rotation basis of v. Then, P(B) circumscribes a

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

77

ball of radius at least t/4.
Proof. For i ∈ [0, n − 1], let vi = v × xi, and zi = vi − t · ei. We have that zi = z0 × xi ≤ γMult(R) · z0 ≤ γMult(R) · s. (In other words, we have that vi = t · e1 + zi is nearly parallel to ei when γMult(R) · s is much smaller than t.)
For every point a on the surface of P(B), there is an i such that

for xj ∈ [−1/2, 1/2]. So,

a = (±1/2) · vi + xj · vj
j=i

| a, ei | ≥ t/2 − n · γMult(R) · s

In particular, a ≥ t/2 − n · γMult(R) · s and the lemma follows.

Perhaps lattice problems over principal ideal lattices generated in the above ad hoc fashion are easy, though currently no eﬃcient attacks are known. A “better” instantiation of IdealGen, which permits a security reduction from worst-case SIVP, is given in Section 18.
7.7 Security of the Concrete Scheme
When instantiated with ideal lattices, the ideal coset problem (ICP) becomes the following problem.
Deﬁnition 7.7.1 ((Decision) Bounded Distance Decoding Problem (Decision BDDP) for Ideal Lattices). Fix a polynomial ring R = Z[x]/(f (x)), algorithm IdealGen that samples a basis of an ideal in R, and an algorithm Samp1 that eﬃciently samples Zn. The challenger sets b ←R {0, 1} and (BsJk, BpJk) ←R IdealGen(R, BI ). If b = 0, it sets r ←R Samp1(R) and t ← r mod BpJk. If b = 1, it samples t uniformly from R mod BpJk. The problem: guess b given (t, BpJk).
In short, the problem is to decide whether t is uniform modulo the ideal lattice J, or whether t was sampled according to a known “clumpier” distribution induced by Samp1.

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

78

Obviously, the hardness of decision BDDP depends crucially on Samp1 – i.e., decision BDDP is an average-case problem whose hardness depends on the (average-case) distri-

bution of Samp1. For example, if Samp1(R) always output the zero vector 0, or sampled according to some other distribution with very low min-entropy, the problem would be easy.

However, based on current knowledge, it seems reasonable to believe the problem can be

hard when Samp1’s min-entropy is high – e.g., when r is sampled from a sphere of radius n, or when r is sampled according to a discrete n-dimensional Gaussian distribution with a standard deviation parameter s = ω(√log n). We defer details regarding discrete Gaus-

sian distributions until Section 13; for now, as a concrete example, let’s suppose that r is

sampled uniformly from a sphere of radius Samp1 = n. The hardness of decision BDDP also depends on how J is generated – in particu-

lar, on the value λ1(J), and whether λ1(J) is much larger than Samp1. In particular, if λ1(J)/ Samp1 ≥ 2n (and we could replace the rhs with a slightly sub-exponential value),
then Babai’s nearest plane algorithm [13] or variants of the lattice reduction algorithm LLL

[81] can be used to recover the closest J-vector to t in polynomial time. This attack breaks

decision BDDP for these parameters, since it is a very safe bet that t was generated using

Samp1 when dist(J, t) < Samp1 uniformly. However, there are

; if no

dkinsto(wJn, t)at>tacSkasmwp1h, eitn,isfoarceexrtaaminpblee,tλt1h(aJt)t=wa2sOg(√enne) r(aatnedd

Samp1 is as before). Above, we suggested ways of instantiating the ring R, the algorithm Samp used in

Encrypt, and the algorithm IdealGen used in KeyGen. Let’s reconsider these suggestions,

and revisit the sizes of rEnc and rDec, with a view to how they impact the hardness of the

induced decision BDDP. √
In Section 7.5, we observed that rEnc is at most n · BI + n · Samp1 · BI , where BI can be chosen so that BI is polynomial in n (or even constant). In short, we can

have rEnc only polynomially larger than Samp1. In Section 7.6, we observed that one can instantiate IdealGen so that it outputs a secret basis BsJk for J such that, if rDec is the radius of the largest ball circumscribed by P(BsJk), then rDec is only polynomially smaller
than λ1(J ). Overall, we can make rDec/rEnc be within a polynomial factor of λ1(J )/ Samp1, where the latter is essentially the approximation factor of our decision BDDP problem.

As a rule of thumb, solving 2k-approximate decision BDDP takes time roughly 2n/k using known attacks; so, rDec = 2O(√n) and rEnc = poly(n) seems to be a reasonable setting of parameters. When rDec = 2nc1 and γMult(R) · rEnc = 2nc2 , then Theorems 5.2.6 and 7.3.2

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

79

imply that the scheme can correctly evaluate circuits of depth (c1 − c2) log n.
Remark 7.7.2. Setting rDec to be small permits a weaker assumption, but leads to a scheme that can evaluate only very shallow circuits. Let us suppose that rDec = nα(n) and γMult(R) · rEnc = nβ(n), for some functions α(n), β(n). As far as we know, for irreducible f (x), γMult(R) must be at least polynomial in n, so β(n) must be at least constant. In this case, the scheme can evaluate depth log α(n) − log β(n). This implies that we can only evaluate constant depth circuits, unless rDec/rEnc is super-polynomial. Though we omit details here, constant depth will be insuﬃcient to make our eventual scheme bootstrappable; bootstrappability will require the BDDP approximation factor to be super-polynomial.
Again, one may question how hard the decision BDDP actually is for our ad hoc instantiation of IdealGen. In Section 6, we mentioned that Gentry and Szydlo [50] have a polynomial-time attack on circulant ideal lattices that have orthonormal bases. This attack suggests that we may want to avoid principal ideal lattices with “nearly orthonormal” bases even in non-cyclotomic polynomial rings. We provide an alternative IdealGen algorithm in Section 18, and provide a worst-case / average-case connection for IdealGen’s distribution in Section 17.
We stress that our analysis below regarding the decryption circuit does not rely on the ad hoc concrete suggestions in this section – e.g., the analysis does not require I or J to be principal ideals.
7.8 How Useful is the Somewhat Homomorphic Scheme By Itself ?
The momentum of our paper is directed toward obtaining a bootstrappable, and hence a (leveled) fully homomorphic, encryption scheme. However, we pause brieﬂy to consider how we can use our somewhat homomorphic scheme even if we do not try to bootstrap.
Theorem 7.3.2 tells us that we can evaluate circuits of depth
log log rDec − log log(γMult(R) · rEnc)
even if the AddBI gates have high fan-in (i.e., γMult(R) fan-in). We have seen above that we can take rDec to be of the form 2nc for some constant c < 1, and γMult(R) and rEnc to be polynomial in n. In this case, we can evaluate logarithmic depth.

CHAPTER 7. A SOMEWHAT HOMOMORPHIC ENCRYPTION SCHEME

80

Already this is a signiﬁcant improvement on prior work. For example, the Boneh-GohNissim (BGN) pairing-based cryptosystem [21] was the ﬁrst to permit eﬃcient evaluation of 2-DNF formulas, quadratic formulas that may have a polynomial number of monomials. Being able to compute quadratic formulas is extremely useful – e.g., Groth, Ostrovsky, and Sahai [63] used their system to construct a perfectly NIZK system for general circuits (with length proportion to the size of the circuit). However, one shortcoming of the BGN system is its small plaintext space – log λ bits for security parameter λ. Our somewhat homomorphic scheme, without the bootstrapping, already improves upon this, allowing both greater multiplicative depth in the circuit and a larger plaintext space.
As an example, we obtain the ﬁrst single-database private information retrieval scheme with communication complexity O(λ·log m), where λ is the security parameter and m is bitlength of the database s1, . . . , sm. The querier encrypts the binary representation π1, . . . , πM of the index that it wants, constructing the ciphertexts ψ1, . . . , ψM , where M = log m + 1. Homomorphically, the server homomorphically evaluates the formula

M

f (π1, . . . , πM , s1, . . . , sm) =

st · (ti − πi + 1) mod 2

t∈{0,1}M

j=1

where, in st, t is interpreted as a number in [1, m]. Notice that this formula encrypts

the correct entry in the database. Also, observe that if the ciphertexts ψ1, . . . , ψM have

oﬀsets in B(rEnc), then the oﬀset of the output is in B(r) for r = O(m · (γMult(R) ·

rMEnc=)Mθ)(√=nO/ l(o(g2(·γMγMulut(ltR(R) )·

· rEnc)M ). If rEnc)), which

one permits rDec is polynomial in

= n.

2θ(√n), then one In other words,

can our

permit scheme

correctly evaluates the PIR formula even when the database is sub-exponential (super-

polynomial) in size, though of course the computation would be very high in that case.

In general, when the function to be evaluated is highly parallel, the bootstrapping step

may be unnecessary, permitting better eﬃciency.

Chapter 8
Tweaks to the Somewhat Homomorphic Scheme
At this point, we have described our somewhat homomorphic scheme in enough detail to begin considering whether the scheme is bootstrappable. First, however, we describe two “tweaks” to the scheme. The purpose of these tweaks is to lower the eventual circuit complexity of decryption without substantially reducing the depth that the scheme can evaluate.
As the ﬁrst tweak, we modify the secret key of our scheme so that the decryption equation simpliﬁes from
π = ψ − BsJk · (BsJk)−1 · ψ mod BI to
π = ψ − vJsk × ψ mod BI where vJsk ∈ J −1.
Before describing the tweak, it is helpful to understand the relationship between the dual of a lattice (a good basis for which was originally used as the decryption key) and the inverse of an ideal lattice (a vector from which is used as the decryption key in our revised decryption equation).
81

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

82

8.1 On the Relationship between the Dual and the Inverse of an Ideal Lattice

Recall the deﬁnition of the dual of an ideal lattice J: J∗ = {x ∈ Rn : ∀v ∈ J, x, v ∈ Z}. The inverse in R = Z[x]/(f (x)) of an ideal has a superﬁcially similar deﬁnition: J−1 = {x ∈

Q[x]/(f (x)) : ∀v ∈ J, x × v ∈ R}.
If BJ happens to be a rotation basis of J = (v), then the inverse J−1 = (1/v) is generated by the rotation basis of 1/v, the columns of B−J 1. However, the dual of J is generated by the inverse transpose of BJ . So it is certainly not true in general that the ideal lattice associated to J−1 is generated by the dual of the ideal lattice associated to J.1

However, for rotation bases, since the bases of the dual and the inverse are just transposes

of each other, we have the following easy lemma, which is analogous to Lemma 7.6.1.

Lemma 8.1.1. Let B be a rotation basis and B∗ be its inverse transpose. Then, B∗ ·√n ≥

B−1 rDec ≤

≥ B∗ √n/(2

/√n. In particular, · (BsJk)−1 ).

if

BsJk

is

a

rotation

basis,

we

have

1/(2√n ·

(BsJk)−1

)≤

Proof. Let bij be the highest-magnitude coeﬃcient in the matrix B−1. Then,

B−1

≥ bij ≥

B∗

√ /n

and

B∗

≥ bij ≥

B−1

√ /n

Using Lemma 7.6.1, we have

√ 1/(2 n ·

(BsJk)−1

√ ) ≤ rDec ≤ n/(2 ·

(BsJk)−1 )

Can we provide a more precise characterization of this relationship between the dual and the inverse for general (non-principal) ideal lattices? For example, given a short vector in J−1, can we ﬁnd a short basis of J∗? Or, given a short vector in J∗, can we output a short basis of J−1. The answer to both of these questions is yes.
Lemma 8.1.1 already answers the ﬁrst question. Let BJ be a basis of J, with column vectors u0, . . . , un−1. If v is a short vector in J−1 and Bv is its rotation basis, then v×ui ∈ R for all i, and therefore Bv · BJ is an integer matrix. This implies that the rows of Bv form
1Contrary to what we stated in [48]. Lyubashevsky [87] indicated this error.

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

83

an independent set in J∗. The longest row of Bv cannot be much longer than the longest column, as in the proof of Lemma 7.6.1.
The second question – i.e., whether one can generate a short basis of J−1 from a short vector in J∗ is more challenging, but we have the following lemma.

Lemma 8.1.2. Let w ∈ J∗, where J∗ is the dual of the ideal lattice J. Let

n−1

n

v = xi

fj · wj−i−1

i=0 j=i+1

Then, v ∈ J−1. Let Bv be the rotation basis of v. Then, Bv ≤ √n · f · w . This applies even when J is a fractional ideal.

The idea of the proof is to take w ∈ J∗, place it as the bottom row in an n × n matrix, and then to try to ﬁll out the rest of the matrix so that we end up with the rotation basis of a vector in J−1. Together, the vector w and the polynomial f (x) dictate what the rest of the matrix must be.

Proof. We claim that the bottom row of Bv is (w0, w1, . . . , wn−1). In other words, in some sense, one can view Bv as an “extension” of the single row (w0, w1, . . . , wn−1) into an entire matrix that happens to be a rotation basis.
Denote the columns of Bv by v(k) = v · xi mod f (x). We claim that

n−1

n

k−1 i

v(k) = xi

fj · wj−i−1+k −

xi

fj · wj−i−1+k

i=k j=i+1

i=0 j=0

from which it follows that the coeﬃcient of xn−1 in v(k) is indeed wk. This is clearly true

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

84

for k = 0; assume it is true for k − 1. We have that





n−1

n

k −2 i

v(k ) = x 

xi

fj · wj−i−1+k −1 −

xi fj · wj−i−1+k −1 mod f (x)

i=k −1 j=i+1

i=0 j=0

n

n

k −1 i−1

=

xi fj · wj−i−1+k −

xi fj · wj−i−1+k mod f (x)

i=k j=i

i=1 j=0

n

n

k −1 i−1

=

xi fj · wj−i−1+k −

xi fj · wj−i−1+k − (fn · wk −1) · f (x)

i=k j=i

i=1 j=0

n

n

k −1 i−1

n

=

xi fj · wj−i−1+k −

xi fj · wj−i−1+k − xi · wk −1 · fi

i=k j=i

i=1 j=0 

i=0

n

n

=

xi −fi · wk −1 + fj · wj−i−1+k 

i=k

j=i



k −1

i−1

−

xi fi · wk −1 +

fj · wj−i−1+k  − wk −1 · fi

i=1

j=0

n

n

k −1 i

=

xi

fj · wj−i−1+k −

xi fj · wj−i−1+k − wk −1 · fi

i=k j=i+1

i=1 j=0

as required. To show that v ∈ J−1, it suﬃces to prove that z ← v × x ∈ R for any x ∈ J. Let Bx
and Bz be the rotation bases of x and z. We know that Bz = Bv · Bx. We also know that
the bottom row of Bz is an integer vector, since this row is w · Bx and w has an integer
inner product with all vectors in J (which includes the column vectors of Bx). Assume, toward a contradiction that z is not an integer vector – in particular, that i∗
is the largest such that the coeﬃcient zi∗ is not an integer. Consider z(n−i∗−1) ← xn−i∗−1 · z mod f (x), which is a column vector in Bz. In xn−i∗−1 · z, the coeﬃcients of xn through x2n−i∗−2 – all of the highest coeﬃcients – are integers. Therefore, since f (x) is monic, z(n−i∗−1) = xn−i∗−1 · z − a(x) · f (x), where a(x) is an integer polynomial. On the other hand, the coeﬃcient of xn−1 in xn−i∗−1 · z is not an integer, since zi∗ is not an integer. Consequently, since z(n−i∗−1) diﬀers from xn−i∗−1·z by an integer polynomial, the coeﬃcient of xn−1 in z(n−i∗−1) is also not an integer. But we have established that the bottom row of Bz is integral, a contradiction. Therefore, z is in R and v ∈ J−1.

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

85

Regarding Bv , we have established that each entry of this matrix is an inner product

of two vectors – one vector with coeﬃcients in {f0, . . . , fn}, the other with coeﬃcients in

{w0 f

,. ·

.., w

wn−1} (up , implying

to sign). that Bv

The ≤

magnitude √n · f ·

of w

each .

coeﬃcient

in

Bv

is

therefore

at

most

8.2 Transference Lemmas for Ideal Lattices

As an easily corollary, we can obtain a bound on the determinant of J−1 in terms of det(J), and also place a bound on λn(J−1) in terms of λn(J). Not all ideals are “invertible” in the sense that it is not always the case that J−1 · J = R. (See Section 13.4 for more details on
this.) But we bound the discrepancy in the following lemma.

Lemma 8.2.1. Let J be a (possibly fractional) ideal of R √n · f · λ1(J∗) ≤ n · f /λn(J ). Also, det(J −1) < nn ·

= f

Z[x]/(f (x)). n/ det(J).

Then,

λn(J −1)

≤

PtinhwwraoLto.ef≤.mwBLm√eyant/≤t8whd.1ee√.tb2(tne,Jr/aa)aλn1n/sndvnf(eeJrblcee)tyt,nocrMBweihivnntihckbJhoeewo∗irismetoksmfpi,lrliewoλentse1ag(thttLihhao)evnλ·eﬁ1λbd(ranJses(tt∗iL(s)Bs.∗.t)vaBt)G≤ey≤emnL√eneenrnnmta.·tmfeofaSrvin8ng∈c.e/1end.2eJedr,t−ae(t1lJ(BJ)lfa.rv∗to)tmic≤=ews√,1/∈wnde·eJth∗(faJva)es·,

Using Lemma 8.2.1, we can upper bound λn(J) in terms of n, |f | and det(J).

Lemma 8.2.2. Let J be an ideal of R = Z[x]/(f (x)). Then, λn(J) < n · f · det(J)1/n.

Proof. We have

λn(J )

≤ n · f /λn(J−1) (by Lemma 8.2.1) ≤ n · f / det(J −1)1/n ≤ n · f · det(J )1/n

We have a similar result regarding the product of two general ideals (not necessarily inverses of each other).

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

86

Lemma 8.2.3. Let J and K be two (possibly fractional) ideals of R. Then, λn(JK) < n · f (det(J) · det(K))1/n. Also, det(JK) ≤ nn · f n · det(J) · det(K).

Proof. This would follow trivially from Lemma 8.2.2, except that it is possible that det(J · K) > det(J) · det(K) when J and K are divisible by singular primes (see Chapter 13.4).
By Lemma 8.2.1, we have that

√ λn(JK) ≤ n ·

f

· λ1(((J K)−1)∗)

The determinant of the latter ideal is at most det(J) · det(K), since, in general, det(I1 · I2) ≥ det(I1) · det(I2) and det(I) · det(I−1) ≥ 1 (see Chapter 13.4). So, by Minkowski, λn(JK) < n · f (det(J) · det(K))1/n.
By Lemma 8.2.1, we have that det(JK) · det((JK)−1) < nn · f n. So, we have

nn · f n ≥ det(J K) · det((J K)−1) ≥ det(J K) · det(J −1) · det(K−1) ≥ det(JK) · det(J∗) · det(K∗)

from which the result follows.

8.3 Tweaking the Decryption Equation
Having characterized the relationship between the inverse and the dual, we return to our ﬁrst tweak.
Tweak 1: From BI and secret key BsJk, compute a certain short vJsk ∈ J−1 and redeﬁne decryption to output π = ψ − vJsk × ψ mod BI . Also, redeﬁne CE , so that it instead uses B(rDec/(n2.5 · f · BI ) instead of B(rDec). Purpose: To simplify the decryption equation and improve computational eﬃciency.
This tweak is not actually essential, since matrix-vector multiplication is just as parallelizable as ring multiplication – i.e., the circuits have essentially the same depth. However, the tweak reduces the size of our secret key. This will help reduce the computational complexity of decryption (and, thus, the computational complexity of the homomorphic decryption step in bootstrapping). Essentially, it makes the already shallow decryption circuit less wide.

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

87

Tweak 1 requires us to reduce the permitted distance of ciphertexts from the J-lattice.
But it does not aﬀect our maximum evaluation depth very much when |f | and BI are only polynomial in n, and rDec/rEnc is super-polynomial (as it will need to be to make our scheme bootstrappable).
Toward understanding how this simpliﬁcation works, suppose that it is the case that BsJk is the rotation basis for some vector wJsk ∈ Z[x]/(f (x)). Let xsJk = 1/wJsk ∈ Q[x]/(f (x)). Then, since the rotation basis of xsJk is precisely (BsJk)−1, and by properties of rotation bases (see Chapter 6.2) we have that

π = ψ − BsJk · (BsJk)−1 · ψ mod BI = ψ − wJsk × xsJk × ψ mod BI

As for generating the initial BsJk as a rotation basis, for now we just mention that the ad hoc instantiation of IdealGen given in Chapter 7.6 suﬃces. However, as the lemmas below establish, Tweak 1 works even when BsJk is not a rotation basis.

Lemma 8.3.1. Let BsJk be an initial secret basis that decrypts correctly for parameter rDec. From BsJk and BI , we can compute in polynomial time a vector vJsk ∈ J−1 such that the rotation basis of 1/vJsk circumscribes a ball of radius at least rDec/(n2.5 · f · BI ). In particular, if ψ is a valid ciphertext according to Tweak 1, in the sense that it equals π +i+j
for plaintext π, i ∈ I, j ∈ J, and π + i ∈ B(rDec/(n2.5 · f · BI ), then π = ψ − (vJsk)−1 × vJsk × ψ mod BI . For our particular value of vJsk ∈ J −1, it will also hold that π = ψ − vJsk × ψ mod BI .

Proof. Since BsJk be an initial secret basis that decrypts correctly for parameter rDec, Lemma

7.6.1 tells us that ((BsJk)−1)T ≤ 1/2rDec. Let w ∈ J∗ be a vector in this basis. By Lemma

8.1.2, most

we √n

can ·f

use ·

w w

to generate ≤ √n · f

a vector /2rDec.

x ∈ J−1 whose rotation From Bx and a vector

basis Bx has length at in I of length at most

√BnI·

, we Bx

can generate an · BI ≤ n · f ·

independent set BJ−1I of (x) · I ⊂ J −1I BI /2rDec. We set vJsk ← e1 mod BJ−1I . It

of length at has length at

most most

n2 · f · BI /2rDec.

Let B†J be the rotation basis of (vJsk)−1; we want to prove that this basis can be used as the secret key for ciphertexts that are valid according to Tweak 1. Certainly B†J fulﬁlls the

requirement of generating a super-lattice of J, since vJsk generates a sub-lattice of J−1. It remains to show that a large enough sphere is circumscribed by B†J . Let rDec be the radius

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

88

of the largest such sphere. We have

√ rDec ≥ 1/(2 n ·

(B†J )−1 ) ≥ rDec/(n2.5 ·

f

·

BI )

where the ﬁrst inequality follows from Lemma 8.1.1, and the second substitutes in the upper bound on the length of the rotation basis for vJsk. The correctness of decryption with the new key follows.
However, now we need to establish that we can simply drop the (vJsk)−1 term in the decryption equation. Since I and J are relatively prime, there is a vector j ∈ J ∩ (1 + I).
Such a j can be found eﬃciently using the Chinese remainder theorem and bases for I and J . Let r = j × vJsk. Since vJsk ∈ J −1, we have r ∈ R. In fact, since vJsk ∈ 1 + J −1I, we have r ∈ 1 + I. Since, by the correctness of decryption, we know that (vJsk)−1 × vJsk · ψ ∈ R (even though vJsk)−1 may not be in R, we have the following congruences modulo I:

(vJsk)−1 × vJsk · ψ

= r × (vJsk)−1 × vJsk · ψ = j × vJsk · ψ = vJsk · ψ

8.4 A Tweak to Reduce the Circuit Complexity of the Rounding Step in Decryption
Tweak 2 will actually be more critical than Tweak 1 for reducing the depth of our decryption circuit and enabling bootstrapping.
Tweak 2: Redeﬁne the set of permitted circuits CE , replacing B(rDec) with B(rDec/2). Purpose: To ensure that ciphertext vectors are closer to the lattice J than they strictly need to be, so that we will need less “precision” to ensure the correctness of decryption.
Remark 8.4.1. If using Tweak 1 and Tweak 2, then use B(rDec/(2n2.5 · f · BI ) in the redeﬁnition of permitted circuits – i.e., a radius half as small as the one used in Tweak 1. For simplicity, in this Section, we will abuse notation and use rDec to refer to the value of the permitted radius before Tweak 2.

CHAPTER 8. TWEAKS TO THE SOMEWHAT HOMOMORPHIC SCHEME

89

The purpose of the tweak will become clearer as we delve into the details of the decryption circuit. But, brieﬂy, recall that Decrypt computes BsJk1 · (BsJk2)−1 · ψ . (If Tweak 1 is used, then BsJk1 is just the identity matrix and (BsJk2)−1 is the rotation basis of vJsk.) If we permitted the coeﬃcients of (BsJk2)−1 · ψ to be very close to half-integers, we would need high precision to ensure correct rounding. However, after Tweak 2, we have the following lemma:
Lemma 8.4.2. If ψ is a valid ciphertext after Tweak 2, then each coeﬃcient of (BsJk2)−1 · ψ is within 1/4 of an integer.
Proof. Observe that ψ ∈ B(rDec/2)+J. Let ψ = x+j for x ∈ B(rDec/2) and j ∈ J. We have (BsJk)−1 · ψ = (BsJk)−1 · x + (BsJk)−1 · j, where the former term has coeﬃcients of magnitude at most 1/4 by Lemma 7.6.1 and the latter is an integer vector.
This fact will help us simplify our decryption circuit, and does not substantially impair the evaluative capacity of our scheme. The new maximum evaluation depth, per Theorem 7.3.2, is log log(rDec/2) − log log(γMult(R) · rEnc), which is less than the original amount by only a sub-constant additive factor.
Again, to use Tweaks 1 and 2 simultaneously, use B(rDec/(2n2.5 · f · BI ).

Chapter 9
Decryption Complexity of the Tweaked Scheme
To decrypt, we compute
(ψ − BsJk1 · BsJk2 · ψ ) mod BI
where ψ ∈ Zn, BsJk1 ∈ Zn×n, BsJk2 ∈ Qn×n, and BI is a basis of an ideal I of R = Z[x]/(f (x)). From Tweak 2, we have the promise that the coeﬃcients of BsJk2 · ψ are all within 1/4 of an integer. Optionally, Tweak 1 ensures that BsJk1 is the identity matrix and BsJk2 is a rotation matrix. How do we optimally express this computation as a circuit?
Let us split the computation into pieces – in particular, the following steps: Step 1: Generate n vectors x1, . . . , xn with sum BsJk2 · ψ. Step 2: From the n vectors x1, . . . , xn, generate integer vectors y1, . . . , yn+1 with sum
xi . Step 3: Compute π ← ψ − BsJk1 · ( yi) mod BI We do not claim that this way of splitting up the computation leads to an optimal decryption circuit. But, we will eventually see that, thanks to Tweak 2, Step 3 can be done in constant depth using a circuit with polynomial fan-in addition gates. (In Theorem 7.3.2, we saw that constant fan-in multiplication gates were as bad as, or worse than, polynomial fanin addition gates.) We will see that Step 2 requires a deep circuit, but that there is a way to squash this aspect of the computation. (See Chapter 10.) Step 1 could be done by multiplying the n columns of BsJk2 by the n coeﬃcients of ψ. But our method for
90

