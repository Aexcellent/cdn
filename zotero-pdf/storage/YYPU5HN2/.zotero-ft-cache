
JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page. Skip to main content Skip to article
Elsevier logo ScienceDirect

    Journals & Books 

    View  PDF
    Download full issue 

Elsevier
Medical Image Analysis
Volume 101 , April 2025, 103497
Medical Image Analysis
Survey paper
From challenges and pitfalls to recommendations and opportunities: Implementing federated learning in healthcare
Author links open overlay panel Ming Li a b , Pengcheng Xu c d , Junjie Hu b , Zeyu Tang a e , Guang Yang a b f g
Show more
Outline
Add to Mendeley
Share
Cite
https://doi.org/10.1016/j.media.2025.103497 Get rights and content
Under a Creative Commons license
Open access
Highlights

    •
    Evaluate recent FL technologies in healthcare, focusing on challenges and pitfalls.
    •
    Offer a taxonomic analysis of FL in healthcare across critical aspects.
    •
    Recommend strategies for improving FL and ensuring reproducibility.
    •
    Highlight trends and opportunities to enhance FL workflow.

Abstract
Federated learning holds great potential for enabling large-scale healthcare research and collaboration across multiple centers while ensuring data privacy and security are not compromised. Although numerous recent studies suggest or utilize federated learning based methods in healthcare, it remains unclear which ones have potential clinical utility . This review paper considers and analyzes the most recent studies up to May 2024 that describe federated learning based methods in healthcare. After a thorough review, we find that the vast majority are not appropriate for clinical use due to their methodological flaws and/or underlying biases which include but are not limited to privacy concerns, generalization issues, and communication costs. As a result, the effectiveness of federated learning in healthcare is significantly compromised. To overcome these challenges, we provide recommendations and promising opportunities that might be implemented to resolve these problems and improve the quality of model development in federated learning with healthcare.

    Previous article in issue
    Next article in issue 

Keywords
Federated learning
Healthcare
Pitfalls
Challenges
Recommendations
Opportunities
1. Introduction
The integration of Artificial Intelligence (AI) into healthcare research has started a transformative era, catalyzing unprecedented advancements in patient care, diagnostic precision, and therapeutic efficacy ( Liu et al., 2021c ). However, developing robust AI models requires a vast amount of multi-center data. A notable example is the genome-wide association studies, when confined to data from a single institution, are often limited by sample size , failing to identify established biomarkers ( Newton et al., 2013 ). This underscores the imperative for collaborative data sharing among institutions. Standard AI approaches rely on centralized datasets for model training, but in healthcare, centralization is complex due to various factors such as privacy concerns, regulatory constraints, as well as legal, ethical and technological barriers to data sharing ( Ngiam and Khor, 2019 ).
Federated Learning (FL) emerges as a revolutionary paradigm, promising the collaborative training of AI models across distributed datasets without data sharing ( McMahan et al., 2017 ). By enabling privacy-preserving data analysis across multiple data silos, FL can exploit the full potential of worldwide healthcare data across different demographics, unlocking insights unattainable by isolated institutions. Models trained in a federated fashion are potentially able to yield even less biased decisions and higher sensitivity to rare cases as they are exposed to a more complete data distribution . Recent studies have shown that models trained by FL can achieve performance comparable to the ones trained on centrally hosted datasets and superior to models that only see isolated single-institutional data ( Sheller et al., 2019 , Sheller et al., 2020 ). Notably, early studies into FL, particularly in areas like brain tumor ( Sheller et al., 2020 ), triple negative breast cancer ( Ogier du Terrail et al., 2023 ) and COVID-19 ( Dayan et al., 2021 ), also have begun to illustrate the potential for generalizability beyond a single institution.
Today’s pioneering large-scale initiatives span academic research, clinical applications, and industrial translations, collectively advancing FL in healthcare. Within academic research, consortia such as Trustworthy Federated Data Analytics (TFDA) ( Helmholtz Association, 2024 ) and the German Cancer Consortium (DKTK) (2024) spearhead decentralized research across institutions. An illustrative example is the international collaboration employing FL to develop AI models for mammogram assessment, which outperformed single-institutional models and exhibited enhanced generalizability ( NVIDIA, 2020 ). Moving to clinical applications, projects like HealthChain ( Healthchain Consortium, 2024 ) and DRAGON ( European Lung Foundation, 2024 ) aim to deploy FL across multiple hospitals in Europe, facilitating the prediction of treatment responses for cancer and COVID-19. By aiding clinicians in treatment decisions based on histology slides and CT images, FL demonstrated direct clinical impact. Another large scale project is the Federated Tumour Segmentation (FeTS) initiative ( FeTS-AI, 2024 ), which involves 30 institutions globally, that utilize FL to improve tumor boundary detection across various cancers. In the industrial domain, collaborative efforts like ( Melody Project, 2024 ) demonstrate how competing companies can optimize the drug discovery process through multi-task FL while protecting their proprietary data.
Despite FL’s promising advantages, integrating it within healthcare still faces methodological flaws and underlying biases. These encompass but are not limited to, addressing privacy concerns ( Dayan et al., 2021 , Fang et al., 2022 ), generalization issues ( Kline et al., 2022 ), communication costs ( Rothchild et al., 2020 ), and the non-independent and identically distributed (non-IID) nature of healthcare data across institutions ( Nguyen et al., 2021 ), safeguarding patient data against sophisticated inference attacks that could potentially deanonymize sensitive information from model updates ( Bouacida and Mohapatra, 2021 ), and the necessity for standardization across FL implementations. Moreover, there is a pressing need for models that not only exhibit robust performance across diverse datasets but are also interpretable and transparent in their predictions and decision-making processes ( Li et al., 2023a , Li et al., 2022b ).
To facilitate the implementation of FL in healthcare, we have considered and analyzed the most recent studies, delving into the practical application of FL in healthcare. We provide numerous recommendations and promising opportunities, which, if followed appropriately, might be able to mitigate current pitfalls and challenges, ultimately leading to high-quality development and reliable reporting of results in FL with healthcare. Our review makes contributions as follows:

    •
    Quantifying and evaluating the integrity and variation of most recent and advanced FL technologies in healthcare to identify challenges, flaws and pitfalls;
    •
    Providing a taxonomized, in-depth analysis and discussion of various aspects of FL within healthcare;
    •
    Offering evidence-based guidelines and recommendations to enhance the quality of FL development, ensuring fair and reproducible comparisons of FL strategies, while also identifying emerging trends and suggesting future opportunities for improving patient outcomes and streamlining clinical workflows.

The rest of this review is structured as follows. Section 2 provides an overview of the background and preliminaries of FL. Section 3 describes the screening procedure adopted in this work. Section 4 highlights the key findings of our analysis. Section 5 explores recent advances, challenges, and pitfalls in implementing FL in healthcare, offering practical recommendations to overcome current limitations and outlining potential future research directions.

    Download: Download high-res image (341KB)
    Download: Download full-size image 

2. Preliminaries
FL , introduced in 2017 ( McMahan et al., 2017 ) as federated averaging (FedAvg), is an approach that trains models across multiple clients without centralizing data. In FL, each client (e.g., hospitals and institutions) keeps their private data locally and contributes to a shared model by sending updates like gradients or parameters to a central server. This server coordinates the training process, aggregates updates, and broadcasts the refined model back to clients. The goal of FL is to minimize the global objective function with parameters θ defined as: (1) ∑ k = 1 K w k F k ( θ ) w h e r e F k ( w ) = 1 n k ∑ i ∈ P k l ( x i , y i , θ ) where K is the number of clients, the weights w k represents the proportional significance or scale of each local dataset, n k is the number of training data on client k ; P k is the set of indices of data points on client k , and n k = | P k | ; F k ( θ ) is the local objective function; l ( x i , y i , θ ) is the loss of the prediction on sample ( x i , y i ) .
The traditional centralized FL training process is detailed in Algorithm 1, it involves T communication rounds between server and clients. Specifically, in the t th communication round, each client first downloads the current global model from the server. Then each client trains its local model using the local dataset for E local epochs. Next, the server collects the model updates of all selected clients and aggregates them into a new global model. FL training is accomplished by repeating the above round until the global model meets the desired performance criteria.
In practice, the rapid development of FL has propelled the field beyond the traditional centralized paradigm, as shown in Fig. 1 . For instance, the integration of blockchain ( Kumar et al., 2021 ) and swarm learning ( Saldanha et al., 2022 ) has transitioned FL towards decentralized paradigms, such as peer-to-peer, sequential, and cyclic computing, which enhance data privacy, security, and traceability by enabling secure data transactions and consensus mechanisms . Throughout this evolution, the scope of updates exchanged during communication has expanded. The updates now encompass not only model parameters or gradients but also partial model parameters ( Thapa et al., 2022 ), statistical information ( Zhu et al., 2021 ), and predictions from knowledge distillation techniques, such as logits ( Li and Yang, 2023 ). This expansion helps reduce communication costs, enhance privacy, and enable multi-task learning where only certain parameters are updated collaboratively.

    Download: Download high-res image (125KB)
    Download: Download full-size image 

Fig. 1 . Difference between centralized FL paradigm and decentralized FL paradigm. Centralized FL relies on a central server to manage the training. While decentralized FL eliminates the need for a central server. Instead, clients can directly communicate with connected ones.
Beyond centralized or decentralized topologies, FL has evolved to address complex scenarios caused by varying feature and sample distributions . This evolution has led to the development of three primary paradigms: Horizontal Federated Learning (HFL) , where data from different clients significantly overlap in the feature space but have little overlap in the sample space; Vertical Federated Learning (VFL) , where data from different clients have minimal overlap in the feature space but significant overlap in the sample space; and Federated Transfer Learning (FTL) , which leverages knowledge transfer to handle scenarios where there is little overlap in both feature and sample spaces. Fig. 2 illustrates these differences. HFL is the most prevalent paradigm in FL studies. For instance, Clients 1 and 2 in Fig. 2 represent scenarios where a vast number of people use wearables, such as the Apple Watch, to monitor their health conditions. These devices generate large amounts of data that share the same feature space (e.g., heart rate, step count), enabling collaborative model training. VFL, on the other hand, is better suited for applications where clients share the same sample space but store distinct features. For example, as illustrated by Clients 1 and 3 in Fig. 2 , a patient’s medical records may be distributed across multiple hospitals, with each hospital contributing unique features (e.g., imaging data, lab results). Aggregating these features allows for a more comprehensive model. Finally, FTL addresses scenarios with limited overlap in both feature and sample spaces. As depicted by Clients 2 and 4 in Fig. 2 , different clients may manage varying combinations of healthcare data and patient populations, with only a small intersection in the feature space. This approach is particularly relevant for tabular EHR data ( Liu et al., 2022 ).

    Download: Download high-res image (197KB)
    Download: Download full-size image 

Fig. 2 . Visual representation of three categories of FL, illustrating their distribution across feature and sample spaces.
FL can be further categorized into Cross-silo FL and Cross-device FL based on the scale and attributes of participating clients. Cross-silo FL is tailored for scenarios where a limited number of participating clients, such as hospitals, medical centers, and institutions, collaboratively engage in all stages of FL training. Notable examples include Healthchain ( Healthchain Consortium, 2024 ), which facilitates FL deployment among multiple hospitals in Europe, and the Melody Project ( Melody Project, 2024 ), designed to optimize the drug discovery task across multiple companies while preserving data privacy. Cross-device FL , on the other hand, is designed for scenarios involving a multitude of participating clients, typically edge devices with limited data storage and computing capabilities. Examples include wearables (e.g., Apple Watch) and Internet of Medical Things (IoMT) devices. For instance, IoMT devices like Raspberry Pi and Jetson Nano can collect electronic health records (EHRs) in resource-limited environments, enabling early detection of sepsis ( Alam and Rahmani, 2023 ).
3. Method
Our review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines ( Moher et al., 2009 ). As shown in Fig. 3 , the flow diagram outlines the search, inclusion and exclusion procedures. We carried out a comprehensive search of the most recent studies focusing on advanced FL technologies within healthcare domain up to May 2024.
3.1. Literature search
We conducted a systematic search using PubMed , Web of Science, Scopus , Science Direct, IEEEXplore, ArXiv, Springerlink , ACM Digital Library, and Google Scholar. Any study up to May 2024 that involved the use of FL technologies in healthcare based on a simulated or real distributed scenario was included. The search phrases included the following keywords: “Federate Learning”, “Healthcare”, “Privacy-Preserving”, “Medical”, “Biomedical”, “Decentralized Learning”, and “Privacy”, using Boolean operators such as “AND/OR” and various combinations of these keywords. As shown in Fig. 3 , initially, a total of 1149 studies were identified.
3.2. Study selection
We defined clear and transparent inclusion and exclusion criteria as follows. Inclusion criteria: (1) Studies involving the implementation of FL in the healthcare domain; (2) Studies that, while not explicitly focused on healthcare applications, involve or utilize healthcare data or scenarios in their experiments; (3) Studies on the design or optimization of FL frameworks/workflows that cover the healthcare domain; (4) Studies in English language. Exclusion criteria: (1) Duplicate studies; (2) Studies such as surveys, reviews, opinions, editorial letters, book chapters, and theses; (3) Studies unrelated to FL or those using FL for non-healthcare applications; (4) Non-English language studies.
Based on the above criteria, the screening procedure was conducted independently by two groups of authors (Group A: M.L. and P.X.; Group B: J.H. and Z.T.) to eliminate bias and ambiguity. Two groups confirmed the selected studies and resolved any conflicts or inconsistencies through discussion between the groups. The study selection process is outlined in Fig. 3 . Initially, a total of 43 duplicate studies were removed. Subsequently, the titles and abstracts were carefully screened, leading to the exclusion of 402 unqualified and irrelevant studies. Next, the eligibility of the remaining 704 studies was assessed through full-text screening. Finally, after further evaluation, 597 studies were deemed ineligible, and 107 studies were included in our final review.

    Download: Download high-res image (131KB)
    Download: Download full-size image 

Fig. 3 . PRISMA flow diagram for our review, highlighting the inclusion and exclusion of studies at each stage.
4. Results
4.1. Application and data
Included studies explored a broad range of healthcare specialties, including general medicine ( Sheller et al., 2020 ), cardiology ( Linardos et al., 2022 ), oncology ( Chakravarty et al., 2021 ), ophthalmology ( Liu et al., 2021b ), drug discovery ( Melody Project, 2024 ), multiomics ( Zhou et al., 2024a ), dermatology ( Haggenmüller et al., 2024 ), and radiology ( Malik et al., 2023 ). Most studies focused on tasks such as classification (67/107), segmentation (20/107), and detection (8/107), with additional applications in regression ( Sadilek et al., 2021 ), clustering ( Zhou et al., 2024a ), reconstruction ( Yan et al., 2024 , Zou et al., 2023 ), feature selection ( Sun et al., 2021b , Lu et al., 2022a ), data synthesis ( Wang et al., 2023a , Dalmaz et al., 2024 , Jin and Li, 2023 ), and biomedical language process ( Peng et al., 2024 ). In terms of data types , medical imaging , including MRI, CT, and X-rays, was the most frequently used (55/107), followed by clinical data and electronic health records (EHR) (24/107), skin images (6/107), retinal images (6/107), histopathology slides (16/107), multiomics data (3/107), and biomedical language data (1/107). Some studies involved multiple data types, while 8 studies did not specify the type of data used or used non-healthcare data ( Tian et al., 2023 , Li et al., 2022a , Wang et al., 2023b ).

Table 1 . Key results of included studies.
Item	Characteristics	Number of study	Examples
Cohort size	≤ 100
100 − 1000
≥ 1000
Unavailable	6
9
24
68	Kumar et al., 2021 , Kalapaaking et al., 2022 and Che et al. (2022)
Sheller et al., 2019 , Sheller et al., 2020 and Ogier du Terrail et al. (2023)
Dayan et al., 2021 , Sadilek et al., 2021 and FeTS-AI (2024)
Zhang et al., 2023a , Madni et al., 2023 and Yan et al. (2024)
Task	Classification
Segmentation
Detection
Others	74
22
8
10	Gong et al., 2021 , Ogier du Terrail et al., 2022 and Zhang et al. (2024)
Souza et al., 2021 , Tedeschini et al., 2022 and Lin et al. (2023)
Nguyen et al., 2021 , Alam and Rahmani, 2023 and Baheti et al. (2020)
Sadilek et al., 2021 , Zhou et al., 2024a and Zou et al. (2023)
Data type	Medical imaging (MRI, CT, X-rays)
Clinical and EHR
Skin images
Retinal images
Histopathology slides
Multiomics
Biomedical language
Unavailable or non-healthcare	55
24
6
6
16
3
1
8	Zhang et al., 2021 , Sheller et al., 2020 and Dayan et al. (2021)
Sakib et al., 2021 , Kerkouche et al., 2021 and Soltan et al. (2024)
Zhang et al., 2023a , Lian et al., 2022 and Zhang et al. (2022)
Hatamizadeh et al., 2023 , Lian et al., 2022 and Lin et al. (2023)
Saldanha et al., 2022 , Truhn et al., 2024 and Jiang et al. (2022)
Zhou et al., 2024a , Warnat-Herresthal et al., 2021 and Froelicher et al. (2021)
Peng et al. (2024)
Repetto and La Torre, 2022 , Wang et al., 2023b and Li et al. (2022a)
Number of clients	≤ 10
10 − 50
≥ 50
Unavailable	57
17
6
27	Ogier du Terrail et al., 2023 , NVIDIA, 2020 and Melody Project (2024)
Sheller et al., 2019 , Dayan et al., 2021 and Helmholtz Association (2024)
Kerkouche et al., 2021 , Repetto and La Torre, 2022 and Balkus et al. (2022)
Kalapaaking et al., 2023 , Salim et al., 2024 and Wang et al. (2023b)
Topology	Centralized
Decentralized	95
12	Gong et al., 2021 , Ogier du Terrail et al., 2022 and Yan et al. (2024)
Rehman et al., 2022 , Chang et al., 2021 and Tian et al. (2023)
Type of federation	Cross-Silo
Cross-Device
Unavailable	98
7
2	Bercea et al., 2021 , Zou et al., 2023 and Lin et al. (2023)
Chang et al., 2021 , Rehman et al., 2022 and Chen et al. (2020b)
Wang et al. (2023b) and Salim et al. (2024)
Scenario	Deployment
Simulation	10
97	Mullie et al., 2024 , Roth et al., 2022 and Cremonesi et al. (2023)
Chen et al., 2020a , Li et al., 2021b and Zhang et al. (2022)
Framework	Custom-designed
Open-source options
Unavailable	78
13
16	Li et al., 2021b , Chen et al., 2020a and Sav et al. (2022)
European Lung Foundation, 2024 , Dayan et al., 2021 and Roth et al. (2022)
Madni et al., 2023 , Zhang et al., 2022 and Bey et al. (2020)
Data curation	Standardization & Harmonization
Unavailable	12
95	Ogier du Terrail et al., 2023 , Truhn et al., 2024 and Kumar et al. (2021)
Zhang et al., 2023a , Rehman et al., 2024 and Lakhan et al. (2024)
Data partition	HFL
VFL
FTL
Unavailable	94
3
1
12	Zhou et al., 2024b , Yaqoob et al., 2023 and Feng et al. (2024)
Liu et al., 2022 , Che et al., 2022 and Yan et al. (2024)
Chen et al. (2020b)
Wang et al., 2023a , Andreux et al., 2020a and Lu et al. (2022a)
Natural split
Simulate
Unavailable	37
67
3	Chang et al., 2021 , Tong et al., 2022 and Zou et al. (2023)
Zhou et al., 2024d , Peng et al., 2024 and Lakhan et al. (2024)
Mateus et al., 2024 , Roth et al., 2022 and Helmholtz Association (2024)
Train/Test/Val details per client	17	Peng et al., 2024 , Feng et al., 2024 and Mazher et al. (2024)
Holdout cohort for evaluation	12	Zhang et al., 2023a , Zou et al., 2023 and Truhn et al. (2024)
Model	Deep learning
Traditional machine learning
Unavailable	83
7
17	Mullie et al., 2024 , Cremonesi et al., 2023 and Alam and Rahmani (2023)
Ogier du Terrail et al., 2023 , Sadilek et al., 2021 and Soltan et al. (2024)
Ma et al., 2021b , European Lung Foundation, 2024 and Roth et al. (2022)
Initialization: Random
Initialization: Pretrained/Foundation models
Unavailable	18
5
84	Ogier du Terrail et al., 2023 , Liu et al., 2022 and Hatamizadeh et al. (2023)
Li and Yang, 2024 , Haggenmüller et al., 2024 and Peng et al. (2024)
Wang et al., 2022 , Sav et al., 2022 and Zhang et al. (2024)
Optimization	System heterogeneity	0	–
Generalization in open domain	15	Ogier du Terrail et al., 2023 , Liu et al., 2022 and Haggenmüller et al. (2024)
Communication efficiency	19	Kerkouche et al., 2021 , Li and Yang, 2023 and Qu et al. (2022)
Theoretical convergence analysis	0	–
Temporal data dynamics	2	Alam and Rahmani (2023) and Liu et al. (2022)
Synchronous aggregation
Asynchronous aggregation	92
15	Nguyen et al., 2021 , Kumar et al., 2021 and Saldanha et al. (2022)
Zhou et al., 2024a , Haggenmüller et al., 2024 and Malik et al. (2023)
Privacy and security	Model updates protection	41	Nguyen et al., 2021 , Xie et al., 2024 and Zhang et al. (2022)
Open source	Code available
Trained model available
Unavailable	29
1
78	Gong et al., 2021 , Ogier du Terrail et al., 2022 and Hatamizadeh et al. (2023)
Dayan et al. (2021)
Li et al., 2022e , Kalapaaking et al., 2022 and Qu et al. (2022)
4.2. Topology, scenario and framework
The centralized FL paradigm dominates current implementations, with 95 out of 107 studies following this topology. Only 10 studies reported real-world deployments in distributed clinical settings, while the rest remained in the realm of prototypes or simulations. In terms of frameworks, the majority (78/107) utilized custom-designed FL frameworks, while a smaller number (13/107) employed open-source options such as Flower ( European Lung Foundation, 2024 ), Flare ( Dayan et al., 2021 , Roth et al., 2022 , NVIDIA, 2020 ), SubstraFL ( Ogier du Terrail et al., 2023 , Melody Project, 2024 ), TFF ( Sadilek et al., 2021 ), OpenFL ( FeTS-AI, 2024 ), PySyft ( Malik et al., 2023 , Kalapaaking et al., 2022 , Gawali et al., 2021 , Truhn et al., 2024 ), and FedBioMed ( Cremonesi et al., 2023 ). 16 studies did not specify the framework used. Further details about open-source frameworks can be found in Table 2 .
4.3. Data curation and partition
Among the reviewed studies, only 12 provided details on the processes of data standardization and harmonization. Regarding data partition, HFL was the predominant approach, with 94 out of 107 studies focusing solely on it. In contrast, VFL was explored in only 3 studies ( Yan et al., 2024 , Liu et al., 2022 , Che et al., 2022 ), while 2 studies considered both HFL and VFL in combination ( Liu et al., 2022 , Che et al., 2022 ). Only 1 study discussed FTL ( Chen et al., 2020b ). Notably, 12 studies did not mention this aspect at all. The majority of studies addressed only one type of data heterogeneity , such as quantity skew or label skew, without considering multiple factors simultaneously. Moreover, 37 studies employed natural data splits for training and/or evaluation, while the rest relied on artificial splits. Only 17 studies detailed their training, testing or validation sets and 12 studies split a holdout cohort for evaluation.
4.4. Model
Among reviewed studies, Convolutional Neural Networks (CNNs) were the most commonly utilized (80/107), including both custom models specifically designed for healthcare tasks and well-established architectures like ResNet , DenseNet , MobileNet, and U-Net ( Li et al., 2022e , Kalapaaking et al., 2022 , Qu et al., 2022 ). Additionally, Recurrent Neural Networks (RNNs) have been incorporated to leverage their strengths in handling complex healthcare data ( Che et al., 2022 , Alam and Rahmani, 2023 , Paragliola and Coronato, 2022 ). Some studies also employed custom Multi-Layer Perceptrons (MLPs) and attention mechanisms to further boost model performance ( Repetto and La Torre, 2022 , Kandati and Gadekallu, 2022 , Kerkouche et al., 2021 ). Peng et al. (2024) utilized large language models for distributed biomedical natural language processing . Beyond deep learning approaches, several studies explored traditional machine learning (ML) algorithms, including linear models and ensemble methods . Notable examples include logistic regression ( Repetto and La Torre, 2022 ), support vector machines ( Bey et al., 2020 ), fuzzy clustering ( Brisimi et al., 2018 ), and decision trees ( Balkus et al., 2022 , Aminifar et al., 2022 ). Interestingly, only 23 studies explicitly discussed their initialization strategies for model training. Among these, the majority opted for random initialization, while a mere five clearly stated that they utilized pretrained or foundation models as their starting point ( Li and Yang, 2024 , Adnan et al., 2022 , Haggenmüller et al., 2024 , Linardos et al., 2022 , Peng et al., 2024 ).
4.5. Optimization
Most studies addressed either data or model heterogeneity, and none of them considered system heterogeneity . Only 15 studies evaluated model generalization ability in unseen open domains. A total of 19 studies focused on improving communication efficiency, employing techniques such as knowledge distillation ( Gong et al., 2021 , Xie et al., 2024 , Li and Yang, 2024 ), gradient quantization ( Kerkouche et al., 2021 ), one-shot FL ( Qu et al., 2022 ), split learning ( Gawali et al., 2021 ), and tensor factorization ( Ma et al., 2021b , Ma et al., 2021a ). In terms of convergence analysis , a few studies (21/107) reported metrics such as communication rounds and costs, as well as overall convergence time, but none provided a theoretical understanding of convergence dynamics. Only two studies considered temporal data dynamics in model learning ( Liu et al., 2022 , Alam and Rahmani, 2023 ). Regarding synchronization, 15 studies employed asynchronous aggregation instead of synchronous aggregation, particularly in applications involving wearables ( Chang et al., 2021 ) and IoMT devices ( Alam and Rahmani, 2023 ).
4.6. Privacy and security
Only 41 studies addressed the exchange of model updates with privacy guarantees. The most commonly used techniques for safeguarding model updates included Differential Privacy (DP), Homomorphic Encryption (HE), Secure Multi-Party Computation (SMPC), knowledge distillation, and partial model exchange. However, metadata such as sample sizes and distributions were frequently shared without protection, particularly in methods based on FedAvg ( Adnan et al., 2022 , Ziller et al., 2021 ). To mitigate the risk of adversaries inferring raw data, synthetic data was employed in some cases ( Nguyen et al., 2021 , Qu et al., 2022 , Jin and Li, 2023 , Rehman et al., 2024 ). Additionally, swarm learning and blockchain were utilized to secure the communication process ( Saldanha et al., 2022 , Nguyen et al., 2021 ).
4.7. Fairness and incentive
Only three studies have discussed issues related to fairness and/or incentives in healthcare FL ( Hosseini et al., 2023 , Li et al., 2022a , Zhang et al., 2024 ), with just one of these studies specifically exploring the complexities of both fairness and incentives in detail ( Zhang et al., 2024 ).
In the context of FL for healthcare, fairness generally refers to the equitable distribution of model performance among participants, ensuring that no entity is disadvantaged. Incentives are mechanisms designed to motivate healthcare institutions to participate in federated networks , often by offering rewards for contributions such as high-quality data or computational resources . For a more comprehensive discussion of fairness and incentive in healthcare FL, we refer readers to Section 5.6 , where these concepts are explored in greater detail.
4.8. Evaluation
Most studies used conventional ML metrics for evaluation, such as accuracy, precision, area under the receiver operating characteristic curve (AUC), sensitivity/recall, specificity, F1-score, Dice score, Intersection over Union (IoU), Hausdorff Distance (HD), and loss value. Additionally, many studies performed comparisons against classical centralized models or localized models, and conducted ablation studies. However, only a few studies (26/107) addressed critical aspects unique to FL, such as communication overhead , resource consumption, scalability, generalization, privacy, fairness, and security concerns. As for benchmarking, just one study provided relatively comprehensive benchmarks across multiple healthcare datasets ( Ogier du Terrail et al., 2022 ). Interpretability was explored in seven studies, either through feature selection ( Soltan et al., 2024 , Sun et al., 2021b ), attention maps ( Lu et al., 2022a , Gong et al., 2021 , Truhn et al., 2024 ), or tree-based models ( Ogier du Terrail et al., 2023 , Sadilek et al., 2021 ). While 29 studies released their source code, only one also made the trained model publicly available ( Dayan et al., 2021 ).
We provide a more detailed summary of the key results in Table 1 .

    Download: Download high-res image (1MB)
    Download: Download full-size image 

Fig. 4 . Taxonomy of challenges and pitfalls (red blocks) as well as recommended solutions and opportunities (green blocks).
5. From challenges and pitfalls to recommended solutions and future opportunities
After a thorough review of the most recent and advanced FL studies, we find various challenges and pitfalls that still limit the implementation of FL in healthcare. In this section, we introduce a clear taxonomy, as depicted in Fig. 4 , focusing on the challenges and pitfalls, and further providing recommended solutions and opportunities. We adhere to the best practice workflow in FL for discussion in the following subsections.

    Download: Download high-res image (250KB)
    Download: Download full-size image 

Fig. 5 . Simulation scenario VS. real-world distributed scenario.
5.1. Scenario and framework
5.1.1. Domination of simulation studies
The majority of existing studies have been confined to simulation environments, with only 10 studies incorporating real-world distributed clinical scenarios. This indicates that the application of FL in healthcare is still in its nascent stage. The complexity of deploying FL across a real-world network of hospitals and institutions has significantly hindered its progress. Most studies have operated within controlled, simulated settings where data is pooled and then artificially partitioned to represent distributed environments. The simulated clients interact with a simulated server, coordinating model updates in a manner that is highly controlled and predictable. In contrast, real-world scenarios involve each client working with inherently distributed, heterogeneous, and locale-specific data. The interaction between real server and clients is far more complex, requiring secure protocols, real-time communication, and the ability to handle diverse datasets across various institutions. This disparity between simulation and real-world environments is illustrated in Fig. 5 .
Moreover, very few studies have explored FL practices at a national or international scale ( Dayan et al., 2021 , Soltan et al., 2024 ). Notable examples include the Collaborative Data Analysis (CODA) ( Mullie et al., 2024 , Melody Project, 2024 ), HealthChain ( Healthchain Consortium, 2024 ) and DRAGON ( European Lung Foundation, 2024 ). CODA tested FL’s feasibility across eight hospitals in Canada by enrolling patients with suspected or confirmed COVID-19 over three years. Melody deployed multi-task FL among 10 pharmaceutical companies to optimize the drug discovery process. HealthChain and DRAGON implemented FL across multiple hospitals in Europe, facilitating the prediction of treatment responses for cancer and COVID-19 patients.
Despite these rare promising examples, the majority of FL studies remain proof-of-concept and the broader deployment of FL in healthcare remains largely undocumented. There is still a lack of clarity on how FL nodes are set up within individual hospitals, the methods for delivering local models to these nodes, the protocols enabling interaction between nodes and aggregators, and the mechanisms triggering new training rounds, etc.
Recommendations & opportunities .

    •
    For researchers , it is recommended to continue leveraging simulation environments to rapidly prototype and evaluate FL algorithms. Simulations offer precise control over experimental conditions, which is essential for understanding the underlying mechanics of FL and its behavior under various scenarios. However, researchers should acknowledge the limitations of simulations and anticipate the challenges that real-world deployments may introduce. Beyond simulations, to enhance data diversity, collaboration and generalization, efforts should be made to implement FL at a national and international scale, with cloud computing offering scalable resources and seamless implementation across institutions.
    •
    For clinicians interested in applying FL to enhance clinical diagnostics and prognostics, it is crucial to comprehend both the potential benefits and limitations of FL. Clinicians should collaborate closely with researchers and engineers to identify promising use cases for FL in clinical practice. This may involve conducting pilot studies to assess the feasibility and effectiveness of FL in specific clinical scenarios. Clinicians should advocate for the integration of FL into existing healthcare workflows to ensure a seamless transition from research to practice. Additionally, their feedback on the usability and impact of FL systems is vital for guiding further refinements.
    •
    For engineers , the focus should be on addressing the practical challenges of FL deployment in real-world settings. This includes ensuring the interoperability of different hospital systems, safeguarding data privacy and security, and managing the communication overhead of networks. Engineers should aim to develop robust and scalable solutions adaptable to the heterogeneous IT infrastructures across healthcare institutions . Close collaboration with clinicians and researchers is essential to ensure that FL systems meet healthcare-specific needs and comply with regulatory standards.

Table 2 . Capabilities and features of current popular FL frameworks.
Framework	Developer	Secure
aggregation	Communication
efficiency	Healthcare
adaptation	Traceability	Deployment	Foundation
model	Scalability	Clound
friendly
Flare ( Roth et al., 2022 )	Nvidia	DP, HE	–	–	✓	✓	✓	✓	✓
FedML ( He et al., 2020 )	TensorOpera	DP, HE	✓	–	✓	✓	✓	✓	✓
FederatedScope ( Xie et al., 2022 )	Alibaba	DP, SMPC	–	–	–	–	✓	–	–
Flower ( Beutel et al., 2022 )	FlowerLab	DP	–	–	✓	✓	✓	✓	✓
FATE ( Liu et al., 2021d )	WeBank	DP, HE, SMPC	–	–	✓	✓	✓	✓	✓
SubstraFL ( OWKIN, 2024 )	Owkin	DP, SMPC	–	✓	✓	✓	–	✓	✓
PySyft ( Ryffel et al., 2018 )	OpenMined	DP	–	–	–	–	–	–	–
OpenFL ( Foley et al., 2022 )	Intel	DP	–	–	–	✓	–	–	–
TFF ( Bonawitz et al., 2019 )	Google	DP	–	–	–	✓	–	–	–
Fed-BioMed ( Cremonesi et al., 2023 )	Inria	DP	–	✓	–	✓	–	–	–
IBM FL ( Ludwig et al., 2020 )	IBM	DP, SMPC	–	–	–	✓	–	–	–
PaddleFL ( Ma et al., 2019 )	Baidu	DP, SMPC	–	–	–	✓	–	–	–
SAFEFL ( Gehlhar et al., 2023 )	ENCRYPTO	SMPC	–	–	–	–	–	–	–
5.1.2. Deficiency in FL frameworks development and usage
Most studies developed their own FL frameworks, often not strictly aligning with standard FL protocols, particularly when confined to single machine simulation studies. Meanwhile, some simulation studies used industrial-grade frameworks, which introduce unnecessary complexity and resource demands for simulation and prototype research. Some other studies utilized lightweight open-source FL frameworks, although prevalent, frequently lack healthcare-specific adaptations, leading to deficiencies in privacy, security, and regulatory compliance. Common shortcomings across current FL frameworks include a lack of healthcare adaptations, as most frameworks are not tailored to meet healthcare-specific requirements, which include stringent privacy, security, and regulatory standards. Additionally, many frameworks do not address the need for communication efficiency, which is essential for the practical deployment of FL in resource-constrained environments. Limited support for traceability also hinders accountability and transparency in FL. Furthermore, while some frameworks offer scalability and cloud compatibility, many do not, which can limit their ability to handle large-scale healthcare data and integrate with existing cloud infrastructures. Here, we inventory the most popular FL frameworks in Table 2 , with emphasis on those adapted for healthcare, and outline their features.
Recommendations & opportunities .

    •
    For researchers aiming to swiftly prototype and test novel concepts can benefit from frameworks that incorporate comprehensive simulator modules. These tools allow for the rapid iteration and validation of ideas within a controlled simulation environment, which can be critical for the initial stages of research and development.
    •
    For engineers seeking to deploy FL in real-world scenarios should consider frameworks tailored to the specific needs of the healthcare domain. These frameworks should offer healthcare specific adaptations to ensure compatibility with medical data formats , regulatory compliance, and the unique challenges of healthcare data analysis.
    •
    Users facing computational constraints are encouraged to explore cloud-friendly frameworks that leverage cloud computing services such as Azure and AWS. These platforms can alleviate the burden of substantial computational demands and the complexities of local infrastructure development. Moreover, cloud computing can significantly mitigate the risk of network issues that may arise from client-hosted infrastructures with varying capabilities.
    •
    More specifically, we propose the following suggestions for FL framework selection, usage, and development:
        –
        Secure Communication: The integrity of the FL system hinges on secure communication protocols, where encryption should be employed ( Li et al., 2023b ).
        –
        Flexible Deployment: To streamline the deployment process , FL frameworks should support secure, reliable, and flexible deployment methods. They should integrate seamlessly with existing IT and data science infrastructures, facilitating a routine and uneventful deployment experience ( Lo et al., 2022 ).
        –
        Data Science Workflow Support: Given the necessity for diverse data providers to achieve robust FL outcomes , frameworks should support a comprehensive data science workflow. The ideal framework should be agnostic to both the model and the data, accommodating a wide range of data types and analytical methods ( Cremonesi et al., 2023 ).
        –
        Scalability: Scalability is a key consideration for FL frameworks, which must accommodate an increasing number of participants and the corresponding complexity. Addressing scalability challenges, particularly with privacy-enhancing technologies such as synthetic data or HE , is crucial for the long-term viability of FL initiatives ( Lai et al., 2022 ).
        –
        Future-proofing: FL frameworks should be designed with future-proofing in mind, anticipating emerging use cases, evolving security threats, and new privacy concerns. It should facilitate the dynamic participation of data providers, adapt computational resources to fluctuating client numbers, and implement regular system updates to address privacy and security challenges ( Lo et al., 2022 ).

5.2. Data
5.2.1. Unclear in data standardization and harmonization
Healthcare data are often collected and stored in diverse and proprietary formats that do not always adhere to international standards and terminologies, complicating data linkage and reuse. For example, structured clinical data usually contains features that vary with differences in clinical practice across institutions ( Petersmann et al., 2019 ), such as diabetes diagnosis, which can involve different glucose measurement methods with varying cut-off points, resulting in hidden heterogeneity that may be overlooked in subsequent statistical analyses. Additionally, language differences across institutions, especially in multilingual regions like the European Union, pose additional challenges in standardizing and harmonizing data. Medical terminology and clinical reports may be documented in different languages, complicating data interpretation and analysis across borders. A crucial step before implementing FL in healthcare is to ensure data standardization , harmonization, and interoperability across different cohorts, which are key to the success of FL ( Fig. 6 ).
Most simulation studies processed data centrally and generate artificially partitioned datasets without considering the distributed nature of various data silos. This oversight extends to the lack of discussion on how datasets at each client are curated for use in experiments. Despite this, almost all FL frameworks assume the input data is preformatted for model training or preprocessing pipelines. This assumption leads to significant frustration and delays, as the burden of data export and conversion typically falls on clinical data managers who may lack the necessary budget and training. Moreover, among the included studies, only two performed quality or integrity checks on the data. Gad and Fadlullah (2022) excluded samples with impossible values (e.g., negative heart rates) and inconsistent feature values, while Shaik et al. (2022) used Principal Component Analysis to filter out noise. Few studies addressed structural or informative missingness, with only Alam and Rahmani (2023) and Sun et al. (2021b) considering imputation methods while also deleting features with high missingness rates. Poor quality imputation and handling of non-random missingness can bias model training. Additionally, no studies considered language differences in medical terminology and clinical reports across borders.
Recommendations & opportunities .

    •
    Adopt Standardized Formats: Data standardization, harmonization, and interoperability across clients can be facilitated through formats such as Fast Healthcare Interoperability Resources (FHIR) for electronic health records (EHR) data and Digital Imaging and Communications in Medicine (DICOM) for imaging data.
    •
    Simplify Data Preparation: FL frameworks targeting healthcare research must simplify data preparation and ensure interoperability with standard data formats. This approach eases the burden on clinical data managers and improves data reusability.
    •
    Use Consistent Protocols: Collaborating clients must use consistent preprocessing protocols to standardize data to a Common Data Model (CDM) such as the Observational Medical Outcomes Partnership (OMOP) ( Lee et al., 2023 ). Harmonizing healthcare data to a CDM like OMOP ensures it is interoperable with other clinical datasets, enabling effective merging and analysis across distributed sources and platforms ( Mateus et al., 2024 ).
    •
    Automate Data Pipelines: Extraction, transformation, and loading pipelines that automate the conversion of raw data to analysis-ready/training-ready data are needed to further simplify data standardization and harmonization.
    •
    Ensure Secure Access: Secure access to fully standardized, harmonized, and interoperable large datasets through encryption methods can significantly accelerate clinical research within the federation.
    •
    Address Language Differences: In multilingual regions like the European Union, language differences in medical terminology can hinder data interpretation. Translation and normalization techniques, along with Large Language Models (LLMs), can assist in automatic translation and ensuring consistent terminology, thereby improving data interoperability for FL applications.

    Download: Download high-res image (172KB)
    Download: Download full-size image 

Fig. 6 . Illustration of Data Standardization and Harmonization. Multi-site T1-weighted MRI images from different scanners (GE, Philips, Siemens) exhibit variability in intensity distributions. The standardization process adjusts individual distributions to a common scale, while harmonization ensures alignment across datasets for improved consistency ( Liu and Yap, 2024 ).
5.2.2. Issues in data partition
Among all included studies, only a few leveraged natural splits to replicate data collection processes across different hospitals or institutions. For instance, Chakravarty et al. (2021) employed the CheXpert dataset, Kaissis et al. (2021) worked with the chest X-ray dataset and Lu et al. (2022a) extracted metadata from Tissue Source sites in the TCGA dataset for their studies. These datasets naturally reflect the heterogeneity found in real-world clinical data across hospitals and institutions, making them more suitable for FL studies in healthcare ( Andreux et al., 2020b , Baheti et al., 2020 ).
Simulation studies typically used heuristics to artificially create heterogeneous data partitions from a pooled dataset, assigning these partitions to simulated clients, as illustrated in Fig. 5 . Common synthetic partitioning methods for classification tasks include assigning samples from a limited number of classes to each client, using Dirichlet distribution sampling on class labels, and employing the Pachinko Allocation Method (PAM) when labels have a hierarchical structure ( McMahan et al., 2017 ). For regression tasks , Gaussian Mixture clustering based on t-SNE feature representations has been used to partition datasets among clients ( Philippenko and Dieuleveut, 2020 ).
Nonetheless, synthetic partitioning methods may not accurately reflect the intricate heterogeneity found in real-world scenarios ( Andreux et al., 2020a ). Examples from digital histopathology illustrate the limitations of synthetic partitioning methods ( Chen et al., 2024 ). In digital histopathology, tissue samples are extracted, stained, and digitized, leading to data heterogeneity due to factors such as patient demographics, staining techniques , physical slide storage methods, and digitization processes . Although advancements in staining normalization have reduced some heterogeneity, other sources remain challenging to replicate synthetically, and some may even be unknown ( Howard et al., 2021 ). These underscore the necessity of conducting cohort experiments with natural splits to ensure that FL models are robust across varied clinical settings. This issue also extends to other areas, including radiology, dermatology, and retinal image analysis.
Even among studies that adopted synthetic partitioning methods, the strategies employed are often limited, primarily focusing on scenarios such as quantity skew. These studies addressed only a narrow aspect of heterogeneity. For instance, label skew, where the distribution of labels differs across clients, and feature skew, where clients have different feature distributions, are frequently overlooked. As a result, the synthetic partitions created in these studies may not adequately represent the complex and varied heterogeneous conditions, potentially leading to less robustness in diverse healthcare environments. In Section 5.4.1 , we provide a comprehensive discussion of various types of skew and heterogeneity.
Another significant issue is the lack of clear definitions and descriptions for train and test set partitions across clients in many studies. Among the studies included in this review, 84% did not explicitly define how these partitions are handled for each client, leading to potential ambiguity in evaluating model performance. This concern is particularly critical in the context of personalized FL, where each client’s test set should be unique to accurately reflect individual data distributions .
Recommendations & opportunities .

    •
    Complement Simulation Studies with Real-World Data Evaluations: While simulation studies using artificially partitioned datasets can provide valuable insights, it is essential to validate these findings through evaluations on real-world, naturally partitioned datasets. This multi-stage evaluation process ensures that models are tested in both controlled environments and realistic deployment scenarios , improving their generalizability and robustness ( Kairouz et al., 2021 ).
    •
    Adaptive Partitioning Based on Data Distribution: Researchers should consider using adaptive partitioning techniques that account for the underlying data distribution and specific characteristics of each client’s data. This can create more realistic and representative partitions, especially in scenarios where data is highly heterogeneous.
    •
    Incorporate Multiple Types of Skew: Researchers should broaden the scope of their synthetic partitioning strategies to include not just quantity skew but also label skew and feature skew. This would create a more realistic representation of the heterogeneity found in real-world datasets, allowing FL models to be more robust and generalizable across diverse clinical settings ( Li et al., 2022c ).
    •
    Retaining Client-Specific Test Sets: Consider the non-IID nature of data in FL, we suggest that researchers retain a portion of data within each client as a dedicated test set rather than relying on a single, global test set for all clients. This approach provides a more accurate and reliable evaluation, reflecting the unique data distributions of each client, which is particularly important in personalized FL scenarios ( Kairouz et al., 2021 ).
    •
    Incorporation of Domain Knowledge: Incorporate domain knowledge into the partitioning process can enhance the relevance of synthetic data splits. In medical imaging , for example, understanding the clinical context and variability in imaging protocols across different institutions can inform more meaningful data partitioning strategies.
    •
    Transparency and Reproducibility: Researchers should provide detailed documentation of their data partitioning strategies, including the rationale behind their choices and any domain-specific considerations. This transparency will enable others to replicate and build upon their work effectively.

5.3. Model
5.3.1. Inadequate model selection and development
The studies reviewed exhibit a wide range of model complexities, from advanced, parameter-heavy architectures to traditional ML techniques . However, several issues persist in model selection and development. Firstly , there is an over-reliance on complex models, particularly CNNs , which dominate due to their high performance but pose challenges in resource-constrained healthcare environments. Their complexity complicates reproducibility and generalizability across different settings, particularly when custom architectures are involved. Secondly , the lack of standardization in model selection leads to variability in methodologies, making it difficult to compare results across studies and generalize findings. This inconsistency hampers the ability to benchmark performance across different FL applications. Moreover , simpler and more interpretable models are underutilized. While deep learning models offer high performance, traditional ML algorithms , which are easier to interpret and less resource-intensive, are often overlooked. These models could be more suitable for certain healthcare applications where interpretability and transparency are critical for clinical decision-making, offering a practical alternative that balances performance with the need for clarity and trustworthiness in healthcare settings. Another challenge is the limited focus on personalization. Many studies prioritized a single global model, which may not be optimal for all clients due to the heterogeneity in healthcare data. Personalized FL approaches , tailored to individual client data distributions, remain underdeveloped and require further research. Lastly , scalability concerns arise with complex models, particularly in large-scale healthcare networks. The communication and computational overhead of training such models can become prohibitive, highlighting the need for more scalable FL solutions to ensure practical deployment.
Recommendations & opportunities .

    •
    Standardization for Research and Benchmarking: Standardizing the process of model selection and development is essential for FL research, particularly in benchmarking and comparative studies. This standardization does not aim to limit innovation but to provide a consistent framework for evaluating models across diverse FL applications an settings. For instance, establishing shared protocols for selecting baseline models , defining performance metrics, and validating results can significantly enhance reproducibility and comparability. Such a framework encourages innovations that are both rigorous and generalizable, enabling the development of practical solutions tailored to the unique challenges of FL, such as data heterogeneity and resource constraints ( Ogier du Terrail et al., 2022 ).
    •
    Exploring Simpler, More Interpretable Models: Researchers should not overlook simpler, traditional ML models, particularly in scenarios where interpretability is crucial. These models can be more practical and equally effective in certain healthcare applications, providing a balance between performance and interpretability ( Argente-Garrido et al., 2024 , Li et al., 2023a ). Researchers should also consider developing simpler and lightweight models that can be deployed in resource-constrained environments without sacrificing performance.
    •
    Enhancing Personalization in FL: More work is needed to develop and refine personalized FL approaches that can adapt to the diverse data distributions encountered in healthcare. This could involve hybrid models that combine the strengths of both global and local models, as well as more sophisticated techniques for model adaptation ( Zhang et al., 2023a ).
    •
    Addressing Model Heterogeneity: Given the diverse requirements and constraints across different institutions, it is crucial to develop FL strategies that can effectively manage model heterogeneity. This includes exploring federated ensemble learning methods, which allow the aggregation of heterogeneous models and can lead to more robust and accurate predictions ( Mabrouk et al., 2023 ).
    •
    Improving Scalability and Efficiency: Future studies should prioritize the design of scalable FL models that can handle an increasing number of clients without excessive computational and communication costs. This could involve the development of more efficient algorithms and the use of federated distillation techniques to reduce model size and complexity ( Ullah et al., 2023 ).

5.3.2. Negligence in initialization
Most of the included studies began federated training from a random initialization, a method that, while effective in IID scenarios, can be less optimal for handling non-IID data. In healthcare, where data distribution often varies significantly across institutions due to differences in patient demographics, clinical practices, or data collection methods, random initialization can lead to slower convergence, increased communication costs, and potentially suboptimal local optima ( Nguyen et al., 2023 , Chen et al., 2023 ).
A significant issue is the lack of standardization in model initialization approaches. Many studies either adopted random initialization without justification or entirely omitted the description of their initialization method . This inconsistency can result in significant variations in model performance and convergence rates, making it difficult to compare results across different studies and settings. Additionally, if the initial model is biased towards the data distribution of certain participants, it might not perform well across all clients, leading to fairness issues and suboptimal overall performance. Moreover, these challenges are further exacerbated by the heterogeneity of computational resources available across institutions. Some advanced initialization methods, such as those involving foundation models or pretraining on large-scale datasets, may be computationally expensive and thus infeasible for resource-constrained participants ( Nguyen et al., 2023 , Li and Yang, 2024 , Peng et al., 2024 ).
Personalization in model initialization is another underexplored area. Personalized initialization techniques, which tailor the starting point to the specific data distribution of each client, are critical for improving local model performance and accelerating convergence. However, research into these techniques, such as model-agnostic meta-learning and partial initialization for finding a good initialization, remains limited within FL for healthcare ( Fallah et al., 2020 , Sun et al., 2021a ).
Recommendations & opportunities .

    •
    Transfer Learning for Initialization: Utilize pretraining or foundation models for initialization can provide a strong starting point for FL. This approach has been shown to not only speed up convergence but also mitigate the effects of both data and system heterogeneity ( Li and Yang, 2024 , Peng et al., 2024 , Nguyen et al., 2023 ), potentially closing the performance gap between FL and centralized learning ( Chen et al., 2023 ). However, researchers should carefully consider the similarity between the source and target datasets to avoid negative transfer effects.
    •
    Personalized Initialization: Implement personalized initialization methods, such as model-agnostic meta-learning and partial initialization, can help customize the starting point of the model based on local data characteristics , further enhancing model performance on individual clients and improving overall system convergence ( Fallah et al., 2020 , Sun et al., 2021a ).
    •
    Standardization of Initialization Procedures : Standardizing initialization in FL is essential for ensuring consistency, reproducibility, and comparability across studies. It provides a common baseline for benchmarking and reduces variability in outcomes ( Chen et al., 2023 ). For example, Nguyen et al. (2023) showed that consistent initialization improves convergence rates, especially under non-IID data, while pretraining-based methods help address system heterogeneity ( Li and Yang, 2024 ). Such standardization does not hinder innovation but establishes a foundation for exploring advanced techniques like meta-learning and hybrid initialization, ensuring their broader applicability in diverse healthcare settings.
    •
    Consideration of Resource Constraints: When selecting initialization methods, researchers should account for the varying computational resources across participants. Techniques that balance initialization quality with computational feasibility, such as hierarchical model training or using lightweight pretrained models, are critical to ensuring broader applicability of FL in healthcare ( Li and Yang, 2024 , Peng et al., 2024 , Nguyen et al., 2023 ).

    Download: Download high-res image (217KB)
    Download: Download full-size image 

Fig. 7 . Drift issue in non-IID. In IID scenario, the global optima w ∗ aligns closely with the local optima w 1 ∗ and w 2 ∗ . Consequently, the aggregated model w t + 1 remains near the global optima. However, in non-IID scenario, the global optima w ∗ may be significantly distant from w 1 ∗ , leading to w t + 1 being far from the ideal solution.
5.4. Optimization
5.4.1. Heterogeneity issues
In FL for healthcare, heterogeneity refers to the variability in data, models, and systems across different hospitals and institutions. This variability poses significant challenges to FL’s performance and its ability to generalize well across diverse environments. The key types of heterogeneity in FL for healthcare include statistical heterogeneity , model heterogeneity , and system heterogeneity .
Statistical heterogeneity arises due to the non-IID nature of healthcare data across various institutions, which is characterized by demographic differences, instrumentation biases, distinct data acquisition protocols, and human operations, etc ( Guan and Liu, 2021 ). For instance, variations in CT scan quality across sites can lead to inconsistencies in the correlation between imaging data and corresponding site-specific EHR data. These inconsistencies severely degrade FL performance, with accuracy drops of up to 50% ( McMahan et al., 2017 ), necessitating additional communication rounds for convergence ( Chen et al., 2021 ). Statistical heterogeneity can also result in clients overfitting to their local data, leading to poor generalization on data from other clients, making simple parameter averaging an ineffective aggregation strategy ( Mora et al., 2024 ). Since local models are optimized towards different local optima, the aggregated global model may drift from the true global optima, causing a biased minimum and significantly slowing down convergence as illustrated in Fig. 7 . In healthcare, statistical heterogeneity can be broadly characterized by four forms, including:

    •
    Quantity Skew. The number of training samples differs greatly across clients, leading to imbalanced data distributions. Models tend to optimizing for clients with more data, potentially neglecting those with less, further reducing the generalization ability ( Li et al., 2022c ).
    •
    Label Skew. The distribution of labels varies across clients. For instance, in the context of COVID-19, hospitals in regions heavily impacted by the pandemic may have a higher proportion of positive cases, whereas other regions might have predominantly negative cases. This label imbalance can lead to biased models ( Ghassemi et al., 2020 ).
    •
    Feature Skew. Different clients may have access to different features for the same sample cohort. For example, some institutions might only have access to EHR data, while others may have additional imaging modalities like X-rays or MRIs ( Fallah et al., 2020 , Kline et al., 2022 ). This is especially common in VFL scenarios.
    •
    Quality Skew. This arises from varying data quality across clients, often due to issues like label noise, data acquisition noise, or processing discrepancies. Clients with high-quality, accurately labeled data contribute more effectively to model learning, while those with noisy or inaccurate labels can introduce errors, undermining the model’s generalization and convergence ( Wang et al., 2024a ).

Fig. 8 provides an illustration of these skew forms. Numerous studies have been focusing on one of these skews in healthcare. Qu et al. (2022) introduced a generative replay method by employing a VAE to synthesize medical images, enabling clients to train on a combined dataset of real and generated data, thus mitigating data quantity skew. Jiang et al. (2022) employed a frequency-based approach for medical data harmonization in FL, where images are processed in the frequency domain to retain local phase information and synchronize amplitudes across clients, thereby mitigating feature skew. Chen et al. (2024) leveraged a Dirichlet distribution for modeling categorical probabilities in medical data, applying uncertainty calibration and diversity relaxation to enhance label annotation by focusing on samples with high uncertainty and low similarity, thus reducing label quality skew.
Model heterogeneity occurs when different clients use varying model architectures due to differences in hardware capabilities, data types, or specific institutional requirements. For example, one hospital may use a complex deep learning model for image analysis, while another uses a simpler model due to computational constraints. This divergence complicates the process of aggregating model updates in FL, as different architectures may have different fitting capabilities, performance characteristics, and requirements for convergence ( Lin et al., 2020 ). To address model heterogeneity, approaches like knowledge distillation have been employed, where a “student” model is used to transfer knowledge from various “teacher” models in different clients ( Lin et al., 2020 ). However, these methods often require auxiliary public datasets for transferring knowledge, raising privacy concerns and increasing the computational burden on resource-constrained institutions ( Li and Wang, 2019 , Lin et al., 2020 ). An alternative approach is the use of a lightweight “messenger” model, as proposed by Xie et al. (2024) , which carries concentrated information from one client to another, reducing the need for a full model exchange. This method allows for efficient aggregation and distribution of knowledge without the overhead of auxiliary public datasets.

    Download: Download high-res image (510KB)
    Download: Download full-size image 

Fig. 8 . Illustration of different skew forms in statistical heterogeneity, including quantity, feature, label, and quality skew. Medical image sources: Chest X-rays ( NIH Clinical Center, 2017 ), CT scans ( Radiopaedia, 2021 ), Ultrasound images ( CREATIS, 2019 ), and Whole Slide Imaging (WSI) ( CAMELYON, 2017 ).
System heterogeneity refers to the differences in computational capabilities, network architectures , and resource availability across clients. For example, some hospitals may have advanced computing infrastructure, while others may have limited hardware resources. This variability may affect the efficiency of FL, particularly in aggregating models trained on non-IID data ( Li et al., 2022c , Mabrouk et al., 2023 ). Most studies have focused on addressing statistical or model heterogeneity, but system heterogeneity is equally important. Differences in hardware resources can lead to discrepancies in how models perform and converge across clients. Furthermore, the need for additional local computation and storage resources, as required by methods like knowledge distillation, can be a burden for institutions with limited resources ( Li and Yang, 2023 , Li and Wang, 2019 ).
Recommendations & opportunities .

    •
    Data Harmonization: Apply data harmonization techniques locally at each client site to minimize variability in data distributions and improve the consistency of FL models ( Jiang et al., 2022 , Yan et al., 2020 ).
    •
    Data Synthesis and Augmentation: Use data synthesis and augmentation techniques to generate additional data for underrepresented classes in the local data. Techniques such as GAN, VAE, and diffusion models can be leveraged to create synthetic data that preserves privacy while boosting model generalization.
    •
    Feature Alignment and Data Imputation: Use methods like feature alignment and data imputation during training to ensure models learn from consistent data across clients. For example, FedHealth ( Chen et al., 2020b ) demonstrated the ability to infer missing modalities in healthcare data through FTL.
    •
    Bias Checks and Corrections: Implement continuous monitoring for bias within and across clients throughout the FL process. Correct identified biases to prevent model performance degradation . For instance, Chen et al. (2024) utilized uncertainty calibration and diversity relaxation to dynamically correct annotations for high-uncertainty, low-similarity samples.
    •
    Advanced Optimization Techniques: Enhance FL robustness against client drift and heterogeneity by employing advanced optimization techniques such as FedProx ( Li et al., 2020c ), SCAFFOLD ( Karimireddy et al., 2020 ), and MOON ( Li et al., 2021 ).
    •
    Disentangled Representation Learning (RDL): Integrate DRL into federated models to disentangle underlying invariant factors, making models more robust to data heterogeneity across different institutions ( Bercea et al., 2021 , Luo et al., 2022 ).
    •
    Fine-Tuning and Personalization: Improve model performance on domain-specific tasks by fine-tuning models locally with client-specific data and annotations. Extend techniques from meta-learning and multi-task learning to support personalized or device-specific modeling in FL ( Fallah et al., 2020 ).
    •
    Comprehensive Heterogeneity Handling: Address the complex and multifaceted nature of data skew and heterogeneity more comprehensively. Real-world scenarios often involve intricate combinations of quantity, label, feature, and quality skew, along with system and model heterogeneity. Developing more robust and flexible methods to handle these diverse challenges will be crucial for improving FL’s effectiveness in healthcare.
    •
    Adaptive FL Frameworks: Future research should focus on developing more adaptive FL frameworks capable of accommodating a wide range of model architectures and system configurations. Examples of adaptive frameworks include FedAdapt ( Wu et al., 2022 ), which adjusted client participation and resource allocation based on system heterogeneity, and AutoFL ( Kim and Wu, 2021 ), which used AutoML techniques to dynamically configure FL processes. Adaptive frameworks can also be realized through dynamic client selection and hierarchical aggregation (e.g., Clustered FL Sattler et al., 2020 ) to balance data quality, system resources, and communication efficiency.

5.4.2. Open domain problem
A key challenge in healthcare FL is the poor generalization of models to open domains, where unseen data lies beyond the federation’s scope. A mere 14% of the included studies have validated their methods on such external data, underscoring a significant research gap. Current FL strategies predominantly focus on boosting performance within the federation, frequently overlooking the essential need for model adaptability to new, unseen environments.
Studies have shown that even slight differences in devices or acquisition protocols can result in a significant distribution shift, thereby reducing the model’s effectiveness when applied to new, unseen datasets. This issue is particularly acute in healthcare applications like diabetic retinopathy screening in fundus images, where the diversity of cameras and settings across different institutions can lead to poor model performance on external data. Liu et al. (2021b) addressed this challenge by introducing a frequency-based domain generalization approach in FL. They enabled privacy preserving exchange of distribution information across clients through continuous frequency space interpolation and designed a boundary-oriented episodic learning scheme to expose local training to domain shifts and enhance model generalizability in ambiguous boundary regions. However, the proposed method can be impractical for real-world applications due to its reliance on extensive network bandwidth and computational resources required for Fourier transform computation in frequency space interpolation.
Recommendations & opportunities .

    •
    Domain Generalization Techniques: These techniques aim to create models that are robust to distribution shifts by learning domain-invariant features. Methods such as data augmentation ( Zhou et al., 2024c ), which generates diverse augmented features of client data to improve model robustness, adversarial training ( Zhang et al., 2023b ), where domain-invariant representations are learned by minimizing domain discrimination, and meta-learning ( Liu et al., 2023a ), which optimizes for rapid adaptation to new domains, have been explored to improve the generalization capabilities of FL models to unseen domains.
    •
    Transfer Learning and Fine-Tuning: Apply transfer learning and fine-tuning on small amounts of unlabeled data from the open domain can help adapt the federated model to new environments ( Chen et al., 2020b ). Self-supervised learning techniques like contrastive learning can further facilitate this process ( Zou et al., 2023 ).
    •
    Ensemble Learning: Combine multiple models trained on different clients via sophisticated ensemble methods can enhance the robustness of the final prediction, making it more generalizable to open domains ( Lin et al., 2020 ).
    •
    Data Synthesis and Simulation: Generate synthetic data that mimics the characteristics of potential open domains can be used to pretrain or fine-tune the federated model, improving its generalization to unseen environments ( Liu et al., 2021b ).

5.4.3. Burdens in communication
Communication is a significant bottleneck in the implementation of FL in healthcare. In FL, each client needs to frequently communicate with the central server. This communication can be orders of magnitude slower than local computation due to constraints such as bandwidth, latency, and power ( Ma et al., 2021b ).
The communication bottleneck in FL arises from several factors. First , the number of clients involved in an FL system can be very large (e.g., wearables and IoMT), leading to significant communication overhead. Each communication round requires sending model updates between the clients and the central server, which can be expensive in terms of time and resources ( Ma et al., 2021b , McMahan et al., 2017 ). Second , ensuring data privacy and security in FL is crucial, especially in sensitive domains like healthcare. The need for encryption and secure communication protocols adds to the computational and communication overhead. Encrypting model updates can significantly increase the size of the data being transmitted, further straining the communication channels and requiring more sophisticated algorithms to balance privacy and efficiency ( McMahan et al., 2017 ). Third , as FL tasks become more complex, the size of the models involved increases. Modern large-scale models, such as large language models (LLMs) and foundation models (FMs), can have billions of parameters, resulting in model sizes that require significant bandwidth to transmit. This issue is exacerbated when using standard communication protocols like gRPC, which have size limits on single messages (e.g., 2 GB). Typical LLMs and FMs can exceed these limits, necessitating the model to be split into smaller chunks for transmission, adding additional overhead and complexity to the system ( Tayebi Arasteh et al., 2023 ).
Included studies primarily concentrated on enhancing communication encryption techniques , with the aim of either reducing the volume of data exchanged ( Lian et al., 2022 , Brisimi et al., 2018 ) or minimizing the number of communication rounds ( Souza et al., 2021 ). Additionally, several studies explored methods for achieving fully decentralized communication without central server ( Tedeschini et al., 2022 , Lu et al., 2020 ). Improvements in encryption often involved methods for securely sharing secret keys among clients ( Sav et al., 2022 , Chen et al., 2020a ), encryption mechanisms for safeguarding exchanged data ( Li et al., 2021b , Zhang et al., 2022 ), and techniques for perturbing model outputs at each client using a secret key ( Park and Ye, 2022 ). To decrease the amount of data transmitted, some studies proposed transferring only a subset of model parameters ( Sun et al., 2021a , Lu et al., 2022b , Ma et al., 2021b ) or employing strategies like compressing ( Wang et al., 2022 ), masking ( Kerkouche et al., 2021 ), and quantizing gradients ( Ma et al., 2021b ) or model outputs before exchange ( Li and Yang, 2023 ). Reducing the number of communication rounds was addressed through model design ( Tong et al., 2022 , Thakur et al., 2021 , Qu et al., 2022 ), aggregating updates based on elapsed time instead of epochs ( Wang et al., 2022 , Ma et al., 2021a ), and evaluating the potential benefit of an update before communication ( Chen et al., 2020a ). Other studies focused on detecting attacks during communication ( Cholakoska et al., 2021 ), developing authentication systems for clients ( Wang et al., 2023b ), and improving client management systems ( Li et al., 2022a , Zhang et al., 2022 ).
Recommendations & opportunities .

    •
    Model Optimization: Utilize parameter-efficient, lightweight models such as MobileNet and SqueezeNet to reduce computation and memory overhead. Explore model pruning ( Wen et al., 2016 ) and low-rank adaptation (LoRA) ( Hu et al., 2021 ) techniques to decrease model size or regularize model weights without significantly impacting accuracy. Consider split learning ( Gawali et al., 2021 , Thapa et al., 2022 ) to share intermediate activations or a subset of the model instead of the full model, thus reducing communication costs.
    •
    Gradient Compression: Implement gradient compression methods, including sparsification and quantization, to reduce the size of model updates ( Rothchild et al., 2020 ). Integrate AI-driven compression techniques to dynamically adjust quantization and sparsification levels based on model performance and network conditions.
    •
    Reduce Communication Rounds: Minimize the number of communication rounds by adopting methods such as One-Shot FL ( Guha et al., 2019 ), which requires only a single round of communication to achieve effective model training.
    •
    Adopt Decentralized Approaches: Explore decentralized training methods to eliminate the need for a central server, thereby alleviating communication bottlenecks and improving scalability.
    •
    Knowledge Distillation: Use knowledge distillation techniques to transmit only essential distilled knowledge, such as logits from the final layer, rather than the entire model ( Li and Wang, 2019 , Guha et al., 2019 , Madni et al., 2023 ). This approach can reduce communication overhead while maintaining model performance.
    •
    Data Distillation: Apply data distillation to generate synthetic data summaries or distilled representations of the original datasets or updates. Clients can then share smaller, more concise updates with the central server, enhancing communication efficiency ( Xiong et al., 2022 , Goetz and Tewari, 2020 ).
    •
    Develop Specialized Protocols: Design and implement lightweight communication protocols tailored for FL, focusing on bandwidth efficiency and robustness against network instability.
    •
    Design Scalable and Flexible Framework: Develop FL frameworks that adapt to various communication environments and model complexities. Incorporate dynamic communication schedules to optimize efficiency and performance.

5.4.4. Plain convergence analysis
Federated optimization in healthcare aims to adapt models to local data distributions while integrating global information. The inherent heterogeneity across hospitals and institutions often leads to instability and slow convergence in federated training ( Li et al., 2020c ). However, comprehensive convergence analysis is frequently lacking in current studies.
Most studies tend to provide only plain convergence analysis, focusing on reporting metrics such as the number of local epochs, communication rounds, and overall convergence time. While these metrics are useful, they do not offer a deep theoretical understanding of the convergence dynamics. This lack of rigorous analysis limits our understanding of how and why certain FL algorithms perform well (or poorly) in specific healthcare applications.
Only a handful of studies ( Lu et al., 2020 , Kerkouche et al., 2021 , Ma et al., 2021b , Brisimi et al., 2018 ) have focused on the convergence of FL in healthcare settings. These studies typically relied on Stochastic Gradient Descent (SGD) as the foundational optimization method due to its effectiveness in smooth optimization problems , under assumptions such as the existence of lower bounds, Lipschitz smoothness, and bounded variance ( Lu et al., 2020 , Kerkouche et al., 2021 ). However, SGD-based FL algorithms often struggle with nonsmooth optimization problems, which are common in healthcare data due to irregularities in data distributions and the presence of outliers.
Recommendations & opportunities .

    •
    Theoretical Convergence Guarantees: Establish rigorous theoretical methods that provide convergence guarantees for FL in healthcare. This includes deriving bounds on convergence rates and understanding the conditions under which proposed algorithms perform optimally, particularly in non-IID data settings. While complete boundary analyses in large-scale non-IID settings remain challenging due to data noise and complexity, partial modeling of noise, such as using bounded variance assumptions or noise-resilient gradient estimators, has shown promise in existing studies ( Li et al., 2020c , Mishra et al., 2022 ). Future research could explore hybrid approaches that combine empirical noise estimation with theoretical bounds to enhance the practical relevance of convergence analysis.
    •
    Real-World Validation: Prioritize validating convergence analysis and algorithmic improvements on real-world healthcare datasets with natural split rather than relying solely on synthetic partitions. This will ensure that the proposed methods are practical and effective in real healthcare environments.
    •
    Advanced Optimization: Non-convexity, non-smoothness, and heterogeneity are not universal across all healthcare data. For instance, MRI images tend to be homogeneous, while blood test data exhibit more heterogeneity. A unified optimization method may not address all these challenges. Tailored optimization strategies , including smooth methods for homogeneous data and non-smooth, non-convex methods for heterogeneous data, should be explored. Hybrid approaches could also be considered to optimize convergence and stability in diverse healthcare applications.
    •
    Principled Communication Termination: Implement principled methods for terminating communication rounds, potentially based on the performance of the global model at each client on a validation cohort or evaluation data held at the central aggregator. Early stopping based on local convergence could also be beneficial, as it would reduce unnecessary computation and communication costs.

5.4.5. Temporal dynamics and revoke issues
Healthcare data’s inherent time dependence is critical, especially for diseases with distinct progression or treatment timelines, such as cancer and chronic conditions like diabetes. However, included studies often overlooked these temporal dynamics when partitioning data, potentially leading to models that inaccurately reflect disease progression . For example, COVID-19 characteristics, such as ground-glass opacities in lung CT scans, evolve with the disease’s progression ( Pan et al., 2020 ). Ignoring such temporal dynamics can result in models that are overfitted to specific stages of a disease and unable to generalize across different phases ( Li et al., 2019 , Li et al., 2020b , Li et al., 2020a ). Furthermore, the dynamic nature of data at each participating hospital or institution complicates the situation. Hospitals continuously acquire new data and may also remove or modify existing data due to errors or other factors. This dynamic data environment requires FL models to adapt without frequent retraining, as new data might cause model drift, while data removal can leave critical gaps in the model’s understanding, particularly if the removed data represents rare or critical cases.
Another critical but overlooked issue in FL is data revocation, which becomes necessary when specific data must be withdrawn due to privacy concerns, regulatory requirements, patient or participant requests, misdiagnosis , invalidated prior diagnoses, or medical misconduct . Current FL setups, designed for iterative data aggregation, struggle with “unlearning” specific contributions without requiring complete model retraining. Emerging research highlights the need for mechanisms that allow for efficient data revocation without compromising the integrity of the model. For instance, methods have been proposed to facilitate client “unlearning” in FL, enabling the removal of data contributions from specific clients without significant degradation in model performance ( Wang et al., 2024b ). This is critical in healthcare, where patient consent may be withdrawn, new privacy regulations may require data deletion , or misdiagnosed and fraudulent data could undermine model integrity.
Recommendations & opportunities .

    •
    Incorporate Temporal Dynamics: FL frameworks should be adapted to account for the temporal aspects of healthcare data. This could involve time-aware partitioning of data and the development of models that can learn from time-series data, ensuring better generalization across different stages of disease progression.
    •
    Support Dynamic Data Management: FL models should include mechanisms for continuous learning to adapt to the addition and removal of data within the federation. Techniques like incremental learning or online learning could be employed to keep models updated with the latest data while minimizing the need for complete retraining.
    •
    Data Revocation: Develop and integrate efficient data revocation techniques in FL frameworks. Approaches such as machine unlearning ( Wang et al., 2024b ) can be refined to allow the removal of specific data contributions while minimizing the impact on overall model performance. This will be critical for maintaining compliance with privacy laws and upholding patient rights in healthcare applications.
    •
    Active Learning Integration: Incorporate active learning strategies into FL to selectively query the most informative data points during the training process. This would help in focusing on critical data that improves model performance over time, especially in cases where temporal dynamics are at play.

5.4.6. Synchronization issues
Synchronization of updates across different clients also poses significant challenges for FL in healthcare. The variation in computational resources, network conditions, and data availability among clients can lead to different training speeds and delayed model updates.
In Synchronous FL , all clients must complete their training and send their updates before the global model aggregation, which is straightforward but can be inefficient. This approach works well in environments where data is immediately available, such as in a centralized hospital picture archiving and communication system (PACS). However, in real-world scenarios, where data acquisition might be delayed due to network issues or the unavailability of input/output devices, synchronous updates can result in significant idle times and resource underutilization ( Sakib et al., 2021 ). Additionally, clients in an FL network, particularly smaller healthcare entities (e.g., wearables and IoMT devices), may not be active during every communication round, further delaying the global model update and potentially degrading overall system performance ( McMahan et al., 2017 ).
Asynchronous FL , on the other hand, allows clients to send updates independently, without waiting for other clients to finish their training. This approach is more flexible and can accommodate variations in client availability and computational power, thereby improving the overall efficiency of the FL process. One study ( Sakib et al., 2021 ) proposed an asynchronously updating FL architecture for cardiac activity monitoring and arrhythmia detection without the need for frequent synchronization. Another study ( Shiranthika et al., 2024 ) presented an adaptive asynchronous split FL scheme for medical image segmentation , which enhances training efficiency and model performance by allowing clients to operate at their own training speeds. However, asynchronous updates can introduce challenges related to the consistency of the global model, as updates from slower or less reliable clients may arrive out of sync with the rest of the system.
Recommendations & opportunities .

    •
    Hybrid Synchronization: Investigate hybrid synchronization methods that combine the benefits of synchronous and asynchronous updates. For example, employing synchronous updates for critical clients with high-quality data and asynchronous updates for less reliable or slower clients could balance consistency and efficiency.
    •
    Consistency and Anomaly Check: When employing asynchronous updates, it is crucial to assess the consistency and anomaly of updates received from different clients. Divergent updates, where one client’s model update significantly differs from others, could indicate issues such as heterogeneity or anomalous behavior in the training process. These discrepancies need to be carefully managed to prevent the global model from diverging.
    •
    Asynchronous FL for Wearables and IoMT Devices: Asynchronous FL is particularly suitable for wearables and IoMT, where devices may have intermittent connectivity. Leveraging the Async-FL paradigm can pave the way for implementing the next generation of smart and remote healthcare monitoring systems at a mass scale.

Table 3 . Summary of privacy and security attacks in FL applied to healthcare.
Attacks	Description	Risks	Attack
difficulty	Impact
scope	Detection
methods	Defense
strategies
Model inversion
( Li et al., 2022d )	Reconstruct the actual samples (e.g., patient medical images or genetic data) from the model or updates	Potential leakage of original patient data	High	Data privacy, patient confidentiality	Anomaly detection in model outputs & updates	DP
Membership inference
( Yu et al., 2020 )	Determining if a specific patient’s record was part of the model’s training set by analyzing its outputs	Compromises patient confidentiality, leading to potential unauthorized access to sensitive health information	Medium	Data privacy, patient confidentiality	Monitoring for unusual model behavior, particularly overconfident predictions	Regularization techniques, DP, and robust model validation
Data attribute inference
( Melis et al., 2019 )	Infer individual sample’s attributes (like race, gender, age) or gain aggregate statistical insights about the entire training set from model parameters and updates	Leakage of patient privacy	Medium	Data privacy, patient confidentiality, communication security	Gradient analysis, privacy audits	Secure aggregation, DP
Data poisoning
( Nasr et al., 2019 )	Malicious participants alter local data or labels to degrade the global model’s performance	Significant drop in model performance, potentially misleading patient diagnoses	Medium	Model accuracy, patient safety	Monitoring for abnormal model behavior, statistical checks	Robust aggregation methods, anomaly detection in model updates
Model poisoning
( Kalapaaking et al., 2023 )	Malicious participants upload tampered model parameters to manipulate the global model	Global model may be intentionally corrupted, affecting its performance on real data	High	Model integrity, patient safety	Anomaly detection in model updates	Robust aggregation, DP
Denial of service
( Salim et al., 2024 )	Disrupt the FL system by overwhelming it with requests or blocking normal data flow	Training process delays or interruptions, affecting time-sensitive medical applications	Medium	System availability and security, training efficiency	Monitoring network traffic for anomalies	Rate limiting, robust network design, redundancy mechanisms
HE attack
( Zhang et al., 2022 )	Decrypt encrypted model updates to access sensitive information	Encryption key leakage may lead to a breakdown in data protection, compromising patient privacy	High	Data privacy, model integrity	Encryption integrity checks, key management audits	Secure key management, SMPC
User withdrawal attack
( Tian et al., 2023 )	Participants withdraw from training, but their prior updates still affect the global model	Updates from withdrawn users may contain errors or malicious data, degrading the global model	Low	Model integrity	Tracking user participation and contribution consistency	Periodic re-evaluation of model contributions, machine unlearning
5.5. Privacy and security
Two critical privacy and security issues exist in current studies. First, it is concerning that 62% of the included studies did not encrypt model updates during communication. This lack of encryption leaves FL system vulnerable to interception, posing significant security risks. Second, statistical information such as sample sizes and distributions were often shared alongside model updates, particularly in FedAvg-based methods ( Adnan et al., 2022 , Ziller et al., 2021 ). This practice can expose participants with large datasets to targeted attacks if an adversary intercepts the communication or compromises the aggregator ( Tayebi Arasteh et al., 2023 ).
Despite the advantage of FL in healthcare without directly exchanging or sharing local data, it is not immune to privacy and security risks. Adversaries can analyze changes in model updates over time to infer sensitive information or exploit system vulnerabilities to conduct targeted attacks using techniques like model inversion ( Wu et al., 2019 ), membership inference ( Li et al., 2021a ), and poisoning ( Nasr et al., 2019 ). Additionally, clients may unintentionally reveal private data during the FL process. This can happen when the client memorizes previous model and gradient updates, leading to the leakage of sensitive information ( Hatamizadeh et al., 2023 , Fang et al., 2022 ). Furthermore, methods involving the sharing of a few data samples for augmentation or disclosing local data distributions during knowledge transfer can also result in privacy breaches ( Xie et al., 2024 , Madni et al., 2023 ). These adversarial and unintentional exposures undermine the privacy and security of the FL process, necessitating robust countermeasures and continuous vigilance to safeguard the integrity and confidentiality of the FL process.
In Table 3 , we provide a comprehensive overview of various privacy and security attacks identified in the context of FL in healthcare. By summarizing their key characteristics, specific risks they introduce, as well as potential defense strategies and other relevant factors. This table serves as a critical resource for understanding the complexities and vulnerabilities associated with FL in healthcare, offering insights into both the challenges and possible solutions for enhancing privacy and security in this domain.
Among all included studies, methods for data privacy and security protection generally fall into two broad categories, namely cryptography and perturbation techniques. Each of these methods has its advantages and shortcomings, as summarized in Table 4 .
Cryptography encompass a variety of methods, with homomorphic encryption (HE) ( Liu et al., 2021a ) and secure multi-party computation (SMPC) ( Lindell, 2020 ) being among the most popular. HE enables computations directly on encrypted data without the need for decryption. This ensures that data remains encrypted throughout processing, storage, and transmission, thus providing robust data security and privacy. HE allows operations on ciphertexts , with the results, once decrypted, accurately reflecting the outcomes of operations performed on the original plaintext data . HE is particularly valuable in FL due to its ability to safeguard data privacy during computation. Recent research has highlighted HE’s effectiveness in various healthcare applications, including oncology and medical genetics . For instance, Froelicher et al. (2021) demonstrated HE’s potential for truly private federated evaluations, and Chen et al. (2020b) successfully utilized HE for model aggregation in FL. While SMPC enables multiple parties to collaboratively compute a function over their combined data while keeping each party’s data private. Each participant holds a piece of encrypted or encoded data, and the computation is designed so that no party can access the others’ data or infer anything beyond the final result. SMPC ensures the confidentiality of both input data and computation results, making it robust against adversarial attacks and suitable for scenarios with multiple untrusted parties. It is increasingly used in healthcare and other sensitive applications to enhance privacy. For instance, research shows that SMPC can improve privacy in FL with medical datasets by addressing risks related to malicious models and enhancing the confidentiality of model aggregation ( Kalapaaking et al., 2022 , Kalapaaking et al., 2023 ).
Nevertheless, HE typically involves high storage and computational overheads. Encrypted data requires significant processing power, and the complexity of HE schemes can introduce a single point of failure , where a single server manages all encrypted data ( Froelicher et al., 2021 ). Additionally, managing encryption keys securely is crucial, as any compromise in key management can jeopardize the entire system’s security ( Huang et al., 2023 ). Also, SMPC often incurs high computational and communication overhead. The process of encrypting, encoding, and splitting data can be computationally intensive. Moreover, coordinating the computations across multiple parties requires substantial communication resources, which can become a bottleneck as the number of participants grows ( Huang et al., 2022 ).
Perturbation techniques, with differential privacy (DP) ( Dwork, 2006 ) being the most prominent, are crucial for protecting sensitive healthcare data. DP quantifies the risk of exposing individual data points and ensures that the inclusion or exclusion of any single data point has minimal impact on the model’s output by introducing randomness into the model’s results. In FL, DP is typically implemented by adding noise to the local updates or gradients before they are aggregated. This noise is designed to mask the contributions of individual data points, thus making it difficult to infer any single data point from the model’s outputs. DP provides a quantifiable measure of privacy through parameters such as ϵ and δ , allowing for a clear understanding of the trade-off between privacy and model utility. Recent studies in healthcare have shown that FL with DP can achieve comparable accuracy to non-DP models in specific tasks, with a performance gap of less than 5%, proving DP’s efficacy with minimal accuracy compromise ( Adnan et al., 2022 , Ziller et al., 2021 , Tayebi Arasteh et al., 2023 ).
However, the main challenge with DP is balancing the privacy budget with model performance. Adding noise typically reduces model accuracy by obscuring data patterns, which is a critical consideration in DP implementation ( Hatamizadeh et al., 2023 ). Managing the privacy budget ϵ involves a trade-off: a smaller ϵ enhances privacy but may reduce performance, and a larger ϵ offers less privacy protection. Effective management of this trade-off is essential, requiring careful attention to privacy needs and performance goals ( Kaissis et al., 2021 ). Implementing DP also introduces additional computational overhead due to the noise addition and gradient clipping processes. This overhead can affect the scalability and efficiency of FL systems, particularly in scenarios with large numbers of clients or data ( Lee and Kifer, 2021 ).
Beyond cryptography and perturbation methods, blockchain ( Kumar et al., 2021 ) and swarm learning (SL) ( Warnat-Herresthal et al., 2021 , Saldanha et al., 2022 ) have gained lots of attention for enhancing privacy and security in healthcare. Blockchain is increasingly being integrated with FL to address data security and trust issues by replacing the central server with a decentralized privacy protocol. The key advantage of blockchain lies in its distributed ledger system, which ensures that data is securely shared and maintained across all clients without relying on a central authority. This decentralization reduces the risk of single points of failure and enhances data integrity. Furthermore, blockchain’s verification schemes play a crucial role in the FL process, helping to detect and mitigate threats such as poisoning attacks. For instance, a blockchain-based FL framework developed by Chang et al. (2021) combined DP and gradient-verification protocols to enhance security in IoMT devices, significantly reducing the success rate of poisoning attacks in tasks like diabetes prediction. Another approach by Rehman et al. (2022) utilized blockchain alongside an intrusion detection system to monitor and prevent malicious activities during model training, further securing federated healthcare networks. However, while blockchain offers robust security features, its integration with FL is often challenged by high communication and computational costs, which can limit its scalability and efficiency. Swarm Learning takes a different approach by decentralizing not just the privacy protocol but the entire model training process. In SL, there is no central aggregator, instead, decentralized hardware infrastructures work together to securely onboard clients and collaboratively generate a global model. This decentralized approach enhances the network’s resilience against attacks and is particularly effective in scenarios where data is non-IID, such as in the prediction of conditions like COVID-19 and leukemia ( Warnat-Herresthal et al., 2021 , Saldanha et al., 2022 ). However, SL’s reliance on peer-to-peer communication can introduce latency issues, which may slow down the training process, particularly in environments with varying network conditions.

Table 4 . Comparison of Cryptography, perturbation, and other techniques used for privacy and security protection in FL for healthcare.
Category	Technique	Description	Advantages	Limitations
Cryptography	Homomorphic
encryption	Enable computations on encrypted data without decryption, maintaining data encryption throughout	• Provide strong data security and privacy
• Useful for various healthcare applications
• Effective in federated evaluations and model aggregation	• High computational and storage overhead
• Complex schemes may introduce single points of failure
• Key management challenges
Secure
multi-party
computation	Allow multiple parties to collaboratively compute a function on their combined data while keeping data private	• Ensure confidentiality of input data and computation results
• Robust against adversarial attacks
• Enhance privacy in federated settings	• High computational and communication overhead
• Scalability issues with increasing number of participants
• Coordination complexity
Perturbation	Differential
privacy	Adds noise to local updates or gradients to mask individual data contributions, ensuring privacy	• Provide strong privacy guarantees with quantifiable privacy budget
• Achieve competitive performance in healthcare applications	• Trade-off between privacy and model accuracy
• Additional computational overhead
Others	Blockchain	A decentralized ledger system that secures data sharing across all clients, reducing single points of failure	• Decentralized data sharing and management through distributed ledger
• Enhanced data integrity and security with no single point of failure
• Effective at preventing and mitigating poisoning attacks with verification schemes	• High communication and computational costs, which may limit scalability
• Potential challenges in key management and the need for substantial processing power
Swarm
learning	A fully decentralized model training approach without a central aggregator	• Enhance resilience against attack
• Effective in handling non-IID data, making it suitable for diverse and heterogeneous datasets
• Dynamically integrate decentralized hardware infrastructures	• Latency issues due to peer-to-peer communication, potentially slowing down the training process
• The absence of a central aggregator may limit certain coordination and optimization capabilities
Recommendations & opportunities .

    •
    Balancing Privacy and Model Utility: Privacy-preserving FL systems must carefully balance privacy protection with model performance. It is essential to implement techniques that provide strong privacy guarantees while minimizing the impact on model accuracy.
    •
    Quantifying Privacy Levels: Establish clear metrics for quantifying privacy levels. All participants should agree on the acceptable privacy thresholds, ensuring that these thresholds align with the collaborative research goals and regulatory requirements. This quantification should be transparent and well-documented to foster trust and compliance among stakeholders.
    •
    Comprehensive Privacy Enforcement: Privacy protections should be applied uniformly across all components of the FL ecosystem, including clients, central servers, and communication channels. It is also critical to ensure the join or leave of participants does not compromise the federation’s privacy promises.
    •
    Empirical and Theoretical Trade-offs: Address the trade-offs between privacy and model performance requires both theoretical insights and empirical validation. Researchers should focus on understanding how various privacy-preserving techniques impact different aspects of model performance and utility. This includes investigating how privacy budgets, noise levels, and other parameters affect the overall effectiveness of the FL system.

5.6. Fairness and incentive
In FL for healthcare, research on fairness and incentive mechanisms is relatively underexplored, with only ( Zhang et al., 2024 ) delved into the intricacies of both fairness and incentive in FL for healthcare.
Fairness in FL refers to the equitable distribution of model performance across participants. In healthcare, it often means ensuring that ML models perform consistently across different healthcare providers and demographic groups or patient attributes. These fairness considerations are essential because disparities in model accuracy can lead to unequal treatment outcomes. Zhang et al. (2024) introduced several types of fairness, including horizontal fairness, where different hospitals receive comparable model accuracy, and vertical fairness, which focuses on ensuring that model performance is balanced across different demographic or medical attributes. They also proposed multilevel fairness, which seeks to address both client-level and attribute-level fairness simultaneously, and agnostic distribution fairness, aiming to generalize the model’s fairness to non-participating entities, such as hospitals outside the federation.
Incentive mechanisms are equally important in FL, as healthcare institutions often require motivation to participate in the federation. While regulatory constraints can mandate FL within organizations, voluntary participation in broader FL networks typically relies on clear incentives. For instance, hospitals engaging in FL for tasks like chest radiography classification or COVID-19 detection benefit from access to models that are more accurate than those developed using only local data. A well-designed incentive structure should ensure that participants who contribute more, whether through higher-quality data or computational resources, receive proportionately higher rewards. These rewards could be financial, reputational, or in the form of improved access to infrastructure.
Recommendations & opportunities .

    •
    Dynamic Fairness Mechanisms: Future research should focus on developing dynamic fairness mechanisms that can adapt to changes in data distributions and contributions from different healthcare providers. This would ensure that fairness is maintained even as the data and participants evolve over time.
    •
    Transparent Contribution Metrics: Establish transparent and robust methods for quantifying each participant’s contribution is essential. Accurate measurement of contributions in terms of data volume, quality, and computational resources will facilitate the creation of fair incentive structures.
    •
    Broader Incentive: Incentive mechanisms should extend beyond financial rewards to include non-monetary incentives, such as reputation enhancement, access to advanced computational resources, and improved patient outcomes. This broader incentive could encourage more diverse participation from healthcare institutions.

5.7. Evaluation
5.7.1. Gaps in evaluation metrics
The evaluation of FL models in healthcare heavily focuses on conventional ML metrics, such as accuracy, precision, AUC, sensitivity/recall, specificity, F1-score, Dice score, IoU, HD , and loss value ( Dong et al., 2018 ). FL models are typically compared against classical centralized models or localized models, with ablation studies commonly used to isolate the impact of specific modifications. Most studies overlooked critical aspects unique to FL, such as communication overhead, resource consumption, privacy, and security concerns, thus failing to capture the complexity of FL systems.
FL involves frequent communication, which can introduce delays and increase costs. However, only a minority of studies (18%) included communication efficiency in their evaluation. Metrics such as communication cost, number of communication rounds, and latency are crucial for understanding the effectiveness of FL systems ( Hosseini et al., 2023 , Malik et al., 2023 ).
Resource consumption is another crucial factor that has been underexplored, with only 12% of the reviewed studies measuring computational costs in FL evaluation. Key metrics such as training time ( Wang et al., 2022 ), encryption time ( Liu et al., 2023b ), CPU and memory consumption ( Alam and Rahmani, 2023 ) are necessary for evaluating the computational efficiency and understanding the feasibility of FL systems ( Kalapaaking et al., 2022 ). Without these metrics, it is challenging to comprehensively evaluate the trade-offs between performance and resource requirements, limiting the ability to assess the feasibility and practicality of deploying FL systems in resource-constrained healthcare environments.
Privacy and security evaluations are fundamental for FL in healthcare. Despite this, only 16% of the reviewed studies assessed these aspects, with methods focusing on vulnerabilities to attacks such as model inversion attacks, and DP guarantees. For instance, Jin and Li (2023) evaluated the influence of model inversion attacks on synthetic medical images in FL settings. Zhou et al. (2024a) offered theoretical guarantees for DP to assess the system’s privacy resilience. Hatamizadeh et al. (2023) assessed various inversion attacks on medical images to measure and visualize potential data leakage in FL.
Scalability, a critical factor for the widespread adoption of FL in healthcare, has similarly been insufficiently evaluated. Variations in client numbers and patient populations need to be thoroughly assessed to ensure that FL systems can scale across large healthcare networks. Studies by Yan et al. (2024) and Mullie et al. (2024) have demonstrated how FL models can handle varying clients and patient populations.
Finally, generalizability and robustness are crucial, especially given the heterogeneity of healthcare data. As discussed in Section 5.4.1 , most included studies focused on narrow aspects of data skew and heterogeneity, limiting the applicability of their findings across diverse healthcare institutions. To fully evaluate the performance of FL in healthcare, models must be tested across varying types of data skew and heterogeneity. Without this, the true potential and limitations of FL in heterogeneous healthcare environments cannot be fully understood.
Recommendations & opportunities .
In summary, there is a pressing need for a more comprehensive evaluation framework for FL in healthcare. This framework should encompass traditional performance metrics, communication efficiency, resource consumption, privacy and security, scalability, and generalizability. Table 5 summarizes the key aspects and recommended evaluation metrics that should be considered in future research. By adopting this comprehensive approach, researchers can ensure that FL models are not only effective but also scalable, efficient, and secure for real-world healthcare applications.

Table 5 . Comprehensive evaluation metrics for FL in healthcare.
Aspect	Recommended metrics
Performance	Accuracy, AUC, Precision, Sensitivity/Recall, F1-Score, Dice, IoU, HD, Loss
Communication efficiency	Communication cost, Communication rounds, Latency
Resource consumption	Training time, CPU/Memory usage, Encryption time
Privacy and security	Attacks listed in Table 3 , DP guarantees
Scalability	Client numbers, patient populations
Generalizability/Robustness	Data skew scenarios listed in Section 5.4.1
5.7.2. Insufficient benchmarking
Numerous FL algorithms have been proposed to address the challenges posed by non-IID data. However, systematic benchmarking of these algorithms is scarce. Existing studies employed insufficient data partitioning strategies that failed to capture the diversity of real-world healthcare data distributions. Most of them focused on only one or two types of data skew, limiting the scope of analysis and preventing a holistic understanding of algorithm performance under varied conditions. This limitation extends to other critical aspects of FL evaluation as well. To date, no study has provided a comprehensive evaluation covering performance metrics, communication efficiency, resource consumption, privacy and security, scalability, and generalizability. Such evaluations are essential for a robust understanding of FL’s applicability in healthcare.
The absence of comprehensive and universally accepted datasets across various healthcare domains also hinders FL benchmarking. Depending on the research objectives, FL experiments may use datasets that vary significantly in scope and focus, such as medical image classification , segmentation, or reconstruction. Currently, there is no standardized, curated collection of large-scale healthcare datasets across various domains, specifically designed for FL research, which makes it difficult to ensure consistency in benchmarking.
Only one study has reported standardized benchmarking, but it included a limited set of healthcare datasets and failed to integrate key constraints of FL in healthcare, particularly privacy, efficiency, and generalizability ( Ogier du Terrail et al., 2022 ).
Recommendations & opportunities .

    •
    Natural Client Splits and Metrics Definition : Datasets should incorporate a natural client partition reflecting real-world healthcare scenarios, with clearly defined tasks and evaluation metrics. This will facilitate realistic and meaningful benchmarking.
    •
    Reproducible Train/Test Splits: Ensure datasets have predefined and documented train/test splits for each client, enabling reproducible experiments and comparisons across different studies.
    •
    Baseline Models for Comparison: Provide baseline models for each task, including a reference implementation for training on pooled data. This will help researchers compare FL performance against traditional centralized learning approaches.
    •
    Standardized API for FL Algorithms: Standardize the API for FL algorithms to ensure compatibility with the dataset API, allowing for seamless benchmarking of different FL strategies.
    •
    Framework-Agnostic Algorithm Implementation: Offer plain Python code for various FL algorithms that is independent of specific FL frameworks, ensuring flexibility and broader accessibility.
    •
    Comprehensive Evaluation: Cover basic performance metrics, communication efficiency, resource consumption, privacy, security, scalability, and generalizability. Follow the guidelines suggested in Section 5.7.1 .

5.7.3. Lack of interpretability
FL models allow decentralized data processing, but their black-box nature makes it difficult to understand how decisions are made. The opacity of these models raises concerns about trust and accountability, as medical professionals must be able to explain and justify the decisions made by such systems ( Li et al., 2022b , Li et al., 2023a ).
The primary challenge in achieving interpretability in FL stems from the decentralized nature of data. Since each client’s data remains private, the global model lacks direct access to local datasets, making it harder to detect biases, noisy features, or irrelevant data points. Additionally, privacy-preserving mechanisms, such as DP, can obscure data details, further complicating efforts to generate meaningful explanations. Moreover, multiple stakeholders are involved in the decision-making process in FL: the central server needs to understand the significance of certain features to ensure reliable global updates, while clients must comprehend how their data contributes to the model’s performance. These multi-level interpretability needs, combined with resource constraints (e.g., limited computational power and communication bandwidth), present unique challenges for integrating advanced interpretability techniques in FL.
Interpretable feature selection is an essential component of addressing these interpretability challenges in FL. By identifying the most relevant features and filtering out noisy or redundant data, FL models can not only improve performance but also increase transparency in their decision-making processes. In healthcare, this is particularly important, as clinicians need to understand which clinical factors the model considers most relevant. For instance, Soltan et al. (2024) utilized SHAP values to analyze the correlation between 20 clinical features and COVID-19 outcomes in FL settings, finding that eosinophil count had the greatest influence on predictions. Cassará et al. (2022) introduced a mutual information-based approach to select relevant features in a decentralized manner, while Zhang et al. (2023c) proposed an unsupervised technique to detect outlier features and group similar ones via hierarchical clustering in FL.
In addition to feature selection, model-specific techniques such as tree-based FL provide further opportunities for interpretability by allowing models to function as “white-boxes” ( Argente-Garrido et al., 2024 , Li et al., 2024 ). These methods leverage the model’s internal structure to explain its behavior. However, such approaches are often highly specific to particular types of data and may not be broadly applicable across different healthcare domains. Similarly, while gradient-based explanations and attention mechanisms offer another interpretability route, their effectiveness is sometimes limited due to weak correlations between these methods and the actual decision-making processes of the model ( Gong et al., 2021 , Feng et al., 2024 ).
Recommendations & opportunities .

    •
    Incorporation of Domain Knowledge: Integrate domain-specific knowledge into FL models to enhance interpretability. In healthcare, leveraging medical knowledge (e.g., known correlations between symptoms and diseases) can help guide feature selection and model design, making it easier to explain model outputs to clinicians.
    •
    Inherit and Expand Explainable Models: Techniques such as federated decision trees , and rule-based methods could be explored to build models that are transparent by design.
    •
    Client-Side Interpretability Tools: Create lightweight, client-side tools for interpretability that allow individual clients to better understand how their data contributes to the global model. These tools should be resource-efficient to accommodate the limited computational power and bandwidth of many FL clients, particularly in remote healthcare settings.
    •
    Interpretable Aggregation: Explore novel aggregation methods that not only combine client updates but also explain why certain updates were prioritized over others. These methods could use techniques such as explainable boosting or weighted aggregation based on feature importance to make the global model more transparent.
    •
    Privacy-Preserving Explainability: Develop interpretability techniques that align with privacy-preserving requirements in FL, such as DP-aware SHAP values or SMPC for feature importance analysis. These methods should balance transparency with the need to protect sensitive data .

5.7.4. Poor documentation and reproducibility
The reproducibility of FL in healthcare is significantly hindered by several critical issues related to documentation, custom implementations, open-source code availability, and the use of private data.
Firstly, inadequate documentation is a major obstacle. Many included studies lacked crucial details required for reproducing results, such as the methods for data preprocessing , data imputation and augmentation, model initialization, optimization algorithms , and choice of key hyperparameters. This absence of detailed documentation makes it challenging to replicate the reported findings accurately. Additionally, there is often a lack of clarity regarding the data exchanged between clients and the central server. Terms like “model parameters” and “model updates” are frequently used without precise definitions, which leads to ambiguity about whether these terms refer to gradients, model weights, or other parameters.
Secondly, the widespread use of custom FL frameworks exacerbates the issue. Many studies chose to develop their own implementations instead of utilizing established, open-source frameworks. Given the complexity of FL systems, custom implementations are more prone to errors and may lack the robustness of well-tested frameworks. This practice can lead to inconsistencies and difficulties in reproducing results.
Thirdly, the availability of open-source code is critically limited. Only 27% of the reviewed studies made their code publicly available, and none released their trained models. This lack of transparency severely hampers the ability to independently assess and validate model performance, further obstructing reproducibility and impeding future research and application of FL techniques.
Additionally, many studies relied on private data and did not test their methods on publicly available datasets. This practice further complicates reproducibility and fairness in comparisons, as proprietary datasets restrict the ability to conduct fair evaluations and verify results.
Recommendations & opportunities .

    •
    Code & Model Release: Prioritize the release of well-documented code and trained models to facilitate independent performance evaluations and advance the field collaboratively. However, to balance transparency with privacy, ensure that shared models incorporate privacy-preserving techniques such as DP or HE to safeguard sensitive information.
    •
    Checklist: Create a comprehensive FL methodology checklist to improve documentation practices in future studies. The checklist should include guidelines for maintaining transparency while adhering to data privacy standards.
    •
    Pipelines Documentation: Implement full-stack FL pipelines with documentation to simplify AI development for healthcare institutions, making advanced methods more accessible to users with information technology expertise. Modular and privacy-aware pipeline designs are recommended to reduce the risk of exposing sensitive details.
    •
    Evaluation on Public Datasets: Encourage the use of public datasets for evaluation to ensure fair comparisons and enhance the generalizability of results. Anonymized or synthetic datasets could also be employed when real-world data cannot be shared openly due to privacy concerns.
    •
    Framework: Extend existing FL frameworks rather than developing new ones to reduce the risk of errors and support community-driven validation and improvement. Incorporating privacy- preserving modules into these frameworks can address both security and transparency needs effectively.
    •
    Privacy & Transparency Balance: Emphasize the importance of balancing open-sourcing efforts with robust privacy measures. Transparency initiatives should focus on sharing aggregated insights, generalizable methodologies, and anonymized results while safeguarding patient data integrity.

6. Conclusions
In this review, we find that the application of FL to healthcare is still in its relative infancy, with most studies focusing on prediction tasks and often lacking robust demonstrations of clinically significant outcomes. We delve into the challenges and pitfalls of existing solutions and offer practical guidelines for selecting the most appropriate techniques based on specific application scenarios. Additionally, we identify open research challenges that need to be addressed in the near future. We also highlight the importance of establishing standardized methodologies and protocols, as well as promoting the release of open-source code to ensure reproducibility and transparency in FL development in healthcare. We hope that this review will spark new ideas and inspire numerous possibilities for research and application in healthcare FL.
CRediT authorship contribution statement
Ming Li: Writing – review & editing, Writing – original draft, Methodology, Investigation, Conceptualization. Pengcheng Xu: Writing – original draft, Methodology, Formal analysis. Junjie Hu: Methodology, Investigation. Zeyu Tang: Resources, Methodology. Guang Yang: Writing – review & editing, Writing – original draft, Validation, Supervision, Resources, Project administration, Methodology, Investigation, Funding acquisition, Formal analysis, Conceptualization.
Declaration of competing interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
Acknowledgments
This study was supported in part by the ERC IMI ( 101005122 ), the H2020 ( 952172 ), the MRC ( MC/PC/21013 ), the Royal Society, United Kingdom ( IEC\NSFC\211235 ), the NVIDIA Academic Hardware Grant Program , the SABER project supported by Boehringer Ingelheim Ltd, NIHR Imperial Biomedical Research Centre ( RDA01 ), Wellcome Leap Dynamic Resilience, UKRI guarantee funding for Horizon Europe MSCA Postdoctoral Fellowships ( EP/Z002206/1 ), and the UKRI Future Leaders Fellowship ( MR/V023799/1 ).
Data availability
No data was used for the research described in the article.
References

    Adnan et al., 2022
    M. Adnan, S. Kalra, J.C. Cresswell, G.W. Taylor, H.R. Tizhoosh
    Federated learning and differential privacy for medical image analysis
    Sci. Rep., 12 (1) (2022), p. 1953
    View in Scopus Google Scholar
    Alam and Rahmani, 2023
    M.U. Alam, R. Rahmani
    Fedsepsis: A federated multi-modal deep learning-based internet of medical things application for early detection of sepsis from electronic health records using raspberry pi and jetson nano devices
    Sensors, 23 (2) (2023), p. 970
    View at publisher Crossref View in Scopus Google Scholar
    Aminifar et al., 2022
    A. Aminifar, M. Shokri, F. Rabbi, V.K.I. Pun, Y. Lamo
    Extremely randomized trees with privacy preservation for distributed structured health data
    IEEE Access, 10 (2022), pp. 6010-6027
    View at publisher
    Crossref View in Scopus Google Scholar
    Andreux et al., 2020b
    M. Andreux, J.O. du Terrail, C. Beguier, E.W. Tramel
    Siloed federated learning for multi-centric histopathology datasets
    Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings 2, Springer (2020), pp. 129-139
    View at publisher Crossref View in Scopus Google Scholar
    Andreux et al., 2020a
    M. Andreux, A. Manoel, R. Menuet, C. Saillard, C. Simpson
    Federated survival analysis with discrete-time cox models
    (2020)
    arXiv preprint arXiv:2006.08997
    Google Scholar
    Argente-Garrido et al., 2024
    A. Argente-Garrido, C. Zuheros, M. Luzón, F. Herrera
    An interpretable client decision tree aggregation process for federated learning
    (2024)
    arXiv preprint arXiv:2404.02510
    Google Scholar
    Baheti et al., 2020
    P. Baheti, M. Sikka, K. Arya, R. Rajesh
    Federated learning on distributed medical records for detection of lung nodules
    VISIGRAPP (4: VISAPP) (2020), pp. 445-451
    View at publisher Crossref View in Scopus Google Scholar
    Balkus et al., 2022
    S.V. Balkus, H. Fang, H. Wang
    Federated fuzzy clustering for longitudinal health data
    2022 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE, IEEE (2022), pp. 128-132
    View in Scopus Google Scholar
    Bercea et al., 2021
    C.I. Bercea, B. Wiestler, D. Rueckert, S. Albarqouni
    Feddis: Disentangled federated learning for unsupervised brain pathology segmentation
    (2021)
    arXiv preprint arXiv:2103.03705
    Google Scholar
    Beutel et al., 2022
    D.J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K.H. Li, T. Parcollet, P.P.B. de Gusmão, et al.
    Flower: A friendly federated learning framework
    (2022)
    Google Scholar
    Bey et al., 2020
    R. Bey, R. Goussault, F. Grolleau, M. Benchoufi, R. Porcher
    Fold-stratified cross-validation for unbiased and privacy-preserving federated learning
    J. Am. Med. Inform. Assoc., 27 (8) (2020), pp. 1244-1251
    View at publisher Crossref View in Scopus Google Scholar
    Bonawitz et al., 2019
    K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Konečnỳ, S. Mazzocchi, B. McMahan, et al.
    Towards federated learning at scale: System design
    Proc. Mach. Learn. Syst., 1 (2019), pp. 374-388
    Google Scholar
    Bouacida and Mohapatra, 2021
    N. Bouacida, P. Mohapatra
    Vulnerabilities in federated learning
    IEEE Access, 9 (2021), pp. 63229-63249
    View at publisher
    Crossref View in Scopus Google Scholar
    Brisimi et al., 2018
    T.S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I.C. Paschalidis, W. Shi
    Federated learning of predictive models from federated electronic health records
    Int. J. Med. Inform., 112 (2018), pp. 59-67
    View PDF View article View in Scopus Google Scholar
    CAMELYON, 2017
    T.S. CAMELYON
    CAMELYON17 challenge: Grand challenge on cancer metastasis detection in lymph nodes
    (2017)
    https://camelyon17.grand-challenge.org/Home/ . (Accessed 15 August 2024)
    Google Scholar
    Cassará et al., 2022
    P. Cassará, A. Gotta, L. Valerio
    Federated feature selection for cyber-physical systems of systems
    IEEE Trans. Veh. Technol., 71 (9) (2022), pp. 9937-9950
    View at publisher
    Crossref View in Scopus Google Scholar
    Chakravarty et al., 2021
    A. Chakravarty, A. Kar, R. Sethuraman, D. Sheet
    Federated learning for site aware chest radiograph screening
    2021 IEEE 18th International Symposium on Biomedical Imaging, ISBI, IEEE (2021), pp. 1077-1081
    View at publisher Crossref View in Scopus Google Scholar
    Chang et al., 2021
    Y. Chang, C. Fang, W. Sun
    A blockchain-based federated learning method for smart healthcare
    Comput. Intell. Neurosci., 2021 (2021)
    Google Scholar
    Che et al., 2022
    S. Che, Z. Kong, H. Peng, L. Sun, A. Leow, Y. Chen, L. He
    Federated multi-view learning for private medical data integration and analysis
    ACM Trans. Intell. Syst. Technol. (TIST), 13 (4) (2022), pp. 1-23
    View at publisher Crossref Google Scholar
    Chen et al., 2021
    Y. Chen, Z. Chai, Y. Cheng, H. Rangwala
    Asynchronous federated learning for sensor data with concept drift
    2021 IEEE International Conference on Big Data, Big Data, IEEE (2021), pp. 4822-4831
    View at publisher Crossref View in Scopus Google Scholar
    Chen et al., 2020a
    H. Chen, H. Li, G. Xu, Y. Zhang, X. Luo
    Achieving privacy-preserving federated learning with irrelevant updates over e-health applications
    ICC 2020-2020 IEEE International Conference on Communications, ICC, IEEE (2020), pp. 1-6
    View PDF View article Google Scholar
    Chen et al., 2024
    Chen, J., Ma, B., Cui, H., Xia, Y., 2024. Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 11439–11449.
    Google Scholar
    Chen et al., 2020b
    Y. Chen, X. Qin, J. Wang, C. Yu, W. Gao
    Fedhealth: A federated transfer learning framework for wearable healthcare
    IEEE Intell. Syst., 35 (4) (2020), pp. 83-93
    Google Scholar
    Chen et al., 2023
    Chen, H.-Y., Tu, C.-H., Li, Z., Shen, H.-W., Chao, W.-L., 2023. On the importance and applicability of pre-training for federated learning. In: International Conference on Learning Representations.
    Google Scholar
    Cholakoska et al., 2021
    Cholakoska, A., Pfitzner, B., Gjoreski, H., Rakovic, V., Arnrich, B., Kalendar, M., 2021. Differentially private federated learningfor anomaly detection in ehealth networks. In: Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers. pp. 514–518.
    Google Scholar
    CREATIS, 2019
    A. CREATIS
    CAMUS challenge: Cardiac acquisitions for multi-structure ultrasound segmentation
    (2019)
    https://www.creatis.insa-lyon.fr/Challenge/camus/index.html . (Accessed 15 August 2024)
    Google Scholar
    Cremonesi et al., 2023
    F. Cremonesi, M. Vesin, S. Cansiz, Y. Bouillard, I. Balelli, L. Innocenti, S. Silva, S.-S. Ayed, R. Taiello, L. Kameni, et al.
    Fed-BioMed: open, transparent and trusted federated learning for real-world healthcare applications
    (2023)
    arXiv preprint arXiv:2304.12012
    Google Scholar
    Dalmaz et al., 2024
    O. Dalmaz, M.U. Mirza, G. Elmas, M. Ozbey, S.U. Dar, E. Ceyani, K.K. Oguz, S. Avestimehr, T. Çukur
    One model to unite them all: Personalized federated learning of multi-contrast MRI synthesis
    Med. Image Anal., 94 (2024), Article 103121
    View PDF View article View in Scopus Google Scholar
    Dayan et al., 2021
    I. Dayan, H.R. Roth, A. Zhong, A. Harouni, A. Gentili, A.Z. Abidin, A. Liu, A.B. Costa, B.J. Wood, C.-S. Tsai, et al.
    Federated learning for predicting clinical outcomes in patients with COVID-19
    Nature Med., 27 (10) (2021), pp. 1735-1743
    View at publisher
    Crossref View in Scopus Google Scholar
    Dong et al., 2018
    S. Dong, Z. Gao, S. Sun, X. Wang, M. Li, H. Zhang, G. Yang, H. Liu, S. Li, et al.
    Holistic and deep feature pyramids for saliency detection
    BMVC, Vol. 67 (2018)
    Google Scholar
    Dwork, 2006
    C. Dwork
    Differential privacy
    International Colloquium on Automata, Languages, and Programming, Springer (2006), pp. 1-12
    View at publisher Crossref Google Scholar
    European Lung Foundation, 2024
    C. European Lung Foundation
    DRAGON project
    (2024)
    URL: https://europeanlung.org/dragon/ . (Accessed 24 April 2024)
    Google Scholar
    Fallah et al., 2020
    A. Fallah, A. Mokhtari, A. Ozdaglar
    Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach
    Adv. Neural Inf. Process. Syst., 33 (2020), pp. 3557-3568
    Google Scholar
    Fang et al., 2022
    M.L. Fang, D.S. Dhami, K. Kersting
    Dp-ctgan: Differentially private medical data generation using ctgans
    International Conference on Artificial Intelligence in Medicine, Springer (2022), pp. 178-188
    View at publisher Crossref View in Scopus Google Scholar
    Feng et al., 2024
    B. Feng, J. Shi, L. Huang, Z. Yang, S.-T. Feng, J. Li, Q. Chen, H. Xue, X. Chen, C. Wan, et al.
    Robustly federated learning model for identifying high-risk patients with postoperative gastric cancer recurrence
    Nat. Commun., 15 (1) (2024), p. 742
    View in Scopus Google Scholar
    FeTS-AI, 2024
    B. FeTS-AI
    The federated tumor segmentation (FeTS) initiative
    (2024)
    URL: https://www.fets.ai . (Accessed 24 April 2024)
    Google Scholar
    Foley et al., 2022
    P. Foley, M.J. Sheller, B. Edwards, S. Pati, W. Riviera, M. Sharma, P.N. Moorthy, S.-h. Wang, J. Martin, P. Mirhaji, et al.
    OpenFL: the open federated learning library
    Phys. Med. Biol., 67 (21) (2022), Article 214001
    View at publisher
    Crossref View in Scopus Google Scholar
    Froelicher et al., 2021
    D. Froelicher, J.R. Troncoso-Pastoriza, J.L. Raisaro, M.A. Cuendet, J.S. Sousa, H. Cho, B. Berger, J. Fellay, J.-P. Hubaux
    Truly privacy-preserving federated analytics for precision medicine with multiparty homomorphic encryption
    Nat. Commun., 12 (1) (2021), p. 5910
    View in Scopus Google Scholar
    Gad and Fadlullah, 2022
    G. Gad, Z. Fadlullah
    Federated learning via augmented knowledge distillation for heterogenous deep human activity recognition systems
    Sensors, 23 (1) (2022), p. 6
    View at publisher Crossref Google Scholar
    Gawali et al., 2021
    M. Gawali, C. Arvind, S. Suryavanshi, H. Madaan, A. Gaikwad, K. Bhanu Prakash, V. Kulkarni, A. Pant
    Comparison of privacy-preserving distributed deep learning methods in healthcare
    Medical Image Understanding and Analysis: 25th Annual Conference, MIUA 2021, Oxford, United Kingdom, July 12–14, 2021, Proceedings 25, Springer (2021), pp. 457-471
    View at publisher Crossref View in Scopus Google Scholar
    Gehlhar et al., 2023
    T. Gehlhar, F. Marx, T. Schneider, A. Suresh, T. Wehrle, H. Yalame
    Safefl: Mpc-friendly framework for private and robust federated learning
    2023 IEEE Security and Privacy Workshops, SPW, IEEE (2023), pp. 69-76
    View at publisher
    Crossref View in Scopus Google Scholar
    German Cancer Consortium (DKTK), 2024
    T. German Cancer Consortium (DKTK)
    Joint imaging platform
    (2024)
    Web Page. URL: https://jip.dktk.dkfz.de/jiphomepage/ . (Accessed 24 April 2024)
    Google Scholar
    Ghassemi et al., 2020
    M. Ghassemi, T. Naumann, P. Schulam, A.L. Beam, I.Y. Chen, R. Ranganath
    A review of challenges and opportunities in machine learning for health
    AMIA Summits Transl. Sci. Proc., 2020 (2020), p. 191
    Google Scholar
    Goetz and Tewari, 2020
    J. Goetz, A. Tewari
    Federated learning via synthetic data
    (2020)
    arXiv preprint arXiv:2008.04489
    Google Scholar
    Gong et al., 2021
    Gong, X., Sharma, A., Karanam, S., Wu, Z., Chen, T., Doermann, D., Innanje, A., 2021. Ensemble attention distillation for privacy-preserving federated learning. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 15076–15086.
    Google Scholar
    Guan and Liu, 2021
    H. Guan, M. Liu
    Domain adaptation for medical image analysis: a survey
    IEEE Trans. Biomed. Eng. (2021)
    Google Scholar
    Guha et al., 2019
    N. Guha, A. Talwalkar, V. Smith
    One-shot federated learning
    (2019)
    arXiv preprint arXiv:1902.11175
    Google Scholar
    Haggenmüller et al., 2024
    S. Haggenmüller, M. Schmitt, E. Krieghoff-Henning, A. Hekler, R.C. Maron, C. Wies, J.S. Utikal, F. Meier, S. Hobelsberger, F.F. Gellrich, et al.
    Federated learning for decentralized artificial intelligence in melanoma diagnostics
    JAMA Dermatol., 160 (3) (2024), pp. 303-311
    View at publisher
    Crossref View in Scopus Google Scholar
    Hatamizadeh et al., 2023
    A. Hatamizadeh, H. Yin, P. Molchanov, A. Myronenko, W. Li, P. Dogra, A. Feng, M.G. Flores, J. Kautz, D. Xu, et al.
    Do gradient inversion attacks make federated learning unsafe?
    IEEE Trans. Med. Imaging, 42 (7) (2023), pp. 2044-2056
    View at publisher Crossref View in Scopus Google Scholar
    He et al., 2020
    C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh, H. Qiu, et al.
    Fedml: A research library and benchmark for federated machine learning
    (2020)
    arXiv preprint arXiv:2007.13518
    Google Scholar
    Healthchain Consortium, 2024
    C. Healthchain Consortium
    Healthchain consortium
    (2024)
    Web Page. URL: http://healthchain-i3.eu . (Accessed 24 April 2024)
    Google Scholar
    Helmholtz Association, 2024
    C. Helmholtz Association
    Trustworthy federated data analytics (TFDA)
    (2024)
    Web Page. URL: https://tfda.hmsp.center . (Accessed 24 April 2024)
    Google Scholar
    Hosseini et al., 2023
    S.M. Hosseini, M. Sikaroudi, M. Babaie, H.R. Tizhoosh
    Proportionally fair hospital collaborations in federated learning of histopathology images
    IEEE Trans. Med. Imaging, 42 (7) (2023), pp. 1982-1995
    View at publisher
    Crossref View in Scopus Google Scholar
    Howard et al., 2021
    F.M. Howard, J. Dolezal, S. Kochanny, J. Schulte, H. Chen, L. Heij, D. Huo, R. Nanda, O.I. Olopade, J.N. Kather, et al.
    The impact of site-specific digital histology signatures on deep learning model accuracy and bias
    Nat. Commun., 12 (1) (2021), p. 4423
    View in Scopus Google Scholar
    Hu et al., 2021
    E.J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen
    Lora: Low-rank adaptation of large language models
    (2021)
    arXiv preprint arXiv:2106.09685
    Google Scholar
    Huang et al., 2022
    C. Huang, Y. Yao, X. Zhang, D. Teng, Y. Wang, L. Zhou
    Robust secure aggregation with lightweight verification for federated learning
    2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom, IEEE (2022), pp. 582-589
    View at publisher Crossref View in Scopus Google Scholar
    Huang et al., 2023
    W. Huang, M. Zhuo, T. Zhu, S. Zhou, Y. Liao
    Differential privacy: Review of improving utility through cryptography-based technologies
    Concurr. Comput.: Pr. Exp., 35 (5) (2023), Article e7565
    View in Scopus Google Scholar
    Jiang et al., 2022
    Jiang, M., Wang, Z., Dou, Q., 2022. Harmofl: Harmonizing local and global drifts in federated learning on heterogeneous medical images. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36, pp. 1087–1095.
    Google Scholar
    Jin and Li, 2023
    R. Jin, X. Li
    Backdoor attack and defense in federated generative adversarial network-based medical image synthesis
    Med. Image Anal., 90 (2023), Article 102965
    View PDF View article View in Scopus Google Scholar
    Kairouz et al., 2021
    P. Kairouz, H.B. McMahan, B. Avent, A. Bellet, M. Bennis, A.N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al.
    Advances and open problems in federated learning
    Found. Trends® Mach. Learn., 14 (1–2) (2021), pp. 1-210
    View at publisher Crossref View in Scopus Google Scholar
    Kaissis et al., 2021
    G. Kaissis, A. Ziller, J. Passerat-Palmbach, T. Ryffel, D. Usynin, A. Trask, I. Lima Jr., J. Mancuso, F. Jungmann, M.-M. Steinborn, et al.
    End-to-end privacy preserving deep learning on multi-institutional medical imaging
    Nat. Mach. Intell., 3 (6) (2021), pp. 473-484
    View at publisher Crossref View in Scopus Google Scholar
    Kalapaaking et al., 2023
    A.P. Kalapaaking, I. Khalil, X. Yi
    Blockchain-based federated learning with SMPC model verification against poisoning attack for healthcare systems
    IEEE Trans. Emerg. Top. Comput., 12 (1) (2023), pp. 269-280
    Google Scholar
    Kalapaaking et al., 2022
    A.P. Kalapaaking, V. Stephanie, I. Khalil, M. Atiquzzaman, X. Yi, M. Almashor
    Smpc-based federated learning for 6g-enabled internet of medical things
    IEEE Netw., 36 (4) (2022), pp. 182-189
    View at publisher Crossref View in Scopus Google Scholar
    Kandati and Gadekallu, 2022
    D.R. Kandati, T.R. Gadekallu
    Genetic clustered federated learning for COVID-19 detection
    Electronics, 11 (17) (2022), p. 2714
    View at publisher Crossref View in Scopus Google Scholar
    Karimireddy et al., 2020
    S.P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, A.T. Suresh
    Scaffold: Stochastic controlled averaging for federated learning
    International Conference on Machine Learning, PMLR (2020), pp. 5132-5143
    Google Scholar
    Kerkouche et al., 2021
    Kerkouche, R., Acs, G., Castelluccia, C., Genevès, P., 2021. Privacy-preserving and bandwidth-efficient federated learning: An application to in-hospital mortality prediction. In: Proceedings of the Conference on Health, Inference, and Learning. pp. 25–35.
    Google Scholar
    Kim and Wu, 2021
    Kim, Y.G., Wu, C.-J., 2021. Autofl: Enabling heterogeneity-aware energy efficient federated learning. In: MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture. pp. 183–198.
    Google Scholar
    Kline et al., 2022
    A. Kline, H. Wang, Y. Li, S. Dennis, M. Hutch, Z. Xu, F. Wang, F. Cheng, Y. Luo
    Multimodal machine learning in precision health: A scoping review
    NPJ Digit. Med., 5 (1) (2022), p. 171
    View in Scopus Google Scholar
    Kumar et al., 2021
    R. Kumar, A.A. Khan, J. Kumar, N.A. Golilarz, S. Zhang, Y. Ting, C. Zheng, W. Wang, et al.
    Blockchain-federated-learning and deep learning models for covid-19 detection using ct imaging
    IEEE Sens. J., 21 (14) (2021), pp. 16301-16314
    View at publisher
    Crossref View in Scopus Google Scholar
    Lai et al., 2022
    F. Lai, Y. Dai, S. Singapuram, J. Liu, X. Zhu, H. Madhyastha, M. Chowdhury
    Fedscale: Benchmarking model and system performance of federated learning at scale
    International Conference on Machine Learning, PMLR (2022), pp. 11814-11827
    View in Scopus Google Scholar
    Lakhan et al., 2024
    A. Lakhan, H. Hamouda, K.H. Abdulkareem, S. Alyahya, M.A. Mohammed
    Digital healthcare framework for patients with disabilities based on deep federated learning schemes
    Comput. Biol. Med., 169 (2024), Article 107845
    View PDF View article View in Scopus Google Scholar
    Lee and Kifer, 2021
    J. Lee, D. Kifer
    Scaling up differentially private deep learning with fast per-example gradient clipping
    Proc. Priv. Enhancing Technol. (2021)
    Google Scholar
    Lee et al., 2023
    G.H. Lee, J. Park, J. Kim, Y. Kim, B. Choi, R.W. Park, S.Y. Rhee, S.-Y. Shin
    Feasibility study of federated learning on the distributed research network of OMOP common data model
    Heal. Inform. Res., 29 (2) (2023), pp. 168-173
    View at publisher Crossref View in Scopus Google Scholar
    Li et al., 2022c
    Q. Li, Y. Diao, Q. Chen, B. He
    Federated learning on non-iid data silos: An experimental study
    2022 IEEE 38th International Conference on Data Engineering, ICDE, IEEE (2022), pp. 965-978
    Google Scholar
    Li et al., 2020a
    M. Li, S. Dong, Z. Gao, C. Feng, H. Xiong, W. Zheng, D. Ghista, H. Zhang, V.H.C. de Albuquerque
    Unified model for interpreting multi-view echocardiographic sequences without temporal information
    Appl. Soft Comput., 88 (2020), Article 106049
    View PDF View article View in Scopus Google Scholar
    Li et al., 2022b
    M. Li, Y. Fang, Z. Tang, C. Onuorah, J. Xia, J. Del Ser, S. Walsh, G. Yang
    Explainable COVID-19 infections identification and delineation using calibrated pseudo labels
    IEEE Trans. Emerg. Top. Comput. Intell., 7 (1) (2022), pp. 26-35
    Google Scholar
    Li et al., 2021
    Li, Q., He, B., Song, D., 2021. Model-contrastive federated learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10713–10722.
    Google Scholar
    Li et al., 2021a
    Li, J., Li, N., Ribeiro, B., 2021a. Membership inference attacks and defenses in classification models. In: Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy. pp. 5–16.
    Google Scholar
    Li et al., 2023b
    H. Li, C. Li, J. Wang, A. Yang, Z. Ma, Z. Zhang, D. Hua
    Review on security of federated learning and its application in healthcare
    Future Gener. Comput. Syst., 144 (2023), pp. 271-290
    View PDF View article View in Scopus Google Scholar
    Li et al., 2023a
    A. Li, R. Liu, M. Hu, L.A. Tuan, H. Yu
    Towards interpretable federated learning
    (2023)
    arXiv preprint arXiv:2302.13473
    Google Scholar
    Li et al., 2021b
    J. Li, Y. Meng, L. Ma, S. Du, H. Zhu, Q. Pei, X. Shen
    A federated learning based privacy-preserving smart healthcare system
    IEEE Trans. Ind. Inform., 18 (3) (2021)
    Google Scholar
    Li et al., 2020c
    T. Li, A.K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, V. Smith
    Federated optimization in heterogeneous networks
    Proc. Mach. Learn. Syst., 2 (2020), pp. 429-450
    Google Scholar
    Li and Wang, 2019
    D. Li, J. Wang
    Fedmd: Heterogenous federated learning via model distillation
    (2019)
    arXiv preprint arXiv:1910.03581
    Google Scholar
    Li et al., 2022d
    Z. Li, L. Wang, G. Chen, Z. Zhang, M. Shafiq, Z. Gu
    E2EGI: End-to-end gradient inversion in federated learning
    IEEE J. Biomed. Heal. Inform., 27 (2) (2022), pp. 756-767
    View at publisher Crossref View in Scopus Google Scholar
    Li et al., 2020b
    M. Li, C. Wang, H. Zhang, G. Yang
    MV-RAN: Multiview recurrent aggregation network for echocardiographic sequences segmentation and full cardiac cycle analysis
    Comput. Biol. Med., 120 (2020), Article 103728
    View PDF View article View in Scopus Google Scholar
    Li et al., 2024
    Li, Q., Xie, C., Xu, X., Liu, X., Zhang, C., Li, B., He, B., Song, D., 2024. Effective and Efficient Federated Tree Learning on Hybrid Data. In: The Twelfth International Conference on Learning Representations.
    Google Scholar
    Li et al., 2022e
    Z. Li, X. Xu, X. Cao, W. Liu, Y. Zhang, D. Chen, H. Dai
    Integrated CNN and federated learning for COVID-19 detection on chest X-ray images
    IEEE/ ACM Trans. Comput. Biol. Bioinform. (2022)
    Google Scholar
    Li and Yang, 2023
    M. Li, G. Yang
    Data-free distillation improves efficiency and privacy in federated thorax disease analysis
    2023 IEEE EMBS Special Topic Conference on Data Science and Engineering in Healthcare, Medicine and Biology, IEEE (2023), pp. 131-132
    Google Scholar
    Li and Yang, 2024
    M. Li, G. Yang
    Where to begin? From random to foundation model instructed initialization in federated learning for medical image segmentation
    2024 IEEE International Symposium on Biomedical Imaging, ISBI, IEEE (2024), pp. 1-5
    Google Scholar
    Li et al., 2022a
    L. Li, X. Yu, X. Cai, X. He, Y. Liu
    Contract-theory-based incentive mechanism for federated learning in health crowdsensing
    IEEE Internet Things J., 10 (5) (2022), pp. 4475-4489
    Google Scholar
    Li et al., 2019
    M. Li, W. Zhang, G. Yang, C. Wang, H. Zhang, H. Liu, W. Zheng, S. Li
    Recurrent aggregation learning for multi-view echocardiographic sequences segmentation
    Medical Image Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13–17, 2019, Proceedings, Part II 22, Springer (2019), pp. 678-686
    View at publisher
    Crossref View in Scopus Google Scholar
    Lian et al., 2022
    Z. Lian, Q. Yang, W. Wang, Q. Zeng, M. Alazab, H. Zhao, C. Su
    DEEP-FEL: Decentralized, efficient and privacy-enhanced federated edge learning for healthcare cyber physical systems
    IEEE Trans. Netw. Sci. Eng., 9 (5) (2022), pp. 3558-3569
    View at publisher Crossref View in Scopus Google Scholar
    Lin et al., 2020
    T. Lin, L. Kong, S.U. Stich, M. Jaggi
    Ensemble distillation for robust model fusion in federated learning
    Adv. Neural Inf. Process. Syst., 33 (2020), pp. 2351-2363
    Finding PDF… Crossref View in Scopus Google Scholar
    Lin et al., 2023
    L. Lin, J. Wu, Y. Liu, K.K. Wong, X. Tang
    Unifying and personalizing weakly-supervised federated medical image segmentation via adaptive representation and aggregation
    International Workshop on Machine Learning in Medical Imaging, Springer (2023), pp. 196-206
    Google Scholar
    Linardos et al., 2022
    A. Linardos, K. Kushibar, S. Walsh, P. Gkontra, K. Lekadir
    Federated learning for multi-center imaging diagnostics: a simulation study in cardiovascular disease
    Sci. Rep., 12 (1) (2022), p. 3551
    View in Scopus Google Scholar
    Lindell, 2020
    Y. Lindell
    Secure multiparty computation
    Commun. ACM, 64 (1) (2020), pp. 86-96
    Google Scholar
    Liu et al., 2021b
    Liu, Q., Chen, C., Qin, J., Dou, Q., Heng, P.-A., 2021b. FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space. In: The IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR.
    Google Scholar
    Liu et al., 2021a
    B. Liu, M. Ding, S. Shaham, W. Rahayu, F. Farokhi, Z. Lin
    When machine learning meets privacy: A survey and outlook
    ACM Comput. Surv., 54 (2) (2021), pp. 1-36
    Google Scholar
    Liu et al., 2023a
    Q. Liu, Q. Dou, C. Chen, P.-A. Heng
    Domain generalization of deep networks for medical image segmentation via meta learning
    Meta Learning with Medical Imaging and Health Informatics Applications, Elsevier (2023), pp. 117-139
    View PDF View article Google Scholar
    Liu et al., 2021d
    Y. Liu, T. Fan, T. Chen, Q. Xu, Q. Yang
    Fate: An industrial grade platform for collaborative learning with data protection
    J. Mach. Learn. Res., 22 (226) (2021), pp. 1-6
    View PDF View article Google Scholar
    Liu et al., 2021c
    X. Liu, Y. Fan, S. Li, M. Chen, M. Li, W.K. Hau, H. Zhang, L. Xu, A.P.-W. Lee
    Deep learning-based automated left ventricular ejection fraction assessment using 2-D echocardiography
    Am. J. Physiol.- Hear. Circ. Physiol., 321 (2) (2021), pp. H390-H399
    Finding PDF… Crossref View in Scopus Google Scholar
    Liu et al., 2022
    D. Liu, K. Fox, G. Weber, T. Miller
    Confederated learning in healthcare: Training machine learning models using disconnected data separated by individual, data type and identity for large-scale health system intelligence
    J. Biomed. Inform., 134 (2022), Article 104151
    View PDF View article View in Scopus Google Scholar
    Liu et al., 2023b
    W. Liu, Y. He, X. Wang, Z. Duan, W. Liang, Y. Liu
    BFG: privacy protection framework for internet of medical things based on blockchain and federated learning
    Connect. Sci., 35 (1) (2023), Article 2199951
    View in Scopus Google Scholar
    Liu and Yap, 2024
    S. Liu, P.-T. Yap
    Learning multi-site harmonization of magnetic resonance images without traveling human phantoms
    Commun. Eng., 3 (1) (2024), p. 6
    Finding PDF… Crossref View in Scopus Google Scholar
    Lo et al., 2022
    S.K. Lo, Q. Lu, L. Zhu, H.-Y. Paik, X. Xu, C. Wang
    Architectural patterns for the design of federated learning systems
    J. Syst. Softw., 191 (2022), Article 111357
    View PDF View article View in Scopus Google Scholar
    Lu et al., 2022a
    M.Y. Lu, R.J. Chen, D. Kong, J. Lipkova, R. Singh, D.F. Williamson, T.Y. Chen, F. Mahmood
    Federated learning for computational pathology on gigapixel whole slide images
    Med. Image Anal., 76 (2022), Article 102298
    View PDF View article View in Scopus Google Scholar
    Lu et al., 2022b
    W. Lu, J. Wang, Y. Chen, X. Qin, R. Xu, D. Dimitriadis, T. Qin
    Personalized federated learning with adaptive batchnorm for healthcare
    IEEE Trans. Big Data (2022)
    Google Scholar
    Lu et al., 2020
    S. Lu, Y. Zhang, Y. Wang
    Decentralized federated learning for electronic health records
    2020 54th Annual Conference on Information Sciences and Systems, CISS, IEEE (2020), pp. 1-5
    Google Scholar
    Ludwig et al., 2020
    H. Ludwig, N. Baracaldo, G. Thomas, Y. Zhou, A. Anwar, S. Rajamoni, Y. Ong, J. Radhakrishnan, A. Verma, M. Sinn, et al.
    Ibm federated learning: an enterprise framework white paper v0. 1
    (2020)
    arXiv preprint arXiv:2007.10987
    Google Scholar
    Luo et al., 2022
    Z. Luo, Y. Wang, Z. Wang, Z. Sun, T. Tan
    Disentangled federated learning for tackling attributes skew via invariant aggregation and diversity transferring
    International Conference on Machine Learning, PMLR (2022), pp. 14527-14541
    View in Scopus Google Scholar
    Ma et al., 2019
    Y. Ma, D. Yu, T. Wu, H. Wang
    PaddlePaddle: An open-source deep learning platform from industrial practice
    Front. Data Comput., 1 (1) (2019), pp. 105-115
    Google Scholar
    Ma et al., 2021a
    J. Ma, Q. Zhang, J. Lou, L. Xiong, S. Bhavani, J.C. Ho
    Communication efficient tensor factorization for decentralized healthcare networks
    2021 IEEE International Conference on Data Mining, ICDM, IEEE (2021), pp. 1216-1221
    Finding PDF… Crossref View in Scopus Google Scholar
    Ma et al., 2021b
    Ma, J., Zhang, Q., Lou, J., Xiong, L., Ho, J.C., 2021b. Communication efficient federated generalized tensor factorization for collaborative health data analytics. In: Proceedings of the Web Conference 2021. pp. 171–182.
    Google Scholar
    Mabrouk et al., 2023
    A. Mabrouk, R.P.D. Redondo, M. Abd Elaziz, M. Kayed
    Ensemble federated learning: An approach for collaborative pneumonia diagnosis
    Appl. Soft Comput., 144 (2023), Article 110500
    View PDF View article View in Scopus Google Scholar
    Madni et al., 2023
    H.A. Madni, R.M. Umer, G.L. Foresti
    Federated learning for data and model heterogeneity in medical imaging
    International Conference on Image Analysis and Processing, Springer (2023), pp. 167-178
    Google Scholar
    Malik et al., 2023
    H. Malik, A. Naeem, R.A. Naqvi, W.-K. Loh
    DMFL_Net: A federated learning-based framework for the classification of COVID-19 from multiple chest diseases using X-rays
    Sensors, 23 (2) (2023), p. 743
    Finding PDF… Crossref View in Scopus Google Scholar
    Mateus et al., 2024
    P. Mateus, J. Moonen, M. Beran, E. Jaarsma, S.M. van der Landen, J. Heuvelink, M. Birhanu, A.G. Harms, E. Bron, F.J. Wolters, et al.
    Data harmonization and federated learning for multi-cohort dementia research using the OMOP common data model: A netherlands consortium of dementia cohorts case study
    J. Biomed. Inform. (2024), Article 104661
    View PDF View article View in Scopus Google Scholar
    Mazher et al., 2024
    M. Mazher, I. Razzak, A. Qayyum, M. Tanveer, S. Beier, T. Khan, S.A. Niederer
    Self-supervised spatial-temporal transformer fusion based federated framework for 4D cardiovascular image segmentation
    Inf. Fusion, 106 (2024), Article 102256
    View PDF View article View in Scopus Google Scholar
    McMahan et al., 2017
    B. McMahan, E. Moore, D. Ramage, S. Hampson, B.A. y Arcas
    Communication-efficient learning of deep networks from decentralized data
    Artificial Intelligence and Statistics, PMLR (2017), pp. 1273-1282
    View in Scopus Google Scholar
    Melis et al., 2019
    L. Melis, C. Song, E. De Cristofaro, V. Shmatikov
    Exploiting unintended feature leakage in collaborative learning
    2019 IEEE Symposium on Security and Privacy, SP, IEEE (2019), pp. 691-706
    View at publisher
    Crossref View in Scopus Google Scholar
    Melody Project, 2024
    L. Melody Project
    Machine learning ledger orchestration for drug discovery
    (2024)
    URL: https://www.melloddy.eu . (Accessed 24 April 2024)
    Google Scholar
    Mishra et al., 2022
    R. Mishra, H.P. Gupta, T. Dutta
    Noise-resilient federated learning: Suppressing noisy labels in the local datasets of participants
    IEEE INFOCOM 2022-IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS, IEEE (2022), pp. 1-2
    Google Scholar
    Moher et al., 2009
    D. Moher, A. Liberati, J. Tetzlaff, D.G. Altman, t. PRISMA Group*
    Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement
    Ann. Intern. Med., 151 (4) (2009), pp. 264-269
    View at publisher Crossref Google Scholar
    Mora et al., 2024
    A. Mora, A. Bujari, P. Bellavista
    Enhancing generalization in federated learning with heterogeneous data: A comparative literature review
    Future Gener. Comput. Syst. (2024)
    Google Scholar
    Mullie et al., 2024
    L. Mullie, J. Afilalo, P. Archambault, R. Bouchakri, K. Brown, D.L. Buckeridge, Y.A. Cavayas, A.F. Turgeon, D. Martineau, F. Lamontagne, et al.
    CODA: an open-source platform for federated analysis and machine learning on distributed healthcare data
    J. Am. Med. Inform. Assoc., 31 (3) (2024), pp. 651-665
    View at publisher
    Crossref View in Scopus Google Scholar
    Nasr et al., 2019
    M. Nasr, R. Shokri, A. Houmansadr
    Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning
    2019 IEEE Symposium on Security and Privacy, SP, IEEE (2019), pp. 739-753
    View at publisher
    Crossref View in Scopus Google Scholar
    Newton et al., 2013
    K.M. Newton, P.L. Peissig, A.N. Kho, S.J. Bielinski, R.L. Berg, V. Choudhary, M. Basford, C.G. Chute, I.J. Kullo, R. Li, et al.
    Validation of electronic medical record-based phenotyping algorithms: results and lessons learned from the eMERGE network
    J. Am. Med. Inform. Assoc., 20 (e1) (2013), pp. e147-e154
    View at publisher
    Crossref View in Scopus Google Scholar
    Ngiam and Khor, 2019
    K.Y. Ngiam, W. Khor
    Big data and machine learning algorithms for health-care delivery
    Lancet Oncol., 20 (5) (2019), pp. e262-e273
    View PDF View article View in Scopus Google Scholar
    Nguyen et al., 2021
    D.C. Nguyen, M. Ding, P.N. Pathirana, A. Seneviratne, A.Y. Zomaya
    Federated learning for COVID-19 detection with generative adversarial networks in edge cloud computing
    IEEE Internet Things J., 9 (12) (2021), pp. 10257-10271
    Google Scholar
    Nguyen et al., 2023
    Nguyen, J., Wang, J., Malik, K., Sanjabi, M., Rabbat, M., 2023. Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning. In: International Conference on Learning Representations.
    Google Scholar
    NIH Clinical Center, 2017
    J. NIH Clinical Center
    Chest X-ray dataset
    (2017)
    https://nihcc.app.box.com/v/ChestXray-NIHCC . (Accessed 15 August 2024)
    Google Scholar
    NVIDIA, 2020
    J. NVIDIA
    Medical institutions collaborate to improve mammogram assessment AI
    (2020)
    Web Page. URL: https://blogs.nvidia.com/blog/federated-learning-mammogram-assessment/ . (Accessed 28 May 2020)
    Google Scholar
    OWKIN, 2024
    J. OWKIN
    SubstraFL overview
    (2024)
    URL: https://docs.substra.org/en/stable/substrafl_doc/substrafl_overview.html
    Google Scholar
    Pan et al., 2020
    F. Pan, T. Ye, P. Sun, S. Gui, B. Liang, L. Li, D. Zheng, J. Wang, R.L. Hesketh, L. Yang, C. Zheng
    Time course of lung changes at chest CT during recovery from coronavirus disease 2019 (COVID-19)
    Radiology, 295 (2020), pp. 715-721
    Finding PDF… Crossref View in Scopus Google Scholar
    Paragliola and Coronato, 2022
    G. Paragliola, A. Coronato
    Definition of a novel federated learning approach to reduce communication costs
    Expert Syst. Appl., 189 (2022), Article 116109
    View PDF View article View in Scopus Google Scholar
    Park and Ye, 2022
    S. Park, J.C. Ye
    Multi-task distributed learning using vision transformer with random patch permutation
    IEEE Trans. Med. Imaging, 42 (7) (2022), pp. 2091-2105
    Finding PDF… Crossref View in Scopus Google Scholar
    Peng et al., 2024
    L. Peng, G. Luo, S. Zhou, J. Chen, Z. Xu, J. Sun, R. Zhang
    An in-depth evaluation of federated learning on biomedical natural language processing for information extraction
    NPJ Digit. Med., 7 (1) (2024), p. 127
    View in Scopus Google Scholar
    Petersmann et al., 2019
    A. Petersmann, D. Müller-Wieland, U.A. Müller, R. Landgraf, M. Nauck, G. Freckmann, L. Heinemann, E. Schleicher
    Definition, classification and diagnosis of diabetes mellitus
    Exp. Clin. Endocrinol. Diabetes, 127 (S 01) (2019), pp. S1-S7
    View in Scopus Google Scholar
    Philippenko and Dieuleveut, 2020
    C. Philippenko, A. Dieuleveut
    Bidirectional compression in heterogeneous settings for distributed or federated learning with partial participation: tight convergence guarantees
    (2020)
    arXiv preprint arXiv:2006.14591
    Google Scholar
    Qu et al., 2022
    L. Qu, N. Balachandar, M. Zhang, D. Rubin
    Handling data heterogeneity with generative replay in collaborative learning for medical imaging
    Med. Image Anal., 78 (2022), Article 102424
    View PDF View article View in Scopus Google Scholar
    Radiopaedia, 2021
    L. Radiopaedia
    Ground-glass opacification
    (2021)
    https://radiopaedia.org/articles/ground-glass-opacification-3?lang=gb . (Accessed 15 August 2024)
    Google Scholar
    Rehman et al., 2022
    A. Rehman, S. Abbas, M. Khan, T.M. Ghazal, K.M. Adnan, A. Mosavi
    A secure healthcare 5.0 system based on blockchain technology entangled with federated learning technique
    Comput. Biol. Med., 150 (2022), Article 106019
    View PDF View article View in Scopus Google Scholar
    Rehman et al., 2024
    A. Rehman, H. Xing, L. Feng, M. Hussain, N. Gulzar, M.A. Khan, A. Hussain, D. Saeed
    FedCSCD-GAN: A secure and collaborative framework for clinical cancer diagnosis via optimized federated learning and GAN
    Biomed. Signal Process. Control., 89 (2024), Article 105893
    View PDF View article View in Scopus Google Scholar
    Repetto and La Torre, 2022
    M. Repetto, D. La Torre
    Federated learning through goal programming: a computational study in cancer detection
    2022 5th International Conference on Signal Processing and Information Security, ICSPIS, IEEE (2022), pp. 80-85
    Finding PDF… Crossref View in Scopus Google Scholar
    Roth et al., 2022
    H.R. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten, A. Harouni, C. Zhao, K. Lu, et al.
    Nvidia flare: Federated learning from simulation to real-world
    (2022)
    arXiv preprint arXiv:2210.13291
    Google Scholar
    Rothchild et al., 2020
    D. Rothchild, A. Panda, E. Ullah, N. Ivkin, I. Stoica, V. Braverman, J. Gonzalez, R. Arora
    Fetchsgd: Communication-efficient federated learning with sketching
    International Conference on Machine Learning, PMLR (2020), pp. 8253-8265
    View in Scopus Google Scholar
    Ryffel et al., 2018
    T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, J. Passerat-Palmbach
    A generic framework for privacy preserving deep learning
    (2018)
    arXiv preprint arXiv:1811.04017
    Google Scholar
    Sadilek et al., 2021
    A. Sadilek, L. Liu, D. Nguyen, M. Kamruzzaman, S. Serghiou, B. Rader, A. Ingerman, S. Mellem, P. Kairouz, E.O. Nsoesie, et al.
    Privacy-first health research with federated learning
    NPJ Digit. Med., 4 (1) (2021), p. 132
    View in Scopus Google Scholar
    Sakib et al., 2021
    S. Sakib, M.M. Fouda, Z.M. Fadlullah, K. Abualsaud, E. Yaacoub, M. Guizani
    Asynchronous federated learning-based ECG analysis for arrhythmia detection
    2021 IEEE International Mediterranean Conference on Communications and Networking, MeditCom, IEEE (2021), pp. 277-282
    Finding PDF… Crossref View in Scopus Google Scholar
    Saldanha et al., 2022
    O.L. Saldanha, P. Quirke, N.P. West, J.A. James, M.B. Loughrey, H.I. Grabsch, M. Salto-Tellez, E. Alwers, D. Cifci, N. Ghaffari Laleh, et al.
    Swarm learning for decentralized artificial intelligence in cancer histopathology
    Nature Med., 28 (6) (2022), pp. 1232-1239
    Finding PDF… Crossref View in Scopus Google Scholar
    Salim et al., 2024
    M.M. Salim, Y. Sangthong, X. Deng, J.H. Park
    Federated learning-enabled zero-day ddos attack detection scheme in healthcare 4.0
    (2024)
    Google Scholar
    Sattler et al., 2020
    F. Sattler, K.-R. Müller, W. Samek
    Clustered federated learning: Model-agnostic distributed multitask optimization under privacy constraints
    IEEE Trans. Neural Netw. Learn. Syst., 32 (8) (2020), pp. 3710-3722
    Google Scholar
    Sav et al., 2022
    S. Sav, J.-P. Bossuat, J.R. Troncoso-Pastoriza, M. Claassen, J.-P. Hubaux
    Privacy-preserving federated neural network learning for disease-associated cell classification
    Patterns, 3 (5) (2022)
    Google Scholar
    Shaik et al., 2022
    T. Shaik, X. Tao, N. Higgins, R. Gururajan, Y. Li, X. Zhou, U.R. Acharya
    FedStack: Personalized activity monitoring using stacked federated learning
    Knowl.-Based Syst., 257 (2022), Article 109929
    View PDF View article Google Scholar
    Sheller et al., 2020
    M.J. Sheller, B. Edwards, G.A. Reina, J. Martin, S. Pati, A. Kotrotsou, M. Milchenko, W. Xu, D. Marcus, R.R. Colen, et al.
    Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data
    Sci. Rep., 10 (1) (2020), p. 12598
    View in Scopus Google Scholar
    Sheller et al., 2019
    M.J. Sheller, G.A. Reina, B. Edwards, J. Martin, S. Bakas
    Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation
    Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 4th International Workshop, BrainLes 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Revised Selected Papers, Part I 4, Springer (2019), pp. 92-104
    View at publisher
    Crossref View in Scopus Google Scholar
    Shiranthika et al., 2024
    C. Shiranthika, H. Hadizadeh, P. Saeedi, I.V. Bajjć
    Adaptive asynchronous split federated learning for medical image segmentation
    IEEE Access (2024)
    Google Scholar
    Soltan et al., 2024
    A.A. Soltan, A. Thakur, J. Yang, A. Chauhan, L.G. D’Cruz, P. Dickson, M.A. Soltan, D.R. Thickett, D.W. Eyre, T. Zhu, et al.
    A scalable federated learning solution for secondary care using low-cost microcomputing: privacy-preserving development and evaluation of a COVID-19 screening test in UK hospitals
    Lancet Digit. Heal., 6 (2) (2024), pp. e93-e104
    View PDF View article View in Scopus Google Scholar
    Souza et al., 2021
    R. Souza, A. Tuladhar, P. Mouches, M. Wilms, L. Tyagi, N.D. Forkert
    Multi-institutional travelling model for tumor segmentation in MRI datasets
    International MICCAI Brainlesion Workshop, Springer (2021), pp. 420-432
    View in Scopus Google Scholar
    Sun et al., 2021b
    W. Sun, Y. Chen, X. Yang, J. Cao, Y. Song
    FedIO: Bridge inner-and outer-hospital information for perioperative complications prognostic prediction via federated learning
    2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM, IEEE (2021), pp. 3215-3221
    View at publisher Crossref View in Scopus Google Scholar
    Sun et al., 2021a
    B. Sun, H. Huo, Y. Yang, B. Bai
    Partialfed: Cross-domain personalized federated learning via partial initialization
    Adv. Neural Inf. Process. Syst., 34 (2021), pp. 23309-23320
    View in Scopus Google Scholar
    Tayebi Arasteh et al., 2023
    S. Tayebi Arasteh, A. Ziller, C. Kuhl, M. Makowski, S. Nebelung, R. Braren, D. Rueckert, D. Truhn, G. Kaissis
    Private, fair and accurate: Training large-scale, privacy-preserving ai models in medical imaging
    (2023)
    arXiv e-prints, arXiv–2302
    Google Scholar
    Tedeschini et al., 2022
    B.C. Tedeschini, S. Savazzi, R. Stoklasa, L. Barbieri, I. Stathopoulos, M. Nicoli, L. Serio
    Decentralized federated learning for healthcare networks: A case study on tumor segmentation
    IEEE Access, 10 (2022), pp. 8693-8708
    Google Scholar
    Ogier du Terrail et al., 2022
    J. Ogier du Terrail, S.-S. Ayed, E. Cyffers, F. Grimberg, C. He, R. Loeb, P. Mangold, T. Marchand, O. Marfoq, E. Mushtaq, et al.
    Flamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings
    Adv. Neural Inf. Process. Syst., 35 (2022), pp. 5315-5334
    Google Scholar
    Ogier du Terrail et al., 2023
    J. Ogier du Terrail, A. Leopold, C. Joly, C. Béguier, M. Andreux, C. Maussion, B. Schmauch, E.W. Tramel, E. Bendjebbar, M. Zaslavskiy, et al.
    Federated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer
    Nature Med., 29 (1) (2023), pp. 135-146
    View at publisher Crossref View in Scopus Google Scholar
    Thakur et al., 2021
    A. Thakur, P. Sharma, D.A. Clifton
    Dynamic neural graphs based federated reptile for semi-supervised multi-tasking in healthcare applications
    IEEE J. Biomed. Heal. Inform., 26 (4) (2021), pp. 1761-1772
    Google Scholar
    Thapa et al., 2022
    Thapa, C., Arachchige, P.C.M., Camtepe, S., Sun, L., 2022. Splitfed: When federated learning meets split learning. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36, pp. 8485–8493.
    Google Scholar
    Tian et al., 2023
    Y. Tian, S. Wang, J. Xiong, R. Bi, Z. Zhou, M.Z.A. Bhuiyan
    Robust and privacy-preserving decentralized deep federated learning training: Focusing on digital healthcare applications
    IEEE/ACM Trans. Comput. Biol. Bioinform. (2023)
    Google Scholar
    Tong et al., 2022
    J. Tong, C. Luo, M.N. Islam, N.E. Sheils, J. Buresh, M. Edmondson, P.A. Merkel, E. Lautenbach, R. Duan, Y. Chen
    Distributed learning for heterogeneous clinical data with application to integrating COVID-19 data across 230 sites
    NPJ Digit. Med., 5 (1) (2022), p. 76
    View in Scopus Google Scholar
    Truhn et al., 2024
    D. Truhn, S.T. Arasteh, O.L. Saldanha, G. Müller-Franzes, F. Khader, P. Quirke, N.P. West, R. Gray, G.G. Hutchins, J.A. James, et al.
    Encrypted federated learning for secure decentralized collaboration in cancer image analysis
    Med. Image Anal., 92 (2024), Article 103059
    View PDF View article View in Scopus Google Scholar
    Ullah et al., 2023
    F. Ullah, G. Srivastava, H. Xiao, S. Ullah, J.C.-W. Lin, Y. Zhao
    A scalable federated learning approach for collaborative smart healthcare systems with intermittent clients using medical imaging
    IEEE J. Biomed. Heal. Inform. (2023)
    Google Scholar
    Wang et al., 2024a
    L. Wang, J. Bian, J. Xu
    Federated learning with instance-dependent noisy label
    ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, IEEE (2024), pp. 8916-8920
    View at publisher Crossref View in Scopus Google Scholar
    Wang et al., 2022
    R. Wang, J. Lai, Z. Zhang, X. Li, P. Vijayakumar, M. Karuppiah
    Privacy-preserving federated learning for internet of medical things under edge computing
    IEEE J. Biomed. Heal. Inform., 27 (2) (2022), pp. 854-865
    Google Scholar
    Wang et al., 2023b
    W. Wang, X. Li, X. Qiu, X. Zhang, V. Brusic, J. Zhao
    A privacy preserving framework for federated learning in smart healthcare systems
    Inf. Process. Manage., 60 (1) (2023), Article 103167
    View PDF View article View in Scopus Google Scholar
    Wang et al., 2024b
    S. Wang, B. Liu, G. Zuccon
    How to forget clients in federated online learning to rank?
    European Conference on Information Retrieval, Springer (2024), pp. 105-121
    View at publisher Crossref View in Scopus Google Scholar
    Wang et al., 2023a
    J. Wang, G. Xie, Y. Huang, J. Lyu, F. Zheng, Y. Zheng, Y. Jin
    FedMed-GAN: Federated domain translation on unsupervised cross-modality brain image synthesis
    Neurocomputing, 546 (2023), Article 126282
    View PDF View article View in Scopus Google Scholar
    Warnat-Herresthal et al., 2021
    S. Warnat-Herresthal, H. Schultze, K.L. Shastry, S. Manamohan, S. Mukherjee, V. Garg, R. Sarveswara, K. Händler, P. Pickkers, N.A. Aziz, et al.
    Swarm learning for decentralized and confidential clinical machine learning
    Nature, 594 (7862) (2021), pp. 265-270
    View at publisher
    Crossref View in Scopus Google Scholar
    Wen et al., 2016
    W. Wen, C. Wu, Y. Wang, Y. Chen, H. Li
    Learning structured sparsity in deep neural networks
    Adv. Neural Inf. Process. Syst., 29 (2016)
    Google Scholar
    Wu et al., 2022
    D. Wu, R. Ullah, P. Harvey, P. Kilpatrick, I. Spence, B. Varghese
    Fedadapt: Adaptive offloading for iot devices in federated learning
    IEEE Internet Things J., 9 (21) (2022), pp. 20889-20901
    View at publisher Crossref View in Scopus Google Scholar
    Wu et al., 2019
    Wu, B., Zhao, S., Sun, G., Zhang, X., Su, Z., Zeng, C., Liu, Z., 2019. P3sgd: Patient privacy preserving sgd for regularizing deep cnns in pathological image classification. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 2099–2108.
    Google Scholar
    Xie et al., 2024
    Xie, L., Lin, M., Luan, T., Li, C., Fang, Y., Shen, Q., Wu, Z., 2024. MH-pFLID: Model Heterogeneous personalized Federated Learning via Injection and Distillation for Medical Data Analysis. In: Forty-First International Conference on Machine Learning.
    Google Scholar
    Xie et al., 2022
    Y. Xie, Z. Wang, D. Gao, D. Chen, L. Yao, W. Kuang, Y. Li, B. Ding, J. Zhou
    Federatedscope: A flexible federated learning platform for heterogeneity
    (2022)
    arXiv preprint arXiv:2204.05011
    Google Scholar
    Xiong et al., 2022
    Xiong, Y., Wang, R., Cheng, M., Yu, F., Hsieh, C.-J., 2022. FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning. In: Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022).
    Google Scholar
    Yan et al., 2024
    Y. Yan, H. Wang, Y. Huang, N. He, L. Zhu, Y. Xu, Y. Li, Y. Zheng
    Cross-modal vertical federated learning for mri reconstruction
    IEEE J. Biomed. Heal. Inform. (2024)
    Google Scholar
    Yan et al., 2020
    Z. Yan, J. Wicaksana, Z. Wang, X. Yang, K.-T. Cheng
    Variation-aware federated learning with multi-source decentralized medical image data
    IEEE J. Biomed. Heal. Inform., 25 (7) (2020), pp. 2615-2628
    View in Scopus Google Scholar
    Yaqoob et al., 2023
    M.M. Yaqoob, M. Alsulami, M.A. Khan, D. Alsadie, A.K.J. Saudagar, M. AlKhathami
    Federated machine learning for skin lesion diagnosis: an asynchronous and weighted approach
    Diagnostics, 13 (11) (2023), p. 1964
    View at publisher Crossref View in Scopus Google Scholar
    Yu et al., 2020
    D. Yu, H. Zhang, et al.
    Gradient Perturbation is Underrated for Differentially Private Convex Optimization
    Bessiere C. (Ed.), Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20 (2020), pp. 3117-3123
    View at publisher Crossref View in Scopus Google Scholar
    Zhang et al., 2023a
    R. Zhang, Z. Fan, Q. Xu, J. Yao, Y. Zhang, Y. Wang
    Grace: A generalized and personalized federated learning method for medical imaging
    International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer (2023), pp. 14-24
    Google Scholar
    Zhang et al., 2023c
    X. Zhang, A. Mavromatis, A. Vafeas, R. Nejabati, D. Simeonidou
    Federated feature selection for horizontal federated learning in iot networks
    IEEE Internet Things J., 10 (11) (2023), pp. 10095-10112
    View at publisher Crossref View in Scopus Google Scholar
    Zhang et al., 2024
    F. Zhang, Z. Shuai, K. Kuang, F. Wu, Y. Zhuang, J. Xiao
    Unified fair federated learning for digital healthcare
    Patterns, 5 (1) (2024)
    Google Scholar
    Zhang et al., 2022
    L. Zhang, J. Xu, P. Vijayakumar, P.K. Sharma, U. Ghosh
    Homomorphic encryption-based privacy-preserving federated learning in IoT-enabled healthcare system
    IEEE Trans. Netw. Sci. Eng., 10 (5) (2022), pp. 2864-2880
    Google Scholar
    Zhang et al., 2023b
    Zhang, R., Xu, Q., Yao, J., Zhang, Y., Tian, Q., Wang, Y., 2023b. Federated domain generalization with generalization adjustment. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 3954–3963.
    Google Scholar
    Zhang et al., 2021
    W. Zhang, T. Zhou, Q. Lu, X. Wang, C. Zhu, H. Sun, Z. Wang, S.K. Lo, F.-Y. Wang
    Dynamic-fusion-based federated learning for COVID-19 detection
    IEEE Internet Things J., 8 (21) (2021), pp. 15884-15891
    Crossref View in Scopus Google Scholar
    Zhou et al., 2024a
    J. Zhou, S. Chen, Y. Wu, H. Li, B. Zhang, L. Zhou, Y. Hu, Z. Xiang, Z. Li, N. Chen, et al.
    PPML-omics: a privacy-preserving federated machine learning method protects patients’ privacy in omic data
    Sci. Adv., 10 (5) (2024), Article eadh8601
    View in Scopus Google Scholar
    Zhou et al., 2024d
    X. Zhou, W. Huang, W. Liang, Z. Yan, J. Ma, Y. Pan, I. Kevin, K. Wang
    Federated distillation and blockchain empowered secure knowledge sharing for internet of medical things
    Inform. Sci., 662 (2024), Article 120217
    View PDF View article View in Scopus Google Scholar
    Zhou et al., 2024b
    L. Zhou, M. Wang, N. Zhou
    Distributed federated learning-based deep learning model for privacy mri brain tumor detection
    (2024)
    arXiv preprint arXiv:2404.10026
    Google Scholar
    Zhou et al., 2024c
    T. Zhou, Y. Yuan, B. Wang, E. Konukoglu
    Federated feature augmentation and alignment
    IEEE Trans. Pattern Anal. Mach. Intell. (2024)
    Google Scholar
    Zhu et al., 2021
    Z. Zhu, J. Hong, J. Zhou
    Data-free knowledge distillation for heterogeneous federated learning
    International Conference on Machine Learning, PMLR (2021), pp. 12878-12889
    View in Scopus Google Scholar
    Ziller et al., 2021
    A. Ziller, D. Usynin, N. Remerscheid, M. Knolle, M. Makowski, R. Braren, D. Rueckert, G. Kaissis
    Differentially private federated deep learning for multi-site medical image segmentation
    (2021)
    arXiv preprint arXiv:2107.02586
    Google Scholar
    Zou et al., 2023
    J. Zou, T. Pei, C. Li, R. Wu, S. Wang
    Self-supervised federated learning for fast MR imaging
    IEEE Trans. Instrum. Meas. (2023)
    Google Scholar

Cited by (6)

    Artificial intelligence in muscle-invasive bladder cancer: opportunities, challenges, and clinical impact
    2025, Current Opinion in Urology
    AI in Orthopedic Research: A Comprehensive Review
    2025, Journal of Orthopaedic Research
    Spectral Precision: Recent Advances in Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass Spectrometry for Pathogen Detection and Resistance Profiling
    2025, Microorganisms
    Enhancing malaria detection and classification using convolutional neural networks-vision transformer architecture
    2025, Discover Applied Sciences
    Artificial intelligence in personalized nutrition and food manufacturing: a comprehensive review of methods, applications, and future directions
    2025, Frontiers in Nutrition
    Unleashing the Power of Wireless Communication in Healthcare by Empowering Patient Care and Connectivity: A Comprehensive Survey
    2025, IEEE Access

© 2025 The Authors. Published by Elsevier B.V.
Recommended articles

    Self-supervised 3D medical image segmentation by flow-guided mask propagation learning
    Medical Image Analysis, Volume 101, 2025, Article 103478
    Adeleh Bitarafan , …, Azade Farshad
    View PDF
    ProstAtlasDiff: Prostate cancer detection on MRI using Diffusion Probabilistic Models guided by population spatial cancer atlases
    Medical Image Analysis, Volume 101, 2025, Article 103486
    Cynthia Xinran Li , …, Mirabela Rusu
    View PDF
    SIRE: Scale-invariant, rotation-equivariant estimation of artery orientations using graph neural networks
    Medical Image Analysis, Volume 101, 2025, Article 103467
    Dieuwertje Alblas , …, Jelmer M. Wolterink
    View PDF

Show 3 more articles
Article Metrics
Citations

    Citation Indexes 6 

Captures

    Mendeley Readers 53 

PlumX Metrics Logo View details
Elsevier logo with wordmark

    About ScienceDirect
    Remote access
    Contact and support
    Terms and conditions
    Privacy policy 

Cookies are used by this site. Cookie Settings

All content on this site: Copyright © 2025 Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the relevant licensing terms apply.
RELX group home page
Feedback 